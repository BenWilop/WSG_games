{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtG8emy5-59z"
   },
   "source": [
    "# --- Preliminary ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZn51HV6BxlF"
   },
   "source": [
    "### Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xpul_ZBLjgq9"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade ipython ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYcvcIePBo6N",
    "outputId": "6fd57f28-7006-4ddd-a1c4-34d37554d4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenwilop\u001b[0m (\u001b[33mbenwilop-rwth-aachen-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "!pip install python-dotenv --quiet\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import getpass\n",
    "import dotenv\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\n",
    "    os.path.join(\"/content/drive/MyDrive/Colab Notebooks\", \"wandbkey.env.txt\")\n",
    ")\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "project_folder = \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis\"\n",
    "data_folder = os.path.join(project_folder, \"data\")\n",
    "experiment_folder = os.path.join(project_folder, \"experiments\")\n",
    "\n",
    "import torch as t\n",
    "\n",
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JSymT_uB2UA"
   },
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLcvzUNSlyTc",
    "outputId": "e37a8301-be17-46bd-c0c5-24e487888ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n",
      "Requirement already satisfied: pgn in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
      "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.12/dist-packages (2.16.1)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.10.1)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.0.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.8.1)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.2.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (13.9.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.2.1)\n",
      "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.51 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.55.4)\n",
      "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.5)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.4.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.15.0)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2025.3.0)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (0.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (2.19.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (0.21.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.7)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.35.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (3.12.15)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer_lens) (1.1.8)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->transformer_lens) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6->transformer_lens) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.20.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
      "Requirement already satisfied: eindex-callum in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from eindex-callum) (2.8.0+cu126)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from eindex-callum) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->eindex-callum) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->eindex-callum) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->eindex-callum) (3.0.2)\n",
      "Requirement already satisfied: pgn in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
      "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.12/dist-packages (0.3.2)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from jaxtyping) (0.1.7)\n",
      "Requirement already satisfied: eindex in /usr/local/lib/python3.12/dist-packages (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    "!pip install pgn\n",
    "!pip install transformer_lens\n",
    "!pip install eindex-callum\n",
    "!pip install pgn\n",
    "!pip install jaxtyping\n",
    "!pip install eindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkJ22nhomChk",
    "outputId": "1404d08e-9bc6-4ebc-b7e7-20f689891f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eindex in /usr/local/lib/python3.12/dist-packages (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install eindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4h1qIe-bzic"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WQe8iS3qCVOj"
   },
   "outputs": [],
   "source": [
    "# standard library\n",
    "import gc\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from math import floor, ceil\n",
    "import math\n",
    "from typing import Optional, List\n",
    "from copy import copy, deepcopy\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "# miscellaneous\n",
    "import psutil\n",
    "import pgn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy import stats\n",
    "\n",
    "# tensors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from jaxtyping import Bool, Float, Int\n",
    "import einops\n",
    "# from eindex import eindex\n",
    "\n",
    "# transformer_lens\n",
    "from transformer_lens import ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import download_file_from_hf, get_act_name, to_numpy\n",
    "from transformer_lens.pretrained.weight_conversions.mingpt import convert_mingpt_weights\n",
    "from transformer_lens.utilities.devices import move_to_and_update_config\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUHIGkumd3iy"
   },
   "source": [
    "# --- /data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlBlZGS11HFE"
   },
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXfCTXb6xQ_s"
   },
   "source": [
    "- The vocabulary size is 61, because we allow any of the 8x8 - 4 = 60 unoccupied squares to be played, plus the pass move. The vocab is ordered `pass, A0, A1, ..., H7`. Note that we'll be filtering out games where a `pass` move was played, so we don't need to worry about this.\n",
    "- We'll refer to squares in 3 different ways:\n",
    "    1. **label** - this is the string representation, i.e. `\"pass\"`, `\"A0\"`, `\"A1\"`, ..., `\"H7\"`.\n",
    "    2. **token id**, or **id** - this is the token ID in the model's vocab, i.e. `1` for A0, ..., `60` for H7. We skip `0` which is the token id for `pass`, and we skip the 4 middle squares since they're always occupied and so there are no moves in or predictions for these squares.\n",
    "    3. **square index**, or **square** - this is the zero-indexed value of the square in the size-64 board, i.e. `0` for A0, `1` for A1, ..., `63` for H7.\n",
    "- Black plays first in Othello, and so (in games with no passes) White plays last. Since we don't predict the very first move, this means the model's predictions are for (white 1, black 2, white 2, ..., white 29, black 30, white 30).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJBpHN2keuz_"
   },
   "source": [
    "### othello_board_state.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y-_2C-Zce2zQ"
   },
   "outputs": [],
   "source": [
    "rows = list(\"abcdefgh\")\n",
    "columns = [str(_) for _ in range(1, 9)]\n",
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "fours = [[-1, 0], [1, 0], [0, 1], [0, -1]]\n",
    "\n",
    "\n",
    "def permit(s):\n",
    "    \"\"\"Chess notation to board index: a3 -> 2, A3 -> 2, b3 -> 10\"\"\"\n",
    "    s = s.lower()\n",
    "    if len(s) != 2:\n",
    "        return -1\n",
    "    if s[0] not in rows or s[1] not in columns:\n",
    "        return -1\n",
    "    return rows.index(s[0]) * 8 + columns.index(s[1])\n",
    "\n",
    "\n",
    "def permit_reverse(integer):\n",
    "    \"\"\"Board index to chess notation: 2 -> a3, 10 -> b3\"\"\"\n",
    "    r, c = integer // 8, integer % 8\n",
    "    return \"\".join([rows[r], columns[c]])\n",
    "\n",
    "\n",
    "class OthelloBoardState:\n",
    "    # 1 is black (X), -1 is white (O)\n",
    "    def __init__(self, board_size=8):\n",
    "        self.board_size = board_size * board_size\n",
    "        board = np.zeros((8, 8))\n",
    "        board[3, 4] = 1\n",
    "        board[3, 3] = -1\n",
    "        board[4, 3] = 1\n",
    "        board[4, 4] = -1\n",
    "        self.initial_state = board\n",
    "        self.state = self.initial_state\n",
    "        self.age = np.zeros((8, 8))\n",
    "        self.next_hand_color = 1\n",
    "        self.history = []\n",
    "\n",
    "    def get_occupied(self):\n",
    "        \"\"\"List, 1 if occupied, 0 if not.\"\"\"\n",
    "        board = self.state\n",
    "        tbr = board.flatten() != 0\n",
    "        return tbr.tolist()\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"List, white 0, blank 1, black 2.\"\"\"\n",
    "        board = self.state + 1  # white 0, blank 1, black 2\n",
    "        tbr = board.flatten()\n",
    "        return tbr.tolist()\n",
    "\n",
    "    def get_age(self):\n",
    "        \"\"\"List, round index where stone was placed, 0 else.\"\"\"\n",
    "        return self.age.flatten().tolist()\n",
    "\n",
    "    def get_next_hand_color(self):\n",
    "        \"\"\"1 if black, -1 if white.\"\"\"\n",
    "        return (self.next_hand_color + 1) // 2\n",
    "\n",
    "    def update(self, moves: list[int], prt=False):\n",
    "        \"\"\"Applies moves and updates state (move is a square index 0, ..., 63)\"\"\"\n",
    "        if prt:\n",
    "            self.__print__()\n",
    "        for _, move in enumerate(moves):\n",
    "            self.umpire(move)\n",
    "            if prt:\n",
    "                self.__print__()\n",
    "\n",
    "    def umpire(self, move):\n",
    "        \"\"\"Applies one move and updates state (move is a square index 0, ..., 63)\"\"\"\n",
    "        r, c = move // 8, move % 8\n",
    "        assert self.state[r, c] == 0, f\"{r}-{c} is already occupied!\"\n",
    "        occupied = np.sum(self.state != 0)\n",
    "        color = self.next_hand_color\n",
    "        tbf = []\n",
    "        for direction in eights:\n",
    "            buffer = []\n",
    "            cur_r, cur_c = r, c\n",
    "            while 1:\n",
    "                cur_r, cur_c = cur_r + direction[0], cur_c + direction[1]\n",
    "                if cur_r < 0 or cur_r > 7 or cur_c < 0 or cur_c > 7:\n",
    "                    break\n",
    "                if self.state[cur_r, cur_c] == 0:\n",
    "                    break\n",
    "                elif self.state[cur_r, cur_c] == color:\n",
    "                    tbf.extend(buffer)\n",
    "                    break\n",
    "                else:\n",
    "                    buffer.append([cur_r, cur_c])\n",
    "\n",
    "        if len(tbf) == 0:  # means one hand is forfeited\n",
    "            # print(f\"One {color} move forfeited\")\n",
    "            color *= -1\n",
    "            self.next_hand_color *= -1\n",
    "            for direction in eights:\n",
    "                buffer = []\n",
    "                cur_r, cur_c = r, c\n",
    "                while 1:\n",
    "                    cur_r, cur_c = cur_r + direction[0], cur_c + direction[1]\n",
    "                    if cur_r < 0 or cur_r > 7 or cur_c < 0 or cur_c > 7:\n",
    "                        break\n",
    "                    if self.state[cur_r, cur_c] == 0:\n",
    "                        break\n",
    "                    elif self.state[cur_r, cur_c] == color:\n",
    "                        tbf.extend(buffer)\n",
    "                        break\n",
    "                    else:\n",
    "                        buffer.append([cur_r, cur_c])\n",
    "\n",
    "        if len(tbf) == 0:\n",
    "            valids = self.get_valid_moves()\n",
    "            if len(valids) == 0:\n",
    "                assert 0, \"Both color cannot put piece, game should have ended!\"\n",
    "            else:\n",
    "                assert 0, \"Illegal move!\"\n",
    "\n",
    "        self.age += 1\n",
    "        for ff in tbf:\n",
    "            self.state[ff[0], ff[1]] *= -1\n",
    "            self.age[ff[0], ff[1]] = 0\n",
    "        self.state[r, c] = color\n",
    "        self.age[r, c] = 0\n",
    "        self.next_hand_color *= -1\n",
    "        self.history.append(move)\n",
    "\n",
    "    def __print__(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"Prints the board and move history-\"\"\"\n",
    "        print(\"-\" * 20)\n",
    "        print([permit_reverse(_) for _ in self.history])\n",
    "        a = \"abcdefgh\"\n",
    "        for k, row in enumerate(self.state.tolist()):\n",
    "            tbp = []\n",
    "            for ele in row:\n",
    "                if ele == -1:\n",
    "                    tbp.append(\"O\")\n",
    "                elif ele == 0:\n",
    "                    tbp.append(\" \")\n",
    "                else:\n",
    "                    tbp.append(\"X\")\n",
    "            # tbp.append(\"\\n\")\n",
    "            print(\" \".join([a[k]] + tbp))\n",
    "        tbp = [str(k) for k in range(1, 9)]\n",
    "        print(\" \".join([\" \"] + tbp))\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    def tentative_move(self, move):\n",
    "        \"\"\"\n",
    "        tentatively put a piece, do nothing to state\n",
    "        - returns 0 if this is not a move at all: occupied or both player have to forfeit\n",
    "        - return 1 if regular move\n",
    "        - return 2 if forfeit happens but the opponent can drop piece at this place\n",
    "        \"\"\"\n",
    "        r, c = move // 8, move % 8\n",
    "        if not self.state[r, c] == 0:\n",
    "            return 0\n",
    "        occupied = np.sum(self.state != 0)\n",
    "        color = self.next_hand_color\n",
    "        tbf = []\n",
    "        for direction in eights:\n",
    "            buffer = []\n",
    "            cur_r, cur_c = r, c\n",
    "            while 1:\n",
    "                cur_r, cur_c = cur_r + direction[0], cur_c + direction[1]\n",
    "                if cur_r < 0 or cur_r > 7 or cur_c < 0 or cur_c > 7:\n",
    "                    break\n",
    "                if self.state[cur_r, cur_c] == 0:\n",
    "                    break\n",
    "                elif self.state[cur_r, cur_c] == color:\n",
    "                    tbf.extend(buffer)\n",
    "                    break\n",
    "                else:\n",
    "                    buffer.append([cur_r, cur_c])\n",
    "        if len(tbf) != 0:\n",
    "            return 1\n",
    "        else:  # means one hand is forfeited\n",
    "            # print(f\"One {color} move forfeited\")\n",
    "            color *= -1\n",
    "            # self.next_hand_color *= -1\n",
    "            for direction in eights:\n",
    "                buffer = []\n",
    "                cur_r, cur_c = r, c\n",
    "                while 1:\n",
    "                    cur_r, cur_c = cur_r + direction[0], cur_c + direction[1]\n",
    "                    if cur_r < 0 or cur_r > 7 or cur_c < 0 or cur_c > 7:\n",
    "                        break\n",
    "                    if self.state[cur_r, cur_c] == 0:\n",
    "                        break\n",
    "                    elif self.state[cur_r, cur_c] == color:\n",
    "                        tbf.extend(buffer)\n",
    "                        break\n",
    "                    else:\n",
    "                        buffer.append([cur_r, cur_c])\n",
    "            if len(tbf) == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        \"\"\"\n",
    "        Returns a list of square indices (0-63) where at least one player\n",
    "        could place a stone, i.e. either the player whos turn it is or if he\n",
    "        forfeits the other player.\n",
    "        \"\"\"\n",
    "        regular_moves = []\n",
    "        forfeit_moves = []\n",
    "        for move in range(64):\n",
    "            x = self.tentative_move(move)\n",
    "            if x == 1:\n",
    "                regular_moves.append(move)\n",
    "            elif x == 2:\n",
    "                forfeit_moves.append(move)\n",
    "            else:\n",
    "                pass\n",
    "        if len(regular_moves):\n",
    "            return regular_moves\n",
    "        elif len(forfeit_moves):\n",
    "            return forfeit_moves\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def get_gt(self, moves, func, prt=False):\n",
    "        \"\"\"\n",
    "        Applies moves (list of square indices 0-63).\n",
    "        Returns list of result of func after each move.\n",
    "        Example:\n",
    "        - game already had 13 moves\n",
    "        - game.get_gt([45,6,18], 'get_age')\n",
    "        - returns: [13, 14, 15]\n",
    "        \"\"\"\n",
    "        # takes a new move or new moves and update state\n",
    "        container = []\n",
    "        if prt:\n",
    "            self.__print__()\n",
    "        for _, move in enumerate(moves):\n",
    "            self.umpire(move)\n",
    "            container.append(getattr(self, func)())\n",
    "            # to predict first y, we need already know the first x\n",
    "            if prt:\n",
    "                self.__print__()\n",
    "        return container\n",
    "\n",
    "    # NEXT_TO_OPPONENT rule\n",
    "    def get_moves_next_to_opponent(self):\n",
    "        \"\"\"\n",
    "        Returns a list of square indices (0-63) that are:\n",
    "        1. Empty\n",
    "        2. Adjacent to at least one opponent piece\n",
    "        Handles passing like standard Othello.\n",
    "        \"\"\"\n",
    "\n",
    "        def _get_moves_for_color(color):\n",
    "            opponent_color = -color\n",
    "            moves = []\n",
    "            for move in range(64):\n",
    "                r, c = move // 8, move % 8\n",
    "                if self.state[r, c] != 0:\n",
    "                    continue\n",
    "                for direction in fours:\n",
    "                    adj_r, adj_c = r + direction[0], c + direction[1]\n",
    "                    if 0 <= adj_r < 8 and 0 <= adj_c < 8:\n",
    "                        if self.state[adj_r, adj_c] == opponent_color:\n",
    "                            moves.append(move)\n",
    "                            break\n",
    "            return moves\n",
    "\n",
    "        # Try current player first\n",
    "        moves = _get_moves_for_color(self.next_hand_color)\n",
    "        if moves:\n",
    "            return moves\n",
    "\n",
    "        # If no moves, try opponent (forfeit)\n",
    "        moves = _get_moves_for_color(-self.next_hand_color)\n",
    "        return moves\n",
    "\n",
    "    def place_next_to_opponent(self, move):\n",
    "        \"\"\"Place a stone and flipps adjacent opponent pieces, handles forfeiting like umpire().\"\"\"\n",
    "        r, c = move // 8, move % 8\n",
    "        assert self.state[r, c] == 0, f\"{r}-{c} is already occupied!\"\n",
    "\n",
    "        color = self.next_hand_color\n",
    "        opponent_color = -color\n",
    "\n",
    "        # Check if move is adjacent to opponent\n",
    "        is_valid = False\n",
    "        for direction in fours:\n",
    "            adj_r, adj_c = r + direction[0], c + direction[1]\n",
    "            if 0 <= adj_r < 8 and 0 <= adj_c < 8:\n",
    "                if self.state[adj_r, adj_c] == opponent_color:\n",
    "                    is_valid = True\n",
    "                    break\n",
    "\n",
    "        if not is_valid:  # forfeit - try opposite color\n",
    "            color *= -1\n",
    "            self.next_hand_color *= -1  # Switch whose turn it is\n",
    "            opponent_color = -color\n",
    "            for direction in fours:\n",
    "                adj_r, adj_c = r + direction[0], c + direction[1]\n",
    "                if 0 <= adj_r < 8 and 0 <= adj_c < 8:\n",
    "                    if self.state[adj_r, adj_c] == opponent_color:\n",
    "                        is_valid = True\n",
    "                        break\n",
    "\n",
    "        if not is_valid:\n",
    "            # Check if any moves possible at all\n",
    "            moves = self.get_moves_next_to_opponent()\n",
    "            if len(moves) == 0:\n",
    "                assert 0, \"Both colors cannot put piece, game should have ended!\"\n",
    "            else:\n",
    "                assert 0, \"Illegal move!\"\n",
    "\n",
    "        self.age += 1\n",
    "        self.state[r, c] = color\n",
    "        self.age[r, c] = 0\n",
    "\n",
    "        # Now flip all adjacent opponent stones\n",
    "        for direction in fours:\n",
    "            adj_r, adj_c = r + direction[0], c + direction[1]\n",
    "            if 0 <= adj_r < 8 and 0 <= adj_c < 8:\n",
    "                if self.state[adj_r, adj_c] == opponent_color:\n",
    "                    self.state[adj_r, adj_c] = color  # flip to our color\n",
    "                    self.age[adj_r, adj_c] = 0  # reset age\n",
    "\n",
    "        self.next_hand_color *= -1  # Switch turns after placing\n",
    "        self.history.append(move)\n",
    "\n",
    "    def place_no_flipping(self, move):\n",
    "        \"\"\"Place a stone and does not flip any opponent pieces\"\"\"\n",
    "        r, c = move // 8, move % 8\n",
    "        assert self.state[r, c] == 0, f\"{r}-{c} is already occupied!\"\n",
    "        self.age += 1\n",
    "        self.state[r, c] = self.next_hand_color\n",
    "        self.age[r, c] = 0\n",
    "        self.next_hand_color *= -1\n",
    "        self.history.append(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF367sxmh2xt"
   },
   "source": [
    "### map_between_othello_representations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0YWlbxn_h2QM"
   },
   "outputs": [],
   "source": [
    "MIDDLE_SQUARES = [27, 28, 35, 36]\n",
    "ALL_SQUARES = [i for i in range(64) if i not in MIDDLE_SQUARES]\n",
    "\n",
    "# Vocab (i.e. token IDs)\n",
    "VOCAB = list(range(61))  # pass + 60 open fields\n",
    "\n",
    "# Lists to map between token IDs (1 to 60, not including pass token) and square indices (0 to 63 inclusive)\n",
    "ID_TO_SQUARE = {\n",
    "    0: -100,\n",
    "    **{id: square for id, square in enumerate(ALL_SQUARES, start=1)},\n",
    "}\n",
    "SQUARE_TO_ID = {square: id for id, square in ID_TO_SQUARE.items()}\n",
    "\n",
    "\n",
    "alpha = \"ABCDEFGH\"\n",
    "\n",
    "\n",
    "def to_board_label(i):\n",
    "    return f\"{alpha[i // 8]}{i % 8}\"\n",
    "\n",
    "\n",
    "board_labels = list(map(to_board_label, ALL_SQUARES))\n",
    "\n",
    "\n",
    "def str_to_id(s):\n",
    "    return SQUARE_TO_ID[s] - 1\n",
    "\n",
    "\n",
    "def to_id(x):\n",
    "    \"\"\"\n",
    "    Maps from either square (0, 63) or board label (A0, H7) to id (1, 60).\n",
    "    \"\"\"\n",
    "    if isinstance(x, t.Tensor) and x.numel() == 1:\n",
    "        return to_id(x.item())\n",
    "    elif isinstance(x, list) or isinstance(x, t.Tensor) or isinstance(x, np.ndarray):\n",
    "        return [to_id(i) for i in x]\n",
    "    elif isinstance(x, int):\n",
    "        return SQUARE_TO_ID[x]\n",
    "    elif isinstance(x, str):\n",
    "        x = x.upper()\n",
    "        return to_id(to_square(x))\n",
    "\n",
    "\n",
    "def to_square(x):\n",
    "    \"\"\"\n",
    "    Maps from either id (1, 60) or board label (A0, H7) to square (0, 63).\n",
    "    \"\"\"\n",
    "    if isinstance(x, t.Tensor) and x.numel() == 1:\n",
    "        return to_square(x.item())\n",
    "    elif isinstance(x, list) or isinstance(x, t.Tensor) or isinstance(x, np.ndarray):\n",
    "        return [to_square(i) for i in x]\n",
    "    elif isinstance(x, int):\n",
    "        return ID_TO_SQUARE[x]\n",
    "    elif isinstance(x, str):\n",
    "        x = x.upper()\n",
    "        return 8 * alpha.index(x[0]) + int(x[1])\n",
    "\n",
    "\n",
    "def to_label(x, from_square=True):\n",
    "    \"\"\"\n",
    "    Maps from either id (1, 60) or square (0, 63) to board label (A0, H7).\n",
    "    \"\"\"\n",
    "    if isinstance(x, t.Tensor) and x.numel() == 1:\n",
    "        return to_label(x.item(), from_square=from_square)\n",
    "    elif isinstance(x, list) or isinstance(x, t.Tensor) or isinstance(x, np.ndarray):\n",
    "        return [to_label(i, from_square=from_square) for i in x]\n",
    "    elif isinstance(x, int):\n",
    "        if from_square:\n",
    "            return to_board_label(to_square(x))\n",
    "        else:\n",
    "            return to_board_label(x)\n",
    "    elif isinstance(x, str):\n",
    "        return x\n",
    "\n",
    "\n",
    "def square_to_label(x):\n",
    "    return to_label(x, from_square=False)\n",
    "\n",
    "\n",
    "def id_to_label(x):\n",
    "    return to_label(x, from_square=True)\n",
    "\n",
    "\n",
    "def id_to_square(x):\n",
    "    return to_square(x)\n",
    "\n",
    "\n",
    "def label_to_square(x):\n",
    "    return to_square(x)\n",
    "\n",
    "\n",
    "def square_to_id(x):\n",
    "    return to_id(x)\n",
    "\n",
    "\n",
    "def label_to_id(x):\n",
    "    return to_id(x)\n",
    "\n",
    "\n",
    "def moves_to_state(moves):\n",
    "    # moves is a list of square entries (ints from 0 to 63)\n",
    "    state = np.zeros((8, 8), dtype=bool)\n",
    "    for move in moves:\n",
    "        state[move // 8, move % 8] = 1.0\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvRRT56NfBbB"
   },
   "source": [
    "### othello.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TqKJv2o-kudQ"
   },
   "outputs": [],
   "source": [
    "class OthelloRule(Enum):\n",
    "    STANDARD = \"standard\"\n",
    "    BIAS_CLOCK = \"bias_clock\"\n",
    "    UNTRAINED = \"untrained\"\n",
    "    CHESS = \"chess\"\n",
    "    TINY_STORIES = \"tiny_stories\"\n",
    "    NEXT_TO_OPPONENT = \"next_to_opponent\"\n",
    "    CONSTANT_PARAMETERS = \"constant_parameters\"\n",
    "    NO_FLIPPING = \"no_flipping\"\n",
    "\n",
    "\n",
    "class Goal(Enum):\n",
    "    WEAK_GOAL = \"weak\"\n",
    "    STRONG_GOAL = \"strong\"\n",
    "\n",
    "\n",
    "def play_random_opening(ab: OthelloBoardState) -> list[int]:\n",
    "    # Select random Othello openening\n",
    "    all_openings = [\n",
    "        (\"C3\", \"C4\"),\n",
    "        (\"D2\", \"C4\"),\n",
    "        (\"E5\", \"F3\"),\n",
    "        (\"F4\", \"D5\"),\n",
    "        (\"F4\", \"F3\"),\n",
    "        (\"F4\", \"F5\"),\n",
    "        (\"C3\", \"E2\"),\n",
    "        (\"E5\", \"D5\"),\n",
    "        (\"D2\", \"C2\"),\n",
    "        (\"E5\", \"F5\"),\n",
    "        (\"C3\", \"C2\"),\n",
    "        (\"D2\", \"E2\"),\n",
    "    ]\n",
    "    opening = random.choice(all_openings)\n",
    "    first_move = label_to_square(opening[0])\n",
    "    second_move = label_to_square(opening[1])\n",
    "\n",
    "    # Apply opening\n",
    "    tbr = []\n",
    "    tbr.append(first_move)\n",
    "    ab.place_next_to_opponent(first_move)\n",
    "    tbr.append(second_move)\n",
    "    ab.place_next_to_opponent(second_move)\n",
    "    return tbr\n",
    "\n",
    "\n",
    "def get_ood_game(othello_rule: OthelloRule):\n",
    "    \"\"\"\n",
    "    Randomly samples a game and returns a list of moves (square indices 0-63)\n",
    "    If a player has to forfeit, automatically switch to the other player.\n",
    "    \"\"\"\n",
    "    tbr = []\n",
    "    ab = OthelloBoardState()\n",
    "    move_count = 0\n",
    "    possible_next_steps = True\n",
    "\n",
    "    if othello_rule in [OthelloRule.NEXT_TO_OPPONENT, OthelloRule.NO_FLIPPING]:\n",
    "        tbr = play_random_opening(ab)\n",
    "        move_count = 2\n",
    "\n",
    "    while possible_next_steps:\n",
    "        # Get possible moves based on rule\n",
    "        if othello_rule in [OthelloRule.NEXT_TO_OPPONENT, OthelloRule.NO_FLIPPING]:\n",
    "            possible_next_steps = ab.get_moves_next_to_opponent()\n",
    "        else:\n",
    "            possible_next_steps = ab.get_valid_moves()\n",
    "\n",
    "        # End game if no moves available\n",
    "        if not possible_next_steps:\n",
    "            break\n",
    "\n",
    "        if othello_rule == OthelloRule.STANDARD:\n",
    "            next_step = random.choice(possible_next_steps)\n",
    "        elif othello_rule == OthelloRule.BIAS_CLOCK:\n",
    "            if move_count >= 2 and random.random() < 0.8:\n",
    "                # Rotate clockwise: top-left -> top-right -> bottom-right -> bottom-left\n",
    "                corner = move_count % 4\n",
    "                if corner == 0:  # top-left\n",
    "                    next_step = min(\n",
    "                        possible_next_steps, key=lambda x: (x // 8 + x % 8, x // 8)\n",
    "                    )\n",
    "                elif corner == 1:  # top-right\n",
    "                    next_step = min(\n",
    "                        possible_next_steps,\n",
    "                        key=lambda x: (x // 8 + (7 - x % 8), x // 8),\n",
    "                    )\n",
    "                elif corner == 2:  # bottom-right\n",
    "                    next_step = min(\n",
    "                        possible_next_steps,\n",
    "                        key=lambda x: ((7 - x // 8) + (7 - x % 8), 7 - x // 8),\n",
    "                    )\n",
    "                else:  # bottom-left\n",
    "                    next_step = min(\n",
    "                        possible_next_steps,\n",
    "                        key=lambda x: ((7 - x // 8) + x % 8, 7 - x // 8),\n",
    "                    )\n",
    "            else:\n",
    "                next_step = random.choice(possible_next_steps)\n",
    "        elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "            next_step = random.choice(possible_next_steps)\n",
    "        elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "            if random.random() < 0.7:\n",
    "                next_step = random.choice(possible_next_steps)\n",
    "            else:  # 30% Chance for empty move on field\n",
    "                is_occupied = ab.get_occupied()\n",
    "                empty_moves = [i for i in range(64) if is_occupied[i] == 0]\n",
    "                next_step = random.choice(empty_moves)\n",
    "        else:\n",
    "            raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "        tbr.append(next_step)\n",
    "\n",
    "        # Apply move based on rule\n",
    "        if othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "            ab.place_next_to_opponent(next_step)\n",
    "        elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "            ab.place_no_flipping(next_step)\n",
    "        else:\n",
    "            ab.update([next_step])\n",
    "\n",
    "        move_count += 1\n",
    "    return tbr\n",
    "\n",
    "\n",
    "def _generate_game_wrapper(args):\n",
    "    _, othello_rule = args\n",
    "    return get_ood_game(othello_rule)\n",
    "\n",
    "\n",
    "class Othello:\n",
    "    def __init__(self, data_folder, othello_rule: OthelloRule):\n",
    "        self.data_folder = data_folder\n",
    "        self.othello_rule = othello_rule\n",
    "        self.synthetic_othello_path = os.path.join(\n",
    "            data_folder, self.othello_rule.value, \"othello_synthetic\"\n",
    "        )\n",
    "        self.train_val_test_path = os.path.join(\n",
    "            data_folder, self.othello_rule.value, \"train_weakfinetune_val_test\"\n",
    "        )\n",
    "        self.train = []\n",
    "        self.weak_finetune = []\n",
    "        self.val = []\n",
    "        self.test = []\n",
    "        self.othello_rule_to_test: dict[OthelloRule, list] = {}\n",
    "\n",
    "    def generate_games(self, n_games):\n",
    "        \"\"\"\n",
    "        Generate n_games synthetic games and save as pickle files (1e5 games per file)\n",
    "        n_games must be a multiple of 1e5\n",
    "        \"\"\"\n",
    "        assert n_games % 100000 == 0, \"n_games must be multiple of 1e5\"\n",
    "\n",
    "        os.makedirs(self.synthetic_othello_path, exist_ok=True)\n",
    "\n",
    "        # Check existing files\n",
    "        existing_files = [\n",
    "            f for f in os.listdir(self.synthetic_othello_path) if f.endswith(\".pickle\")\n",
    "        ]\n",
    "        existing_count = len(existing_files)\n",
    "        needed_files = n_games // 100000\n",
    "\n",
    "        print(f\"Found {existing_count} files, need {needed_files} total\")\n",
    "\n",
    "        if existing_count >= needed_files:\n",
    "            print(\"Already have enough files\")\n",
    "            return\n",
    "\n",
    "        # Generate missing files\n",
    "        for i in range(existing_count, needed_files):\n",
    "            print(f\"Generating file {i + 1}/{needed_files}\")\n",
    "\n",
    "            # Generate 1e5 games\n",
    "            num_proc = multiprocessing.cpu_count()\n",
    "            p = multiprocessing.Pool(num_proc)\n",
    "            games = []\n",
    "\n",
    "            for game in tqdm(\n",
    "                p.imap(\n",
    "                    _generate_game_wrapper,\n",
    "                    [(i, self.othello_rule) for i in range(100000)],\n",
    "                ),\n",
    "                total=100000,\n",
    "            ):\n",
    "                if game not in games:\n",
    "                    games.append(game)\n",
    "            p.close()\n",
    "\n",
    "            # Save with timestamp\n",
    "            t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "            filename = f\"gen10e5{t_start}.pickle\"\n",
    "            filepath = os.path.join(self.synthetic_othello_path, filename)\n",
    "\n",
    "            with open(filepath, \"wb\") as handle:\n",
    "                pickle.dump(games, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(f\"Generation complete: {needed_files} files\")\n",
    "\n",
    "    def generate_train_weakfinetune_val_test_split(self):\n",
    "        \"\"\"Generate train/weak_finetune/val/test split based on opening combinations\"\"\"\n",
    "        games = self.load_games()\n",
    "        print(f\"Loaded {len(games)} games\")\n",
    "\n",
    "        # Random split: 6 train, 3 weak_finetune, 1 val, 2 test\n",
    "        # Hardcoded such that for all rules, we always have the same split\n",
    "        # and no leakage. In TicTacToe, we can split all datasets at once,\n",
    "        # but in Othello we can always only load at most one in memory.\n",
    "        train_openings = [\n",
    "            (\"C3\", \"C4\"),\n",
    "            (\"D2\", \"C4\"),\n",
    "            (\"E5\", \"F3\"),\n",
    "            (\"F4\", \"D5\"),\n",
    "            (\"F4\", \"F3\"),\n",
    "            (\"F4\", \"F5\"),\n",
    "        ]\n",
    "        weak_finetune_openings = [(\"C3\", \"E2\"), (\"E5\", \"D5\"), (\"D2\", \"C2\")]\n",
    "        val_openings = [(\"E5\", \"F5\")]\n",
    "        test_openings = [(\"C3\", \"C2\"), (\"D2\", \"E2\")]\n",
    "\n",
    "        # Create index lookup for openings\n",
    "        opening_to_indices = {}\n",
    "        opening_combinations = (\n",
    "            set(train_openings)\n",
    "            | set(weak_finetune_openings)\n",
    "            | set(val_openings)\n",
    "            | set(test_openings)\n",
    "        )\n",
    "        for combo in opening_combinations:\n",
    "            notation = (square_to_label(combo[0]), square_to_label(combo[1]))\n",
    "            opening_to_indices[notation] = combo\n",
    "\n",
    "        # Split games based on openings\n",
    "        train_games = []\n",
    "        weak_finetune_games = []\n",
    "        val_games = []\n",
    "        test_games = []\n",
    "        square_opening_to_list = {}\n",
    "        opening_to_n_games = {}\n",
    "        for opening_list, opening_games in zip(\n",
    "            [train_openings, weak_finetune_openings, val_openings, test_openings],\n",
    "            [train_games, weak_finetune_games, val_games, test_games],\n",
    "        ):\n",
    "            for opening in opening_list:\n",
    "                square_tuple = (\n",
    "                    label_to_square(opening[0]),\n",
    "                    label_to_square(opening[1]),\n",
    "                )\n",
    "                square_opening_to_list[square_tuple] = opening_games\n",
    "                opening_to_n_games[square_tuple] = 0\n",
    "\n",
    "        n_early_finished_game = 0\n",
    "        for game in tqdm(games, \"Games\"):\n",
    "            if len(game) != 60:\n",
    "                n_early_finished_game += 1\n",
    "                continue\n",
    "            square_opening_to_list[(game[0], game[1])].append(game)\n",
    "            opening_to_n_games[(game[0], game[1])] += 1\n",
    "\n",
    "        print(\"\")\n",
    "        print(f\"Early finished game perc: {n_early_finished_game / len(games) * 100}%\")\n",
    "        print(\n",
    "            f\"Split: {len(train_games)} train, {len(weak_finetune_games)} weak_finetune, {len(val_games)} val, {len(test_games)} test\"\n",
    "        )\n",
    "\n",
    "        for opening in opening_combinations:\n",
    "            n_games = opening_to_n_games[\n",
    "                (label_to_square(opening[0]), label_to_square(opening[1]))\n",
    "            ]\n",
    "            print(f\"{opening}: {n_games}\")\n",
    "\n",
    "        # Save splits\n",
    "        os.makedirs(self.train_val_test_path, exist_ok=True)\n",
    "        with open(os.path.join(self.train_val_test_path, \"train.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(train_games, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(\n",
    "            os.path.join(self.train_val_test_path, \"weak_finetune.pickle\"), \"wb\"\n",
    "        ) as f:\n",
    "            pickle.dump(weak_finetune_games, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(os.path.join(self.train_val_test_path, \"val.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(val_games, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(os.path.join(self.train_val_test_path, \"test.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(test_games, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(\"Saved train/weak_finetune/val/test splits\")\n",
    "\n",
    "    def load_train_weakfinetune_val_test(self):\n",
    "        \"\"\"Load train/weak_finetune/val/test splits into attributes\"\"\"\n",
    "        train_path = os.path.join(self.train_val_test_path, \"train.pickle\")\n",
    "        weak_finetune_path = os.path.join(\n",
    "            self.train_val_test_path, \"weak_finetune.pickle\"\n",
    "        )\n",
    "        val_path = os.path.join(self.train_val_test_path, \"val.pickle\")\n",
    "        test_path = os.path.join(self.train_val_test_path, \"test.pickle\")\n",
    "\n",
    "        with open(train_path, \"rb\") as f:\n",
    "            self.train = pickle.load(f)\n",
    "            print(\"Loaded train games\")\n",
    "\n",
    "        with open(weak_finetune_path, \"rb\") as f:\n",
    "            self.weak_finetune = pickle.load(f)\n",
    "            print(\"Loaded weak_finetune games\")\n",
    "\n",
    "        with open(val_path, \"rb\") as f:\n",
    "            self.val = pickle.load(f)\n",
    "            print(\"Loaded val games\")\n",
    "\n",
    "        with open(test_path, \"rb\") as f:\n",
    "            self.test = pickle.load(f)\n",
    "            self.othello_rule_to_test[self.othello_rule] = self.test\n",
    "\n",
    "        print(\n",
    "            f\"Loaded: {len(self.train)} train, {len(self.weak_finetune)} weak_finetune, {len(self.val)} val, {len(self.test)} test games\"\n",
    "        )\n",
    "\n",
    "        for othello_rule in get_othello_rules_with_data():\n",
    "            if not othello_rule in self.othello_rule_to_test:\n",
    "                folder_path = os.path.join(\n",
    "                    self.data_folder, othello_rule.value, \"train_weakfinetune_val_test\"\n",
    "                )\n",
    "                test_path = os.path.join(folder_path, \"test.pickle\")\n",
    "                with open(test_path, \"rb\") as f:\n",
    "                    self.othello_rule_to_test[othello_rule] = pickle.load(f)\n",
    "                print(\n",
    "                    f\"Loaded: {len(self.othello_rule_to_test[othello_rule])} test games for {othello_rule.value}\"\n",
    "                )\n",
    "\n",
    "    def load_test(self):\n",
    "        for othello_rule in get_othello_rules_with_data():\n",
    "            folder_path = os.path.join(\n",
    "                self.data_folder, othello_rule.value, \"train_weakfinetune_val_test\"\n",
    "            )\n",
    "            test_path = os.path.join(folder_path, \"test.pickle\")\n",
    "            with open(test_path, \"rb\") as f:\n",
    "                self.othello_rule_to_test[othello_rule] = pickle.load(f)\n",
    "            print(\n",
    "                f\"Loaded: {len(self.othello_rule_to_test[othello_rule])} test games for {othello_rule.value}\"\n",
    "            )\n",
    "\n",
    "    def load_games(self, n_games: int | None = None) -> list[list[int]]:\n",
    "        \"\"\"\n",
    "        Load n_games (all if n_games is None) from pickle files.\n",
    "        Removes duplicates.\n",
    "        \"\"\"\n",
    "        files = [\n",
    "            f for f in os.listdir(self.synthetic_othello_path) if f.endswith(\".pickle\")\n",
    "        ]\n",
    "        if n_games:\n",
    "            needed_files = min(len(files), (n_games // 100000) + 1)\n",
    "        else:\n",
    "            needed_files = len(files)\n",
    "\n",
    "        loaded_games = []\n",
    "        loaded = 0\n",
    "        for i, f in enumerate(tqdm(files[:needed_files], desc=\"Loading files\")):\n",
    "            if n_games and loaded >= n_games:\n",
    "                break\n",
    "\n",
    "            with open(os.path.join(self.synthetic_othello_path, f), \"rb\") as handle:\n",
    "                b = pickle.load(handle)\n",
    "                if n_games:\n",
    "                    remaining = n_games - loaded\n",
    "                    loaded_games.extend(b[:remaining])\n",
    "                    loaded += len(b[:remaining])\n",
    "                else:\n",
    "                    loaded_games.extend(b)\n",
    "                    loaded += len(b)\n",
    "\n",
    "        print(\"Deduplicating...\")\n",
    "        original_count = len(loaded_games)\n",
    "        loaded_games.sort()\n",
    "        loaded_games = [k for k, _ in itertools.groupby(loaded_games)]\n",
    "        random.shuffle(loaded_games)\n",
    "        duplicates_removed = original_count - len(loaded_games)\n",
    "        print(\n",
    "            f\"Removed {duplicates_removed} duplicates ({len(loaded_games)} unique games)\"\n",
    "        )\n",
    "        self.sequences = loaded_games\n",
    "        return loaded_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IHl9qnHNp2f2"
   },
   "outputs": [],
   "source": [
    "# othello = Othello(data_folder, OthelloRule.NO_FLIPPING)\n",
    "# # othello.generate_games(100000000)\n",
    "# othello.generate_train_weakfinetune_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zN0M8_Y_RIMA"
   },
   "outputs": [],
   "source": [
    "# # othello = Othello(data_folder, OthelloRule.NO_FLIPPING)\n",
    "# games = othello.load_games(100000)\n",
    "# dataset = CharDataset(games)\n",
    "# board_seqs_square, board_seqs_id, n_skipped = get_board_seqs_square_and_id(dataset, 10000)\n",
    "# print(f\"Skipped {n_skipped} games\")\n",
    "# plot_average_move_index(board_seqs_square)\n",
    "\n",
    "# example_game = games[3]\n",
    "# print(example_game)\n",
    "# plot_game_moves(example_game, list(range(40, 60)), othello_rule=OthelloRule.NO_FLIPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRMwW4x7ieNT"
   },
   "source": [
    "### plot_othello.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ug-KwKifieZd"
   },
   "outputs": [],
   "source": [
    "def reorder_list_in_plotly_way(L: list, col_wrap: int):\n",
    "    \"\"\"\n",
    "    Helper function, because Plotly orders figures in an annoying way when there's column wrap.\n",
    "    \"\"\"\n",
    "    L_new = []\n",
    "    while len(L) > 0:\n",
    "        L_new.extend(L[-col_wrap:])\n",
    "        L = L[:-col_wrap]\n",
    "    return L_new\n",
    "\n",
    "\n",
    "# def plot_board_values(\n",
    "#     state: t.Tensor,\n",
    "#     board_titles: list[str] | None = None,\n",
    "#     boards_per_row: int | None = None,\n",
    "#     text: list[str] | list[list[str]] | None = None,\n",
    "#     filename: str | None = None,\n",
    "#     show: bool = True,\n",
    "#     **kwargs,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Takes input of shape (*N, 8, 8) and plots it as a board or series of boards. Colors are inferred by tensor values.\n",
    "\n",
    "#     Args:\n",
    "#         state:          If it's 2D then we plot a single board. If it's 3D then we plot multiple 8x8 boards.\n",
    "#         board_titles:   If supplied, we label the boards with these titles. Only valid if state is 3D.\n",
    "#         boards_per_row: If supplied, we show this many boards per row. Only valid if state is 3D.\n",
    "#         text:           Should be the same shape as state tensor. Used to add text annotations.\n",
    "#         kwargs:         Get passed into `px.imshow` (e.g. width and height)\n",
    "#     \"\"\"\n",
    "#     state = to_numpy(state)\n",
    "\n",
    "#     # Handle multiple boards\n",
    "#     if state.ndim == 3:\n",
    "#         boards_per_row = boards_per_row or state.shape[0]\n",
    "#         kwargs |= dict(facet_col=0, facet_col_wrap=boards_per_row)\n",
    "\n",
    "#     # Handle color coding, depending on the data type\n",
    "#     if state.dtype in [np.int64, np.int32]:\n",
    "#         kwargs |= dict(color_continuous_scale=\"Greys\")\n",
    "#     elif state.max().item() > 0:\n",
    "#         kwargs |= dict(color_continuous_scale=\"RdBu\", color_continuous_midpoint=0.0)\n",
    "#     else:\n",
    "#         kwargs |= dict(color_continuous_scale=\"Blues\")\n",
    "\n",
    "#     # Create the figure\n",
    "#     fig = px.imshow(to_numpy(state), y=list(\"ABCDEFGH\"), x=[str(i) for i in range(8)], aspect=\"equal\", **kwargs)\n",
    "\n",
    "#     # Optionally add board titles\n",
    "#     if board_titles is not None:\n",
    "#         board_titles = reorder_list_in_plotly_way(board_titles, boards_per_row)\n",
    "#         for i, title in enumerate(board_titles):\n",
    "#             fig.layout.annotations[i][\"text\"] = title\n",
    "\n",
    "#     # Optionally add text\n",
    "#     if text is not None:\n",
    "#         text: np.ndarray = np.array(text)\n",
    "#         try:\n",
    "#             text = np.broadcast_to(text, state.shape if state.ndim == 3 else (1, *state.shape))\n",
    "#         except ValueError:\n",
    "#             raise ValueError(f\"Shape mismatch: {text.shape=} should be broadcastable to {state.shape=}\")\n",
    "#         for i, _text in enumerate(text.tolist()):\n",
    "#             fig.data[i].update(text=_text, texttemplate=\"%{text}\", textfont={\"size\": 12})\n",
    "\n",
    "#     # If monochrome mode (just game state) then we hide the color scale\n",
    "#     if state.dtype in [np.int64, np.int32]:\n",
    "#         fig.update_coloraxes(showscale=False)\n",
    "#     if show:\n",
    "#         fig.show()\n",
    "#     if filename is not None:\n",
    "#         fig.write_html(filename)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "import plotly.graph_objects as go  # Make sure to import go\n",
    "import numpy as np  # Make sure to import numpy\n",
    "\n",
    "\n",
    "def plot_board_values(\n",
    "    state: t.Tensor,\n",
    "    board_titles: list[str] | None = None,\n",
    "    boards_per_row: int | None = None,\n",
    "    text: list[str] | list[list[str]] | None = None,\n",
    "    legal_moves_mask: t.Tensor | None = None,  # NEW: Added argument for the red overlay\n",
    "    filename: str | None = None,\n",
    "    show: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes input of shape (*N, 8, 8) and plots it as a board or series of boards. Colors are inferred by tensor values.\n",
    "\n",
    "    Args:\n",
    "        state:           If it's 2D then we plot a single board. If it's 3D then we plot multiple 8x8 boards.\n",
    "        board_titles:    If supplied, we label the boards with these titles. Only valid if state is 3D.\n",
    "        boards_per_row:  If supplied, we show this many boards per row. Only valid if state is 3D.\n",
    "        text:            Should be the same shape as state tensor. Used to add text annotations.\n",
    "        legal_moves_mask: A boolean tensor of the same shape as state, True for legal moves to be colored red.\n",
    "        kwargs:          Get passed into `px.imshow` (e.g. width and height)\n",
    "    \"\"\"\n",
    "    state = to_numpy(state)\n",
    "\n",
    "    # Handle multiple boards\n",
    "    if state.ndim == 3:\n",
    "        boards_per_row = boards_per_row or state.shape[0]\n",
    "        kwargs |= dict(facet_col=0, facet_col_wrap=boards_per_row)\n",
    "\n",
    "    # Handle color coding, depending on the data type\n",
    "    if state.dtype in [np.int64, np.int32]:\n",
    "        # CHANGED: Use 'Greys' to get black (-1), grey (0), and white (1) pieces.\n",
    "        kwargs |= dict(color_continuous_scale=\"Greys\", zmin=-1, zmax=1)\n",
    "    elif state.max().item() > 0:\n",
    "        kwargs |= dict(color_continuous_scale=\"RdBu\", color_continuous_midpoint=0.0)\n",
    "    else:\n",
    "        kwargs |= dict(color_continuous_scale=\"Blues\")\n",
    "\n",
    "    # Create the base figure with the pieces and board\n",
    "    fig = px.imshow(\n",
    "        to_numpy(state),\n",
    "        y=list(\"ABCDEFGH\"),\n",
    "        x=[str(i) for i in range(8)],\n",
    "        aspect=\"equal\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # --- START OF NEW SECTION ---\n",
    "    # NEW: Overlay a second heatmap for legal moves if a mask is provided\n",
    "    if legal_moves_mask is not None:\n",
    "        legal_moves_mask = to_numpy(legal_moves_mask)\n",
    "        if legal_moves_mask.ndim == 2:\n",
    "            legal_moves_mask = np.expand_dims(legal_moves_mask, axis=0)\n",
    "\n",
    "        num_boards = state.shape[0] if state.ndim == 3 else 1\n",
    "\n",
    "        for i in range(num_boards):\n",
    "            # Create a matrix with 1s for legal moves and NaN (transparent) otherwise\n",
    "            z_overlay = np.where(legal_moves_mask[i], 1, np.nan)\n",
    "\n",
    "            # Add the heatmap as a new layer on the correct subplot\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=z_overlay,\n",
    "                    colorscale=[[0, \"#ff0c0c\"], [1, \"#ff0c0c\"]],  # Solid red color\n",
    "                    # colorscale=[[0, \"rgba(255, 12, 12, 0.5)\"], [1, \"rgba(255, 12, 12, 0.5)\"]], # Lighter, semi-transparent red\n",
    "                    showscale=False,\n",
    "                ),\n",
    "                row=(i // boards_per_row) + 1 if state.ndim == 3 else None,\n",
    "                col=(i % boards_per_row) + 1 if state.ndim == 3 else None,\n",
    "            )\n",
    "    # --- END OF NEW SECTION ---\n",
    "\n",
    "    # Optionally add board titles\n",
    "    if board_titles is not None:\n",
    "        board_titles = reorder_list_in_plotly_way(board_titles, boards_per_row)\n",
    "        for i, title in enumerate(board_titles):\n",
    "            fig.layout.annotations[i][\"text\"] = title\n",
    "\n",
    "    # Optionally add text\n",
    "    if text is not None:\n",
    "        text: np.ndarray = np.array(text)\n",
    "        try:\n",
    "            text = np.broadcast_to(\n",
    "                text, state.shape if state.ndim == 3 else (1, *state.shape)\n",
    "            )\n",
    "        except ValueError:\n",
    "            raise ValueError(\n",
    "                f\"Shape mismatch: {text.shape=} should be broadcastable to {state.shape=}\"\n",
    "            )\n",
    "        for i, _text in enumerate(text.tolist()):\n",
    "            fig.data[0].update(\n",
    "                text=_text, texttemplate=\"%{text}\", textfont={\"size\": 12}\n",
    "            )\n",
    "\n",
    "    # If monochrome mode (just game state) then we hide the color scale\n",
    "    if state.dtype in [np.int64, np.int32]:\n",
    "        fig.update_coloraxes(showscale=False)\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if filename is not None:\n",
    "        fig.write_html(filename)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8unPxOD58V0W"
   },
   "source": [
    "### char_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wrnYmJpP8ZFt"
   },
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):  # WSG: Removed the ood_perc\n",
    "    def __init__(self, data):  # Data is from Othello class\n",
    "        assert max([len(data[i]) for i in range(min(len(data), 10000))]) == 60  # WSG\n",
    "\n",
    "        self.stoi = SQUARE_TO_ID  # Maps squares to IDs 1-60, -100 to 0\n",
    "        self.itos = ID_TO_SQUARE\n",
    "        self.vocab_size = 61\n",
    "        self.max_len = 60\n",
    "        self.block_size = 59\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of games.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns the x, y pair generated by the idx-th game.\"\"\"\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx]\n",
    "        if len(chunk) != self.max_len:\n",
    "            chunk += [\n",
    "                -100,\n",
    "            ] * (self.max_len - len(chunk))  # -100 can be ignored in CE\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "\n",
    "        x = t.tensor(dix[:-1], dtype=t.long)\n",
    "        y = t.tensor(dix[1:], dtype=t.long)\n",
    "        y[:2] = 0  # Ignore the first two moves since we train/test split over these\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7ExCwGRXzJh"
   },
   "source": [
    "### process_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MXj_WBqiOXPI"
   },
   "outputs": [],
   "source": [
    "def get_board_states_and_legal_moves(\n",
    "    games_square: Int[Tensor, \"n_games n_moves\"],\n",
    "    othello_rule: OthelloRule,\n",
    ") -> tuple[\n",
    "    Int[Tensor, \"n_games n_moves rows cols\"],\n",
    "    Int[Tensor, \"n_games n_moves rows cols\"],\n",
    "    list,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns the following:\n",
    "        states:                 (n_games, n_moves, 8, 8): tensor of board states after each move\n",
    "        legal_moves:            (n_games, n_moves, 8, 8): tensor of 1s for legal moves, 0s for illegal moves\n",
    "        legal_moves_annotation: (n_games, n_moves, 8, 8): list containing strings of \"o\" for legal moves (for plotting)\n",
    "    \"\"\"\n",
    "    # Create tensors to store the board state & legal moves\n",
    "    n_games, n_moves = games_square.shape\n",
    "    states = t.zeros((n_games, 60, 8, 8), dtype=t.int32)\n",
    "    legal_moves = t.zeros((n_games, 60, 8, 8), dtype=t.int32)\n",
    "\n",
    "    # Loop over each game, populating state & legal moves tensors after each move\n",
    "    for n in range(n_games):\n",
    "        board = OthelloBoardState()\n",
    "        for i in range(n_moves):  #\n",
    "            if othello_rule in [\n",
    "                OthelloRule.STANDARD,\n",
    "                OthelloRule.BIAS_CLOCK,\n",
    "                OthelloRule.CHESS,\n",
    "                OthelloRule.UNTRAINED,\n",
    "                OthelloRule.TINY_STORIES,\n",
    "                OthelloRule.CONSTANT_PARAMETERS,\n",
    "            ]:\n",
    "                board.umpire(games_square[n, i].item())\n",
    "                states[n, i] = t.from_numpy(board.state)\n",
    "                legal_moves[n, i].flatten()[board.get_valid_moves()] = 1\n",
    "            elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                board.place_next_to_opponent(games_square[n, i].item())\n",
    "                states[n, i] = t.from_numpy(board.state)\n",
    "                legal_moves[n, i].flatten()[board.get_moves_next_to_opponent()] = 1\n",
    "            else:\n",
    "                raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "    # Convert legal moves to annotation\n",
    "    legal_moves_annotation = np.where(to_numpy(legal_moves), \"o\", \"\").tolist()\n",
    "\n",
    "    return states, legal_moves, legal_moves_annotation\n",
    "\n",
    "\n",
    "def get_board_seqs_square_and_id(dataset, n_games: int):\n",
    "    \"\"\"dataset has to contain square indices\"\"\"\n",
    "    games_data = [\n",
    "        dataset.data[i] for i in range(min(int(n_games * 1.2), len(dataset.data)))\n",
    "    ]\n",
    "    board_seqs_square = []\n",
    "    board_seqs_id = []\n",
    "    n_skipped = 0\n",
    "    for game in games_data:\n",
    "        if (\n",
    "            len(game) != 60 or -100 in game\n",
    "        ):  # TODO Filtering out -100 here might be sketchy\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        board_seqs_square.append(game)\n",
    "        game_ids = [square_to_id(sq) for sq in game]\n",
    "        board_seqs_id.append(game_ids)\n",
    "\n",
    "    board_seqs_square = t.tensor(board_seqs_square[:n_games], dtype=t.long)\n",
    "    board_seqs_id = t.tensor(board_seqs_id[:n_games], dtype=t.long)\n",
    "    return board_seqs_square, board_seqs_id, n_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSmryN0PM8H_"
   },
   "source": [
    "### analyze_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4VxswhhmM8Qf"
   },
   "outputs": [],
   "source": [
    "def plot_average_move_index(board_seqs_square):\n",
    "    \"\"\"Plot average move index when each position is played\"\"\"\n",
    "    n_games, n_moves = board_seqs_square.shape\n",
    "    move_indices = t.arange(n_moves).unsqueeze(0).expand(n_games, -1)\n",
    "\n",
    "    avg_indices = t.zeros(64)\n",
    "    for square in range(64):\n",
    "        mask = board_seqs_square == square\n",
    "        if mask.any():\n",
    "            avg_indices[square] = move_indices[mask].float().mean()\n",
    "\n",
    "    avg_board = avg_indices.reshape(8, 8)\n",
    "\n",
    "    plot_board_values(\n",
    "        avg_board,\n",
    "        title=\"Average Move Index by Position\",\n",
    "        text=[[f\"{idx:.1f}\" for idx in row] for row in avg_board.tolist()],\n",
    "    )\n",
    "    return avg_board\n",
    "\n",
    "\n",
    "# def plot_game_moves(game: list[int], move_indices: list[int | str], othello_rule: OthelloRule = OthelloRule.STANDARD) -> None:\n",
    "#     \"\"\"\n",
    "#     Input:\n",
    "#     - game: Square Indices (0-63)\n",
    "#     - move_indices: move index (first move is move 0)\n",
    "#     \"\"\"\n",
    "#     game = to_id(game)\n",
    "#     n_moves = len(game)\n",
    "#     board_states = t.zeros((n_moves, 8, 8), dtype=t.int32)\n",
    "#     legal_moves = t.zeros((n_moves, 8, 8), dtype=t.int32)\n",
    "\n",
    "#     board = OthelloBoardState()\n",
    "#     for i, token_id in enumerate(game):\n",
    "#         if othello_rule in [OthelloRule.STANDARD, OthelloRule.BIAS_CLOCK]:\n",
    "#             board.umpire(id_to_square(token_id))\n",
    "#             board_states[i] = t.from_numpy(board.state)  # 8x8 numpy array of 0 (blank), -1 (black), 1 (white)\n",
    "#             legal_moves[i].flatten()[board.get_valid_moves()] = 1\n",
    "#         elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "#             board.place_next_to_opponent(id_to_square(token_id))\n",
    "#             board_states[i] = t.from_numpy(board.state)\n",
    "#             legal_moves[i].flatten()[board.get_moves_next_to_opponent()] = 1\n",
    "#         elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "#             board.place_no_flipping(id_to_square(token_id))\n",
    "#             board_states[i] = t.from_numpy(board.state)\n",
    "#             is_occupied = board.get_occupied()\n",
    "#             empty_moves = [i for i in range(64) if is_occupied[i] == 0]\n",
    "#             legal_moves[i].flatten()[empty_moves] = 1  # Basically it can never be\n",
    "#         else:\n",
    "#             raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "#     selected_board_states = board_states[move_indices]\n",
    "#     selected_legal_moves = legal_moves[move_indices]\n",
    "#     legal_moves_annotation = np.where(to_numpy(selected_legal_moves), \"o\", \"\").tolist()\n",
    "#     # plot_board_values(\n",
    "#     #     selected_board_states,\n",
    "#     #     title=\"Board states\",\n",
    "#     #     width=1000,\n",
    "#     #     boards_per_row=5,\n",
    "#     #     board_titles=[f\"State after move {i}\" for i in move_indices],\n",
    "#     #     text=legal_moves_annotation,\n",
    "#     # )\n",
    "#     display_states = selected_board_states.clone().float() # Use float for custom color scale\n",
    "#     display_states[selected_legal_moves == 1] = 2\n",
    "\n",
    "#     zmin, zmax = -1, 2\n",
    "#     custom_colorscale = [\n",
    "#         [0.0, \"blue\"],                             # Color for value -1 (Black)\n",
    "#         [(0 - zmin) / (zmax - zmin), \"lightgrey\"], # Color for value 0 (Empty)\n",
    "#         [(1 - zmin) / (zmax - zmin), \"red\"],       # Color for value 1 (White)\n",
    "#         [1.0, \"#ff0c0c\"],                          # Color for value 2 (Legal Move)\n",
    "#     ]\n",
    "\n",
    "#     plot_board_values(\n",
    "#         display_states,\n",
    "#         title=\"Board states\",\n",
    "#         width=1000,\n",
    "#         boards_per_row=5,\n",
    "#         board_titles=[f\"State after move {i}\" for i in move_indices],\n",
    "#         color_continuous_scale=custom_colorscale,\n",
    "#         zmin=zmin,\n",
    "#         zmax=zmax, # Pass the new kwargs to override default color logic\n",
    "#     )\n",
    "\n",
    "\n",
    "def plot_game_moves(\n",
    "    game: list[int],\n",
    "    move_indices: list[int | str],\n",
    "    othello_rule: OthelloRule = OthelloRule.STANDARD,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - game: Square Indices (0-63)\n",
    "    - move_indices: move index (first move is move 0)\n",
    "    \"\"\"\n",
    "    game = to_id(game)\n",
    "    n_moves = len(game)\n",
    "    board_states = t.zeros((n_moves, 8, 8), dtype=t.int32)\n",
    "    legal_moves = t.zeros((n_moves, 8, 8), dtype=t.int32)\n",
    "\n",
    "    board = OthelloBoardState()\n",
    "    for i, token_id in enumerate(game):\n",
    "        if othello_rule in [OthelloRule.STANDARD, OthelloRule.BIAS_CLOCK]:\n",
    "            board.umpire(id_to_square(token_id))\n",
    "            board_states[i] = t.from_numpy(\n",
    "                board.state\n",
    "            )  # 8x8 numpy array of 0 (blank), -1 (black), 1 (white)\n",
    "            legal_moves[i].flatten()[board.get_valid_moves()] = 1\n",
    "        elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "            board.place_next_to_opponent(id_to_square(token_id))\n",
    "            board_states[i] = t.from_numpy(board.state)\n",
    "            legal_moves[i].flatten()[board.get_moves_next_to_opponent()] = 1\n",
    "        elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "            board.place_no_flipping(id_to_square(token_id))\n",
    "            board_states[i] = t.from_numpy(board.state)\n",
    "            is_occupied = board.get_occupied()\n",
    "            empty_moves = [i for i in range(64) if is_occupied[i] == 0]\n",
    "            legal_moves[i].flatten()[empty_moves] = 1\n",
    "        else:\n",
    "            raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "    selected_board_states = board_states[move_indices]\n",
    "    selected_legal_moves = legal_moves[move_indices]\n",
    "\n",
    "    # --- CHANGED SECTION ---\n",
    "    # Call the plotting function, passing the board states and legal moves mask separately\n",
    "    plot_board_values(\n",
    "        selected_board_states,  # Use the original board state with values -1, 0, 1\n",
    "        title=\"Board states\",\n",
    "        width=1000,\n",
    "        boards_per_row=5,\n",
    "        board_titles=[f\"State after move {i}\" for i in move_indices],\n",
    "        legal_moves_mask=selected_legal_moves.bool(),  # Pass the legal moves for the red overlay\n",
    "    )\n",
    "    # --- END OF CHANGED SECTION ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyqteaDW9ssL"
   },
   "source": [
    "### computy_entropy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IKNAcKTl4KUF"
   },
   "outputs": [],
   "source": [
    "def calculate_move_probabilities(legal_moves, othello_rule, move_count):\n",
    "    \"\"\"Calculate the probability distribution over legal moves for a given rule\"\"\"\n",
    "    if not legal_moves:\n",
    "        return {}\n",
    "\n",
    "    if othello_rule in [OthelloRule.STANDARD, OthelloRule.NEXT_TO_OPPONENT]:\n",
    "        # Uniform distribution\n",
    "        prob = 1.0 / len(legal_moves)\n",
    "        return {move: prob for move in legal_moves}\n",
    "\n",
    "    elif othello_rule == OthelloRule.BIAS_CLOCK:\n",
    "        probs = {}\n",
    "\n",
    "        if move_count < 2:\n",
    "            # First two moves are random\n",
    "            prob = 1.0 / len(legal_moves)\n",
    "            return {move: prob for move in legal_moves}\n",
    "\n",
    "        # 80% chance of biased move, 20% chance of random\n",
    "        bias_prob = 0.8\n",
    "        random_prob = 0.2\n",
    "\n",
    "        # Calculate corner preference based on move count\n",
    "        corner = move_count % 4\n",
    "\n",
    "        # Find the preferred move for this corner\n",
    "        if corner == 0:  # top-left\n",
    "            preferred_move = min(legal_moves, key=lambda x: (x // 8 + x % 8, x // 8))\n",
    "        elif corner == 1:  # top-right\n",
    "            preferred_move = min(\n",
    "                legal_moves, key=lambda x: (x // 8 + (7 - x % 8), x // 8)\n",
    "            )\n",
    "        elif corner == 2:  # bottom-right\n",
    "            preferred_move = min(\n",
    "                legal_moves, key=lambda x: ((7 - x // 8) + (7 - x % 8), 7 - x // 8)\n",
    "            )\n",
    "        else:  # bottom-left\n",
    "            preferred_move = min(\n",
    "                legal_moves, key=lambda x: ((7 - x // 8) + x % 8, 7 - x // 8)\n",
    "            )\n",
    "\n",
    "        # Calculate probabilities\n",
    "        uniform_prob_per_move = random_prob / len(legal_moves)\n",
    "\n",
    "        for move in legal_moves:\n",
    "            if move == preferred_move:\n",
    "                probs[move] = bias_prob + uniform_prob_per_move\n",
    "            else:\n",
    "                probs[move] = uniform_prob_per_move\n",
    "\n",
    "        return probs\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "\n",
    "def calculate_entropy_from_probabilities(move_probs):\n",
    "    \"\"\"Calculate entropy from a probability distribution\"\"\"\n",
    "    entropy = 0\n",
    "    for prob in move_probs.values():\n",
    "        if prob > 0:\n",
    "            entropy -= prob * np.log(prob)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_legal_move_entropy(dataset, n_games, othello_rule):\n",
    "    \"\"\"Calculate entropy based on the actual move distribution for the given rule\"\"\"\n",
    "    total_entropy = 0\n",
    "    total_positions = 0\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(min(n_games, len(dataset))),\n",
    "        desc=f\"Calculating entropy for {othello_rule.value}\",\n",
    "    ):\n",
    "        x, y = dataset[i]\n",
    "        board = OthelloBoardState()\n",
    "        move_count = 0\n",
    "\n",
    "        for pos in range(len(x)):\n",
    "            if pos < len(y) and y[pos].item() != 0:  # Valid prediction position\n",
    "                if othello_rule in [OthelloRule.STANDARD, OthelloRule.BIAS_CLOCK]:\n",
    "                    legal_moves = board.get_valid_moves()\n",
    "                elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                    legal_moves = board.get_moves_next_to_opponent()\n",
    "                else:\n",
    "                    raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "                if len(legal_moves) > 1:  # Only count when there's choice\n",
    "                    # Calculate probabilities based on the rule\n",
    "                    move_probs = calculate_move_probabilities(\n",
    "                        legal_moves, othello_rule, move_count\n",
    "                    )\n",
    "\n",
    "                    # Calculate entropy from the probability distribution\n",
    "                    entropy = calculate_entropy_from_probabilities(move_probs)\n",
    "                    total_entropy += entropy\n",
    "                    total_positions += 1\n",
    "\n",
    "            # Apply actual move to advance board\n",
    "            if pos < len(x) and x[pos].item() != 0:\n",
    "                actual_square = id_to_square(x[pos].item())\n",
    "                if othello_rule in [OthelloRule.STANDARD, OthelloRule.BIAS_CLOCK]:\n",
    "                    board.umpire(actual_square)\n",
    "                elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                    board.place_next_to_opponent(actual_square)\n",
    "                else:\n",
    "                    raise Exception(f\"Unknown othello rule: {othello_rule}\")\n",
    "\n",
    "                move_count += 1\n",
    "\n",
    "    return total_entropy / total_positions if total_positions > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHdQp6Pl8UZ2"
   },
   "source": [
    "# --- mingpt/ ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuqz9jya8wGF"
   },
   "source": [
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WjfVtvMg8wQz"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPT model:\n",
    "- the initial stem consists of a combination of token encoding and a positional encoding\n",
    "- the meat of it is a uniform sequence of Transformer blocks\n",
    "    - each Transformer is a sequential combination of a 1-hidden-layer MLP block and a self-attention block\n",
    "    - all blocks feed into a central residual pathway similar to resnets\n",
    "- the final decoder is a linear projection into a vanilla Softmax classifier\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GPTConfig:\n",
    "    \"\"\"base GPT config, params common to all GPT versions\"\"\"\n",
    "\n",
    "    embd_pdrop = 0.1\n",
    "    resid_pdrop = 0.1\n",
    "    attn_pdrop = 0.1\n",
    "\n",
    "    def __init__(self, vocab_size, block_size, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use t.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
    "        # output projection\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            t.tril(t.ones(config.block_size, config.block_size)).view(\n",
    "                1, 1, config.block_size, config.block_size\n",
    "            ),\n",
    "        )\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "    def forward(self, x, layer_past=None, only_last=-1):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        k = (\n",
    "            self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        )  # (B, nh, T, hs)\n",
    "        q = (\n",
    "            self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        )  # (B, nh, T, hs)\n",
    "        v = (\n",
    "            self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        )  # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float(\"-inf\"))\n",
    "        if only_last != -1:\n",
    "            att[:, :, -only_last:, :-only_last] = float(\"-inf\")\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = self.attn_drop(att) @ v  # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = (\n",
    "            y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        )  # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_drop(self.proj(y))\n",
    "        return y, att\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"an unassuming Transformer block\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            nn.Dropout(config.resid_pdrop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_att=False, only_last=-1):\n",
    "        updt, att = self.attn(self.ln1(x), only_last=only_last)\n",
    "        x = x + updt\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        if return_att:\n",
    "            return x, att\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\"the full GPT language model, with a context size of block_size\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # input embedding stem\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.pos_emb = nn.Parameter(t.zeros(1, config.block_size, config.n_embd))\n",
    "        self.drop = nn.Dropout(config.embd_pdrop)\n",
    "        # transformer\n",
    "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
    "        self.n_layer = config.n_layer\n",
    "        # decoder head\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        self.block_size = config.block_size\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.block_size\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def configure_optimizers(self, train_config):\n",
    "        \"\"\"\n",
    "        This long function is unfortunately doing something very simple and is being very defensive:\n",
    "        We are separating out all parameters of the model into two buckets: those that will experience\n",
    "        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n",
    "        We are then returning the PyTorch optimizer object.\n",
    "        \"\"\"\n",
    "\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (t.nn.Linear,)\n",
    "        blacklist_weight_modules = (t.nn.LayerNorm, t.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = \"%s.%s\" % (mn, pn) if mn else pn  # full param name\n",
    "\n",
    "                if pn.endswith(\"bias\"):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith(\"weight\") and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith(\"weight\") and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # special case the position embedding parameter in the root GPT module as not decayed\n",
    "        no_decay.add(\"pos_emb\")\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, (\n",
    "            \"parameters %s made it into both decay/no_decay sets!\"\n",
    "            % (str(inter_params),)\n",
    "        )\n",
    "        assert len(param_dict.keys() - union_params) == 0, (\n",
    "            \"parameters %s were not separated into either decay/no_decay set!\"\n",
    "            % (str(param_dict.keys() - union_params),)\n",
    "        )\n",
    "\n",
    "        # create the pytorch optimizer object\n",
    "        optim_groups = [\n",
    "            {\n",
    "                \"params\": [param_dict[pn] for pn in sorted(list(decay))],\n",
    "                \"weight_decay\": train_config.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [param_dict[pn] for pn in sorted(list(no_decay))],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = t.optim.AdamW(\n",
    "            optim_groups, lr=train_config.learning_rate, betas=train_config.betas\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, idx, targets=None, y_soft_weak_supervision=None):\n",
    "        b, t = idx.size()  # both of shape [B, T]\n",
    "        assert t <= self.block_size, \"Cannot forward, model block size is exhausted.\"\n",
    "\n",
    "        # forward the GPT model\n",
    "        token_embeddings = self.tok_emb(idx)  # each index maps to a (learnable) vector\n",
    "        position_embeddings = self.pos_emb[\n",
    "            :, :t, :\n",
    "        ]  # each position maps to a (learnable) vector\n",
    "        x = self.drop(token_embeddings + position_embeddings)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)  # [B, T, f]\n",
    "        logits = self.head(x)  # [B, T, # Words]\n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            if y_soft_weak_supervision is not None:\n",
    "                mask = (targets != 0).float()  # [B, T]\n",
    "\n",
    "                # Reshape\n",
    "                logits_flat = logits.view(-1, logits.size(-1))  # [B*T, vocab_size]\n",
    "                soft_targets_flat = y_soft_weak_supervision.view(\n",
    "                    -1, y_soft_weak_supervision.size(-1)\n",
    "                )  # [B*T, vocab_size]\n",
    "                mask_flat = mask.view(-1)  # [B*T]\n",
    "\n",
    "                # Softmax with soft labels\n",
    "                loss_per_token = F.cross_entropy(\n",
    "                    logits_flat, soft_targets_flat, reduction=\"none\"\n",
    "                )  # [B*T]\n",
    "\n",
    "                # Apply mask to ignore pass tokens\n",
    "                masked_loss = loss_per_token * mask_flat\n",
    "                if mask_flat.sum() > 0:\n",
    "                    loss = masked_loss.sum() / mask_flat.sum()\n",
    "                else:\n",
    "                    loss = 0\n",
    "            else:\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0\n",
    "                )  # -100 in the string space is mapped to 0 in the index space\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQl3qrr8SV5Z"
   },
   "source": [
    "### create_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4iOlCuVL3tmc"
   },
   "outputs": [],
   "source": [
    "class ModelSize(Enum):\n",
    "    NANO = \"nano\"\n",
    "    MICRO = \"micro\"\n",
    "    MINI = \"mini\"\n",
    "    SMALL = \"small\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LARGE = \"large\"\n",
    "    HUGE = \"huge\"\n",
    "\n",
    "\n",
    "def get_weak_strong_pairs():\n",
    "    ordered_sizes = [\n",
    "        ModelSize.NANO,\n",
    "        ModelSize.MICRO,\n",
    "        ModelSize.MINI,\n",
    "        ModelSize.SMALL,\n",
    "        ModelSize.MEDIUM,\n",
    "        ModelSize.LARGE,\n",
    "        ModelSize.HUGE,\n",
    "    ]\n",
    "    all_sizes = set(ModelSize)\n",
    "    assert set(ordered_sizes) == all_sizes, (\n",
    "        f\"Missing sizes: {all_sizes - set(ordered_sizes)}\"\n",
    "    )\n",
    "\n",
    "    # Generate (weak, strong) pairs where weak < strong\n",
    "    pairs = []\n",
    "    for i, weak in enumerate(ordered_sizes):\n",
    "        for strong in ordered_sizes[i + 1 :]:\n",
    "            pairs.append((weak, strong))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_model_sizes():\n",
    "    model_sizes = {}\n",
    "    model_sizes[ModelSize.NANO] = {\n",
    "        \"n_layer\": 1,\n",
    "        \"n_head\": 1,\n",
    "        \"n_embd\": 7,\n",
    "    }\n",
    "    model_sizes[ModelSize.MICRO] = {\n",
    "        \"n_layer\": 1,\n",
    "        \"n_head\": 2,\n",
    "        \"n_embd\": 20,\n",
    "    }\n",
    "    model_sizes[ModelSize.MINI] = {\n",
    "        \"n_layer\": 2,\n",
    "        \"n_head\": 2,\n",
    "        \"n_embd\": 38,\n",
    "    }\n",
    "    model_sizes[ModelSize.SMALL] = {\n",
    "        \"n_layer\": 3,\n",
    "        \"n_head\": 3,\n",
    "        \"n_embd\": 72,\n",
    "    }\n",
    "    model_sizes[ModelSize.MEDIUM] = {\n",
    "        \"n_layer\": 4,\n",
    "        \"n_head\": 5,\n",
    "        \"n_embd\": 140,\n",
    "    }\n",
    "    model_sizes[ModelSize.LARGE] = {\n",
    "        \"n_layer\": 6,\n",
    "        \"n_head\": 6,\n",
    "        \"n_embd\": 264,\n",
    "    }\n",
    "    model_sizes[ModelSize.HUGE] = {\n",
    "        \"n_layer\": 8,\n",
    "        \"n_head\": 8,\n",
    "        \"n_embd\": 512,\n",
    "    }\n",
    "    return model_sizes\n",
    "\n",
    "\n",
    "def get_model_config(model_size: ModelSize, train_dataset):\n",
    "    size_params = get_model_sizes()[model_size]\n",
    "    return GPTConfig(\n",
    "        train_dataset.vocab_size,\n",
    "        train_dataset.block_size,\n",
    "        n_layer=size_params[\"n_layer\"],\n",
    "        n_head=size_params[\"n_head\"],\n",
    "        n_embd=size_params[\"n_embd\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def format_integer_scientific(n: float) -> str:\n",
    "    s = f\"{n:.1e}\"\n",
    "    return s.replace(\"e+\", \" * 10^\")\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def print_model_ratios(train_dataset) -> None:\n",
    "    last = 0\n",
    "    ratios = []\n",
    "    for model_size in ModelSize:\n",
    "        cfg = get_model_config(model_size, train_dataset)\n",
    "        model = GPT(cfg)\n",
    "        n = count_parameters(model)\n",
    "        if last != 0:\n",
    "            ratios.append(n / last)\n",
    "        last = n\n",
    "        print(model_size, format_integer_scientific(n))\n",
    "        del model\n",
    "    print(\"Ratio of consecutive model-sizes: \", ratios)\n",
    "\n",
    "\n",
    "# print_model_ratios(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOj-51o88zVd"
   },
   "source": [
    "### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nF8ChLr38zdB"
   },
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    \"\"\"Sets all logits that are not in the top k to -inf.\"\"\"\n",
    "    v, ix = t.topk(logits, k)\n",
    "    out = logits.clone()\n",
    "    out[out < v[:, [-1]]] = -float(\"Inf\")\n",
    "    return out\n",
    "\n",
    "\n",
    "@t.no_grad()\n",
    "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):\n",
    "    \"\"\"\n",
    "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
    "    the sequence, feeding the predictions back into the model each time. Clearly the sampling\n",
    "    has quadratic complexity unlike an RNN that is only linear, and has a finite context window\n",
    "    of block_size, unlike an RNN that has an infinite context window.\n",
    "    \"\"\"\n",
    "    block_size = model.get_block_size()\n",
    "    model.eval()\n",
    "    for k in range(steps):\n",
    "        x_cond = (\n",
    "            x if x.size(1) <= block_size else x[:, -block_size:]\n",
    "        )  # crop context if needed\n",
    "        logits, _ = model(x_cond)\n",
    "        # pluck the logits at the final step and scale by temperature\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop probabilities to only the top k options\n",
    "        if top_k is not None:\n",
    "            logits = top_k_logits(logits, top_k)\n",
    "        # apply softmax to convert to probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # sample from the distribution or take the most likely\n",
    "        if sample:\n",
    "            ix = t.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            _, ix = t.topk(probs, k=1, dim=-1)\n",
    "        # append to the sequence and continue\n",
    "        x = t.cat((x, ix), dim=1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    model_size_mb = total_params * 4 / (1024 * 1024)\n",
    "    print(f\"Model size: {model_size_mb:.1f} MB\")\n",
    "    if t.cuda.is_available():\n",
    "        print(f\"GPU memory: {t.cuda.memory_allocated() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjTXE9OjZIrm"
   },
   "source": [
    "### convert_gpt_and_hooked.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XN3HTkKmAVWU"
   },
   "outputs": [],
   "source": [
    "def convert_gpt_to_hooked(gpt_model, gpt_config):\n",
    "    \"\"\"Convert custom GPT model to HookedTransformer using built-in converter\"\"\"\n",
    "    # Create HookedTransformer config\n",
    "    hooked_config = HookedTransformerConfig(\n",
    "        n_layers=gpt_config.n_layer,\n",
    "        d_model=gpt_config.n_embd,\n",
    "        d_head=gpt_config.n_embd // gpt_config.n_head,\n",
    "        n_heads=gpt_config.n_head,\n",
    "        d_mlp=4 * gpt_config.n_embd,\n",
    "        d_vocab=gpt_config.vocab_size,\n",
    "        n_ctx=gpt_config.block_size,\n",
    "        act_fn=\"gelu\",\n",
    "        normalization_type=\"LN\",\n",
    "        positional_embedding_type=\"standard\",\n",
    "    )\n",
    "\n",
    "    # Create HookedTransformer\n",
    "    hooked_model = HookedTransformer(hooked_config)\n",
    "\n",
    "    # Use built-in converter\n",
    "    hooked_state_dict = convert_mingpt_weights(gpt_model.state_dict(), hooked_config)\n",
    "    hooked_model.load_state_dict(hooked_state_dict, strict=False)\n",
    "\n",
    "    return hooked_model\n",
    "\n",
    "\n",
    "def verify_identical_outputs(model_1, model_2, test_input):\n",
    "    \"\"\"Verify both models produce identical outputs\"\"\"\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "\n",
    "    with t.no_grad():\n",
    "        gpt_logits, _ = model_1(test_input)\n",
    "        hooked_logits = model_2(test_input)\n",
    "\n",
    "        mean_diff = (gpt_logits - hooked_logits).abs().mean().item()\n",
    "        if mean_diff > 1e-4:\n",
    "            print(f\"Mean difference between outputs: {mean_diff}\")\n",
    "\n",
    "\n",
    "def convert_gpt_to_hooked_and_verify(\n",
    "    model, conf, val_dataset, device=\"cuda\", n_samples=100\n",
    "):\n",
    "    model = model.to(device)\n",
    "    hooked_model = convert_gpt_to_hooked(model, conf)\n",
    "    hooked_model = hooked_model.to(device)\n",
    "    test_inputs = t.stack([val_dataset[i][0] for i in range(n_samples)]).to(device)\n",
    "    verify_identical_outputs(model, hooked_model, test_inputs)\n",
    "    return hooked_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7arj-ecp3KpV"
   },
   "outputs": [],
   "source": [
    "def convert_hooked_state_dict_to_gpt(hooked_model, gpt_config):\n",
    "    \"\"\"\n",
    "    Convert HookedTransformer state dict to GPT state dict.\n",
    "\n",
    "    This reverses the convert_mingpt_weights function from transformer_lens.\n",
    "    \"\"\"\n",
    "    hooked_state_dict = hooked_model.state_dict()\n",
    "    gpt_state_dict = {}\n",
    "\n",
    "    # Token embeddings\n",
    "    gpt_state_dict[\"tok_emb.weight\"] = hooked_state_dict[\"embed.W_E\"]\n",
    "\n",
    "    # Position embeddings: [n_ctx, d_model] -> [1, n_ctx, d_model]\n",
    "    gpt_state_dict[\"pos_emb\"] = hooked_state_dict[\"pos_embed.W_pos\"].unsqueeze(0)\n",
    "\n",
    "    # Convert transformer blocks\n",
    "    for layer_idx in range(gpt_config.n_layer):\n",
    "        hooked_prefix = f\"blocks.{layer_idx}\"\n",
    "        gpt_prefix = f\"blocks.{layer_idx}\"\n",
    "\n",
    "        # Layer norms\n",
    "        if hooked_model.cfg.normalization_type == \"LNPre\":\n",
    "            # Set identity LayerNorm (w=1, b=0)\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln1.weight\"] = t.ones(gpt_config.n_embd)\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln1.bias\"] = t.zeros(gpt_config.n_embd)\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln2.weight\"] = t.ones(gpt_config.n_embd)\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln2.bias\"] = t.zeros(gpt_config.n_embd)\n",
    "        else:\n",
    "            # Use existing parameters\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln1.weight\"] = hooked_state_dict[\n",
    "                f\"{hooked_prefix}.ln1.w\"\n",
    "            ]\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln1.bias\"] = hooked_state_dict[\n",
    "                f\"{hooked_prefix}.ln1.b\"\n",
    "            ]\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln2.weight\"] = hooked_state_dict[\n",
    "                f\"{hooked_prefix}.ln2.w\"\n",
    "            ]\n",
    "            gpt_state_dict[f\"{gpt_prefix}.ln2.bias\"] = hooked_state_dict[\n",
    "                f\"{hooked_prefix}.ln2.b\"\n",
    "            ]\n",
    "\n",
    "        # Attention weights\n",
    "        # The key insight: convert_mingpt_weights splits the GPT combined QKV into separate Q,K,V\n",
    "        # So we need to do the reverse: combine separate Q,K,V back into the GPT format\n",
    "\n",
    "        n_heads = gpt_config.n_head\n",
    "        d_model = gpt_config.n_embd\n",
    "        d_head = d_model // n_heads\n",
    "\n",
    "        # Get the separate Q, K, V weights: each is [n_heads, d_model, d_head]\n",
    "        W_Q = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.attn.W_Q\"\n",
    "        ]  # [n_heads, d_model, d_head]\n",
    "        W_K = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.attn.W_K\"\n",
    "        ]  # [n_heads, d_model, d_head]\n",
    "        W_V = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.attn.W_V\"\n",
    "        ]  # [n_heads, d_model, d_head]\n",
    "\n",
    "        # The way convert_mingpt_weights does it (in reverse):\n",
    "        # It reshapes [d_model, d_model] to [n_heads, d_model, d_head] for each of Q,K,V\n",
    "        # So we need to reshape back: [n_heads, d_model, d_head] -> [d_model, d_model]\n",
    "\n",
    "        # Reshape each: [n_heads, d_model, d_head] -> [d_model, n_heads * d_head] = [d_model, d_model]\n",
    "        W_Q_reshaped = W_Q.transpose(0, 1).reshape(\n",
    "            d_model, d_model\n",
    "        )  # [d_model, d_model]\n",
    "        W_K_reshaped = W_K.transpose(0, 1).reshape(\n",
    "            d_model, d_model\n",
    "        )  # [d_model, d_model]\n",
    "        W_V_reshaped = W_V.transpose(0, 1).reshape(\n",
    "            d_model, d_model\n",
    "        )  # [d_model, d_model]\n",
    "\n",
    "        # Transpose for Linear layer weight format [out_features, in_features]\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.query.weight\"] = W_Q_reshaped.T\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.key.weight\"] = W_K_reshaped.T\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.value.weight\"] = W_V_reshaped.T\n",
    "\n",
    "        # Attention biases\n",
    "        # Get separate biases: each is [n_heads, d_head]\n",
    "        b_Q = hooked_state_dict[f\"{hooked_prefix}.attn.b_Q\"]  # [n_heads, d_head]\n",
    "        b_K = hooked_state_dict[f\"{hooked_prefix}.attn.b_K\"]  # [n_heads, d_head]\n",
    "        b_V = hooked_state_dict[f\"{hooked_prefix}.attn.b_V\"]  # [n_heads, d_head]\n",
    "\n",
    "        # Reshape: [n_heads, d_head] -> [n_heads * d_head] = [d_model]\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.query.bias\"] = b_Q.reshape(-1)\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.key.bias\"] = b_K.reshape(-1)\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.value.bias\"] = b_V.reshape(-1)\n",
    "\n",
    "        # Attention output projection W_O\n",
    "        W_O = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.attn.W_O\"\n",
    "        ]  # [n_heads, d_head, d_model]\n",
    "\n",
    "        # Reshape: [n_heads, d_head, d_model] -> [n_heads * d_head, d_model] = [d_model, d_model]\n",
    "        W_O_reshaped = W_O.reshape(n_heads * d_head, d_model)  # [d_model, d_model]\n",
    "\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.proj.weight\"] = W_O_reshaped.T\n",
    "\n",
    "        # Attention output bias\n",
    "        gpt_state_dict[f\"{gpt_prefix}.attn.proj.bias\"] = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.attn.b_O\"\n",
    "        ]\n",
    "\n",
    "        # MLP weights\n",
    "        gpt_state_dict[f\"{gpt_prefix}.mlp.0.weight\"] = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.mlp.W_in\"\n",
    "        ].T\n",
    "        gpt_state_dict[f\"{gpt_prefix}.mlp.2.weight\"] = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.mlp.W_out\"\n",
    "        ].T\n",
    "\n",
    "        # MLP biases\n",
    "        gpt_state_dict[f\"{gpt_prefix}.mlp.0.bias\"] = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.mlp.b_in\"\n",
    "        ]\n",
    "        gpt_state_dict[f\"{gpt_prefix}.mlp.2.bias\"] = hooked_state_dict[\n",
    "            f\"{hooked_prefix}.mlp.b_out\"\n",
    "        ]\n",
    "\n",
    "    # Final layer norm\n",
    "    # Final layer norm\n",
    "    if hooked_model.cfg.normalization_type == \"LNPre\":\n",
    "        gpt_state_dict[\"ln_f.weight\"] = t.ones(gpt_config.n_embd)\n",
    "        gpt_state_dict[\"ln_f.bias\"] = t.zeros(gpt_config.n_embd)\n",
    "    else:\n",
    "        gpt_state_dict[\"ln_f.weight\"] = hooked_state_dict[\"ln_final.w\"]\n",
    "        gpt_state_dict[\"ln_f.bias\"] = hooked_state_dict[\"ln_final.b\"]\n",
    "\n",
    "    # Output head (unembedding)\n",
    "    gpt_state_dict[\"head.weight\"] = hooked_state_dict[\"unembed.W_U\"].T\n",
    "\n",
    "    return gpt_state_dict\n",
    "\n",
    "\n",
    "def convert_hooked_to_gpt(hooked_model, device):\n",
    "    \"\"\"\n",
    "    Convert HookedTransformer model back to custom GPT model format.\n",
    "    Returns: (gpt_model, gpt_config)\n",
    "    \"\"\"\n",
    "    hooked_config = hooked_model.cfg\n",
    "    gpt_config = GPTConfig(\n",
    "        vocab_size=hooked_config.d_vocab,\n",
    "        block_size=hooked_config.n_ctx,\n",
    "        n_layer=hooked_config.n_layers,\n",
    "        n_head=hooked_config.n_heads,\n",
    "        n_embd=hooked_config.d_model,\n",
    "    )\n",
    "    gpt_model = GPT(gpt_config)\n",
    "    gpt_model.to(device)\n",
    "    gpt_state_dict = convert_hooked_state_dict_to_gpt(hooked_model, gpt_config)\n",
    "\n",
    "    # Load state dict with strict=False to ignore missing mask buffers and unexpected bias\n",
    "    missing_keys, unexpected_keys = gpt_model.load_state_dict(\n",
    "        gpt_state_dict, strict=False\n",
    "    )\n",
    "    # assert len(missing_keys) == 0, f\"Missing keys: {missing_keys}\"\n",
    "    # assert len(unexpected_keys) == 0, f\"Unexpected keys: {unexpected_keys}\"\n",
    "\n",
    "    return gpt_model, gpt_config\n",
    "\n",
    "\n",
    "def convert_hooked_to_gpt_and_verify(hooked_model, val_dataset, device, n_samples=100):\n",
    "    gpt_model, gpt_config = convert_hooked_to_gpt(hooked_model, device)\n",
    "    gpt_model = gpt_model.to(device)\n",
    "    test_inputs = t.stack([val_dataset[i][0] for i in range(n_samples)]).to(device)\n",
    "    verify_identical_outputs(gpt_model, hooked_model, test_inputs)\n",
    "    return gpt_model, gpt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rE6KxMK4Lgkz"
   },
   "outputs": [],
   "source": [
    "# https://github.com/adamkarvonen/chess_llm_interpretability/blob/main/utils/nanogpt_to_transformer_lens.ipynb\n",
    "\n",
    "\n",
    "def convert_nanogpt_weights(\n",
    "    old_state_dict, cfg: HookedTransformerConfig, bias: bool = False, device=\"cpu\"\n",
    "):\n",
    "    \"\"\"For https://github.com/karpathy/nanoGPT\n",
    "    There are two complications with converting nanogpt models:\n",
    "    The first is that some state dicts have an unwanted prefix on keys that needs to be removed.\n",
    "    The second is that the models can be saved with or without bias. By default, there\n",
    "    is no bias. This function can handle both cases.\"\"\"\n",
    "    # Nanogpt models saved after torch.compile() have this unwanted prefix\n",
    "    # This is a simple way to remove it\n",
    "    unwanted_prefix = \"_orig_mod.\"\n",
    "    for k, v in list(old_state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            old_state_dict[k[len(unwanted_prefix) :]] = old_state_dict.pop(k)\n",
    "\n",
    "    new_state_dict = {}\n",
    "    new_state_dict[\"pos_embed.W_pos\"] = old_state_dict[\"transformer.wpe.weight\"]\n",
    "    new_state_dict[\"embed.W_E\"] = old_state_dict[\"transformer.wte.weight\"]\n",
    "\n",
    "    new_state_dict[\"ln_final.w\"] = old_state_dict[\"transformer.ln_f.weight\"]\n",
    "    new_state_dict[\"ln_final.b\"] = t.zeros_like(\n",
    "        old_state_dict[\"transformer.ln_f.weight\"]\n",
    "    )\n",
    "    new_state_dict[\"unembed.W_U\"] = old_state_dict[\"lm_head.weight\"].T\n",
    "\n",
    "    if bias:\n",
    "        new_state_dict[\"ln_final.b\"] = old_state_dict[\"transformer.ln_f.bias\"]\n",
    "\n",
    "    for layer in range(cfg.n_layers):\n",
    "        layer_key = f\"transformer.h.{layer}\"\n",
    "\n",
    "        new_state_dict[f\"blocks.{layer}.ln1.w\"] = old_state_dict[\n",
    "            f\"{layer_key}.ln_1.weight\"\n",
    "        ]\n",
    "        # A bias of zeros is required for folding layer norm\n",
    "        new_state_dict[f\"blocks.{layer}.ln1.b\"] = t.zeros_like(\n",
    "            old_state_dict[f\"{layer_key}.ln_1.weight\"]\n",
    "        )\n",
    "        new_state_dict[f\"blocks.{layer}.ln2.w\"] = old_state_dict[\n",
    "            f\"{layer_key}.ln_2.weight\"\n",
    "        ]\n",
    "        new_state_dict[f\"blocks.{layer}.ln2.b\"] = t.zeros_like(\n",
    "            old_state_dict[f\"{layer_key}.ln_2.weight\"]\n",
    "        )\n",
    "\n",
    "        W = old_state_dict[f\"{layer_key}.attn.c_attn.weight\"]\n",
    "        W_Q, W_K, W_V = t.tensor_split(W, 3, dim=0)\n",
    "        W_Q = einops.rearrange(W_Q, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        W_K = einops.rearrange(W_K, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        W_V = einops.rearrange(W_V, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        new_state_dict[f\"blocks.{layer}.attn.W_Q\"] = W_Q\n",
    "        new_state_dict[f\"blocks.{layer}.attn.W_K\"] = W_K\n",
    "        new_state_dict[f\"blocks.{layer}.attn.W_V\"] = W_V\n",
    "\n",
    "        W_O = old_state_dict[f\"{layer_key}.attn.c_proj.weight\"]\n",
    "        W_O = einops.rearrange(W_O, \"m (i h)->i h m\", i=cfg.n_heads)\n",
    "        new_state_dict[f\"blocks.{layer}.attn.W_O\"] = W_O\n",
    "\n",
    "        new_state_dict[f\"blocks.{layer}.mlp.W_in\"] = old_state_dict[\n",
    "            f\"{layer_key}.mlp.c_fc.weight\"\n",
    "        ].T\n",
    "        new_state_dict[f\"blocks.{layer}.mlp.W_out\"] = old_state_dict[\n",
    "            f\"{layer_key}.mlp.c_proj.weight\"\n",
    "        ].T\n",
    "\n",
    "        if bias:\n",
    "            new_state_dict[f\"blocks.{layer}.ln1.b\"] = old_state_dict[\n",
    "                f\"{layer_key}.ln_1.bias\"\n",
    "            ]\n",
    "            new_state_dict[f\"blocks.{layer}.ln2.b\"] = old_state_dict[\n",
    "                f\"{layer_key}.ln_2.bias\"\n",
    "            ]\n",
    "            new_state_dict[f\"blocks.{layer}.mlp.b_in\"] = old_state_dict[\n",
    "                f\"{layer_key}.mlp.c_fc.bias\"\n",
    "            ]\n",
    "            new_state_dict[f\"blocks.{layer}.mlp.b_out\"] = old_state_dict[\n",
    "                f\"{layer_key}.mlp.c_proj.bias\"\n",
    "            ]\n",
    "\n",
    "            B = old_state_dict[f\"{layer_key}.attn.c_attn.bias\"]\n",
    "            B_Q, B_K, B_V = t.tensor_split(B, 3, dim=0)\n",
    "            B_Q = einops.rearrange(B_Q, \"(i h)->i h\", i=cfg.n_heads)\n",
    "            B_K = einops.rearrange(B_K, \"(i h)->i h\", i=cfg.n_heads)\n",
    "            B_V = einops.rearrange(B_V, \"(i h)->i h\", i=cfg.n_heads)\n",
    "            new_state_dict[f\"blocks.{layer}.attn.b_Q\"] = B_Q\n",
    "            new_state_dict[f\"blocks.{layer}.attn.b_K\"] = B_K\n",
    "            new_state_dict[f\"blocks.{layer}.attn.b_V\"] = B_V\n",
    "            new_state_dict[f\"blocks.{layer}.attn.b_O\"] = old_state_dict[\n",
    "                f\"{layer_key}.attn.c_proj.bias\"\n",
    "            ]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def convert_nanogpt_to_hooked_and_verify(nanogpt_model_dict, device):\n",
    "    # for name, param in nanogpt_model_dict.items():\n",
    "    #     if name.startswith(\"transformer.h.0\") or not name.startswith(\"transformer.h\"):\n",
    "    #         print(name, param.shape)\n",
    "\n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers=8,\n",
    "        d_model=512,\n",
    "        d_head=64,\n",
    "        n_heads=8,\n",
    "        d_mlp=2048,\n",
    "        d_vocab=32,\n",
    "        n_ctx=1023,\n",
    "        act_fn=\"gelu\",\n",
    "        normalization_type=\"LNPre\",\n",
    "    )\n",
    "    model = HookedTransformer(cfg)\n",
    "    model.load_and_process_state_dict(\n",
    "        convert_nanogpt_weights(nanogpt_model_dict, cfg, bias=True, device=device)\n",
    "    )\n",
    "    sample_input = t.tensor(\n",
    "        [\n",
    "            [\n",
    "                6,\n",
    "                4,\n",
    "                27,\n",
    "                9,\n",
    "                0,\n",
    "                27,\n",
    "                11,\n",
    "                0,\n",
    "                7,\n",
    "                4,\n",
    "                19,\n",
    "                28,\n",
    "                8,\n",
    "                0,\n",
    "                26,\n",
    "                10,\n",
    "                0,\n",
    "                8,\n",
    "                4,\n",
    "                19,\n",
    "                25,\n",
    "                8,\n",
    "                0,\n",
    "                26,\n",
    "                9,\n",
    "                0,\n",
    "                9,\n",
    "                4,\n",
    "                19,\n",
    "                27,\n",
    "                7,\n",
    "                0,\n",
    "                25,\n",
    "                10,\n",
    "                0,\n",
    "                10,\n",
    "                4,\n",
    "                25,\n",
    "                8,\n",
    "                0,\n",
    "                26,\n",
    "                8,\n",
    "                0,\n",
    "                11,\n",
    "                4,\n",
    "                19,\n",
    "                28,\n",
    "                9,\n",
    "                0,\n",
    "                25,\n",
    "                9,\n",
    "                0,\n",
    "                12,\n",
    "                4,\n",
    "                21,\n",
    "                23,\n",
    "                9,\n",
    "                2,\n",
    "                0,\n",
    "                17,\n",
    "                26,\n",
    "                12,\n",
    "                0,\n",
    "                13,\n",
    "                4,\n",
    "                21,\n",
    "                31,\n",
    "                25,\n",
    "                9,\n",
    "                0,\n",
    "                19,\n",
    "                28,\n",
    "                11,\n",
    "                0,\n",
    "                14,\n",
    "                4,\n",
    "                27,\n",
    "                10,\n",
    "                0,\n",
    "                19,\n",
    "                29,\n",
    "                9,\n",
    "                0,\n",
    "                6,\n",
    "                5,\n",
    "                4,\n",
    "                30,\n",
    "                8,\n",
    "                0,\n",
    "                19,\n",
    "                31,\n",
    "                28,\n",
    "                7,\n",
    "                0,\n",
    "                6,\n",
    "                6,\n",
    "                4,\n",
    "                18,\n",
    "                31,\n",
    "                28,\n",
    "                7,\n",
    "                0,\n",
    "                21,\n",
    "                24,\n",
    "                11,\n",
    "                2,\n",
    "                0,\n",
    "                6,\n",
    "                7,\n",
    "                4,\n",
    "                18,\n",
    "                27,\n",
    "                6,\n",
    "                0,\n",
    "                17,\n",
    "                24,\n",
    "                10,\n",
    "                0,\n",
    "                6,\n",
    "                8,\n",
    "                4,\n",
    "                21,\n",
    "                25,\n",
    "                13,\n",
    "                2,\n",
    "                0,\n",
    "                18,\n",
    "                27,\n",
    "                12,\n",
    "                0,\n",
    "                6,\n",
    "                9,\n",
    "                4,\n",
    "                17,\n",
    "                31,\n",
    "                26,\n",
    "                8,\n",
    "                0,\n",
    "                17,\n",
    "                26,\n",
    "                12,\n",
    "                0,\n",
    "                6,\n",
    "                10,\n",
    "                4,\n",
    "                21,\n",
    "                25,\n",
    "                9,\n",
    "                0,\n",
    "                19,\n",
    "                25,\n",
    "                11,\n",
    "                0,\n",
    "                6,\n",
    "                11,\n",
    "                4,\n",
    "                17,\n",
    "                27,\n",
    "                9,\n",
    "                0,\n",
    "                22,\n",
    "                25,\n",
    "                13,\n",
    "                0,\n",
    "                6,\n",
    "                12,\n",
    "                4,\n",
    "                21,\n",
    "                24,\n",
    "                8,\n",
    "                0,\n",
    "                21,\n",
    "                25,\n",
    "                12,\n",
    "                0,\n",
    "                6,\n",
    "                13,\n",
    "                4,\n",
    "                26,\n",
    "                9,\n",
    "                0,\n",
    "                22,\n",
    "                24,\n",
    "                13,\n",
    "                0,\n",
    "                6,\n",
    "                14,\n",
    "                4,\n",
    "                17,\n",
    "                27,\n",
    "                8,\n",
    "                0,\n",
    "                19,\n",
    "                23,\n",
    "                10,\n",
    "                0,\n",
    "                7,\n",
    "                5,\n",
    "                4,\n",
    "                21,\n",
    "                26,\n",
    "                6,\n",
    "                0,\n",
    "                29,\n",
    "                11,\n",
    "                0,\n",
    "                7,\n",
    "                6,\n",
    "                4,\n",
    "                17,\n",
    "                26,\n",
    "                8,\n",
    "                0,\n",
    "                17,\n",
    "                29,\n",
    "                12,\n",
    "                0,\n",
    "                7,\n",
    "                7,\n",
    "                4,\n",
    "                22,\n",
    "                28,\n",
    "                6,\n",
    "                0,\n",
    "                19,\n",
    "                25,\n",
    "                11,\n",
    "                0,\n",
    "                7,\n",
    "                8,\n",
    "                4,\n",
    "                18,\n",
    "                28,\n",
    "                7,\n",
    "                0,\n",
    "                22,\n",
    "                30,\n",
    "                27,\n",
    "                13,\n",
    "                0,\n",
    "                7,\n",
    "                9,\n",
    "                4,\n",
    "                18,\n",
    "                29,\n",
    "                6,\n",
    "                0,\n",
    "                30,\n",
    "                11,\n",
    "                0,\n",
    "                7,\n",
    "                10,\n",
    "                4,\n",
    "                22,\n",
    "                25,\n",
    "                6,\n",
    "                0,\n",
    "                29,\n",
    "                10,\n",
    "                0,\n",
    "                7,\n",
    "                11,\n",
    "                4,\n",
    "                19,\n",
    "                30,\n",
    "                10,\n",
    "                0,\n",
    "                17,\n",
    "                30,\n",
    "                13,\n",
    "                0,\n",
    "                7,\n",
    "                12,\n",
    "                4,\n",
    "                19,\n",
    "                26,\n",
    "                7,\n",
    "                0,\n",
    "                21,\n",
    "                24,\n",
    "                11,\n",
    "                0,\n",
    "                7,\n",
    "                13,\n",
    "                4,\n",
    "                19,\n",
    "                28,\n",
    "                11,\n",
    "                0,\n",
    "                22,\n",
    "                27,\n",
    "                26,\n",
    "                13,\n",
    "                0,\n",
    "                7,\n",
    "                14,\n",
    "                4,\n",
    "                19,\n",
    "                31,\n",
    "                26,\n",
    "                12,\n",
    "                0,\n",
    "                22,\n",
    "                31,\n",
    "                26,\n",
    "                12,\n",
    "                0,\n",
    "                8,\n",
    "                5,\n",
    "                4,\n",
    "                21,\n",
    "                28,\n",
    "                8,\n",
    "                0,\n",
    "                21,\n",
    "                31,\n",
    "                24,\n",
    "                7,\n",
    "                0,\n",
    "                8,\n",
    "                6,\n",
    "                4,\n",
    "                21,\n",
    "                31,\n",
    "                28,\n",
    "                12,\n",
    "                2,\n",
    "                0,\n",
    "                18,\n",
    "                26,\n",
    "                13,\n",
    "                0,\n",
    "                8,\n",
    "                7,\n",
    "                4,\n",
    "                21,\n",
    "                28,\n",
    "                13,\n",
    "                2,\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    model(sample_input)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vS-ZcVE_clMs"
   },
   "outputs": [],
   "source": [
    "# For models with \"LN\", 1e-5 error, if \"LNPre\", then 0.06 (othello_gpt) -> small error\n",
    "# But if we only use them for finetuning, it should be fine.\n",
    "\n",
    "# othello_gpt = load_othello_gpt()\n",
    "# loaded_hooked_model = load_tiny_stories_instruct_8m(DEVICE)\n",
    "# gpt_model, gpt_config = convert_hooked_to_gpt_and_verify(loaded_hooked_model, val_dataset, DEVICE)\n",
    "# hooked_model = convert_gpt_to_hooked_and_verify(gpt_model, gpt_config, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agBm7yQHYXAp"
   },
   "source": [
    "### load_pretrained_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9aCqWiFnYXQL"
   },
   "outputs": [],
   "source": [
    "def load_othello_gpt(device):\n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers=8,\n",
    "        d_model=512,\n",
    "        d_head=64,\n",
    "        n_heads=8,\n",
    "        d_mlp=2048,\n",
    "        d_vocab=61,\n",
    "        n_ctx=59,\n",
    "        act_fn=\"gelu\",\n",
    "        normalization_type=\"LNPre\",\n",
    "        device=device,\n",
    "    )\n",
    "    model = HookedTransformer(cfg)\n",
    "\n",
    "    state_dict_synthetic = download_file_from_hf(\n",
    "        \"NeelNanda/Othello-GPT-Transformer-Lens\", \"synthetic_model.pth\"\n",
    "    )\n",
    "    # state_dict_championship = download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"championship_model.pth\")\n",
    "    model.load_state_dict(state_dict_synthetic)\n",
    "    return model\n",
    "\n",
    "\n",
    "def transform_hooked_transformer_to_othello_vocab(hooked_model):\n",
    "    # Create new model with Othello configuration\n",
    "    othello_cfg = HookedTransformerConfig(\n",
    "        n_layers=hooked_model.cfg.n_layers,\n",
    "        d_model=hooked_model.cfg.d_model,\n",
    "        d_head=hooked_model.cfg.d_head,\n",
    "        n_heads=hooked_model.cfg.n_heads,\n",
    "        d_mlp=hooked_model.cfg.d_mlp,\n",
    "        d_vocab=61,\n",
    "        n_ctx=59,\n",
    "        act_fn=hooked_model.cfg.act_fn,\n",
    "        normalization_type=hooked_model.cfg.normalization_type,\n",
    "        device=hooked_model.cfg.device,\n",
    "    )\n",
    "\n",
    "    othello_model = HookedTransformer(othello_cfg)\n",
    "\n",
    "    # Copy all weights except embeddings\n",
    "    with t.no_grad():\n",
    "        state_dict = hooked_model.state_dict()\n",
    "        new_state_dict = othello_model.state_dict()\n",
    "\n",
    "        for name, param in state_dict.items():\n",
    "            if not any(\n",
    "                embed_name in name\n",
    "                for embed_name in [\n",
    "                    \"embed\",\n",
    "                    \"mask\",\n",
    "                ]\n",
    "            ):  # unembed and pos_embed might work without   #'pos_embed', 'unembed',\n",
    "                new_state_dict[name].copy_(param)\n",
    "            else:\n",
    "                print(f\"Skipping {name}: not in new state dict\")\n",
    "            # if name not in new_state_dict:\n",
    "            #     print(f\"Skipping {name}: not in new state dict\")\n",
    "            # elif not param.shape == new_state_dict[name].shape:\n",
    "            #     print(f\"Skipping {name}: shape mismatch\")\n",
    "            # else:\n",
    "            #     new_state_dict[name].copy_(param)\n",
    "    return othello_model\n",
    "\n",
    "\n",
    "def load_tiny_stories_instruct_8m(\n",
    "    device, force_othello_vocab: bool = True\n",
    ") -> HookedTransformer:\n",
    "    hooked_model = HookedTransformer.from_pretrained(\n",
    "        \"roneneldan/TinyStories-Instruct-8M\", device=DEVICE\n",
    "    )\n",
    "    if force_othello_vocab:\n",
    "        return transform_hooked_transformer_to_othello_vocab(hooked_model)\n",
    "    else:\n",
    "        return hooked_model\n",
    "\n",
    "\n",
    "def load_hooked_chess_gpt(\n",
    "    device, force_othello_vocab: bool = True\n",
    ") -> HookedTransformer:\n",
    "    t.set_grad_enabled(False)\n",
    "    # model_url = 'https://huggingface.co/adamkarvonen/nanogpt_transformer_lens_examples/resolve/main/ckpt_8layers_no_bias_no_opt.pt'\n",
    "    model_url = \"https://huggingface.co/adamkarvonen/nanogpt_transformer_lens_examples/resolve/main/ckpt_8layers_bias_no_opt.pt\"\n",
    "    checkpoint = t.hub.load_state_dict_from_url(model_url, map_location=device)\n",
    "    nanogpt_model_dict = checkpoint[\"model\"]\n",
    "    hooked_chess_gpt = convert_nanogpt_to_hooked_and_verify(\n",
    "        nanogpt_model_dict, device=device\n",
    "    )\n",
    "    if force_othello_vocab:\n",
    "        return transform_hooked_transformer_to_othello_vocab(hooked_chess_gpt)\n",
    "    else:\n",
    "        return hooked_chess_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qhbM1hZN-cko"
   },
   "outputs": [],
   "source": [
    "# chess_gpt = load_chess_gpt(DEVICE, force_othello_vocab=False)\n",
    "# chess_gpt.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThMvq0yOYnXU"
   },
   "source": [
    "### test_hooked_transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4jIIkUcUYnhS"
   },
   "outputs": [],
   "source": [
    "def test_hooked_transformer(\n",
    "    model, othello_rule, test_dataset, batch_size, n_games, device\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'ce_loss': float,\n",
    "            'illegal_move_percentage': float,\n",
    "            'total_predictions': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_subset = Subset(test_dataset, range(n_games))\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "    total_loss = 0\n",
    "    total_predictions = 0\n",
    "    illegal_moves = 0\n",
    "    with t.no_grad():\n",
    "        for x, y in tqdm(test_loader, desc=\"Validating\"):\n",
    "            x = x.to(device)  # [B, T]\n",
    "            y = y.to(device)  # [B, T]\n",
    "            B = x.size(0)\n",
    "            T = x.size(1)\n",
    "\n",
    "            # Sum of CE loss\n",
    "            # logits = model(x)\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=0\n",
    "            )\n",
    "            total_loss += loss.item() * B\n",
    "\n",
    "            # Check illegal moves\n",
    "            for b in range(B):\n",
    "                board = OthelloBoardState()\n",
    "                for t_step in range(T):\n",
    "                    if t_step > 0:  # Skip first move since we don't predict it\n",
    "                        pred_token_id = logits[b, t_step - 1].argmax().item()\n",
    "                        if pred_token_id != 0:  # Skip padding tokens\n",
    "                            pred_square = id_to_square(pred_token_id)\n",
    "                            if othello_rule in [\n",
    "                                OthelloRule.STANDARD,\n",
    "                                OthelloRule.BIAS_CLOCK,\n",
    "                                OthelloRule.CHESS,\n",
    "                                OthelloRule.UNTRAINED,\n",
    "                                OthelloRule.TINY_STORIES,\n",
    "                            ]:\n",
    "                                valid_moves = board.get_valid_moves()\n",
    "                            elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                                valid_moves = board.get_moves_next_to_opponent()\n",
    "                            elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "                                is_occupied = board.get_occupied()\n",
    "                                valid_moves = [\n",
    "                                    i for i in range(64) if is_occupied[i] == 0\n",
    "                                ]\n",
    "                            else:\n",
    "                                raise ValueError(f\"Invalid OthelloRule: {othello_rule}\")\n",
    "                            if pred_square not in valid_moves:\n",
    "                                illegal_moves += 1\n",
    "\n",
    "                            total_predictions += 1\n",
    "\n",
    "                    # Apply actual move to advance board state\n",
    "                    if t_step < T - 1:  # Don't predict beyond sequence\n",
    "                        actual_token_id = x[b, t_step].item()\n",
    "                        if actual_token_id != 0:  # Skip padding\n",
    "                            actual_square = id_to_square(actual_token_id)\n",
    "                            if othello_rule in [\n",
    "                                OthelloRule.STANDARD,\n",
    "                                OthelloRule.BIAS_CLOCK,\n",
    "                                OthelloRule.CHESS,\n",
    "                                OthelloRule.UNTRAINED,\n",
    "                                OthelloRule.TINY_STORIES,\n",
    "                            ]:\n",
    "                                board.umpire(actual_square)\n",
    "                            elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                                board.place_next_to_opponent(actual_square)\n",
    "                            elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "                                board.place_no_flipping(actual_square)\n",
    "                            else:\n",
    "                                raise ValueError(f\"Invalid OthelloRule: {othello_rule}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_ce_loss = total_loss / len(test_subset)\n",
    "    illegal_percentage = (\n",
    "        (illegal_moves / total_predictions * 100) if total_predictions > 0.0 else 0.0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"ce_loss\": avg_ce_loss,\n",
    "        \"illegal_move_percentage\": illegal_percentage,\n",
    "        \"total_predictions\": total_predictions,\n",
    "        \"illegal_moves\": illegal_moves,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8OKY5ZhHqn"
   },
   "source": [
    "### save_load_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1Pt7Y0Q5hH1g"
   },
   "outputs": [],
   "source": [
    "def save_model(\n",
    "    model,\n",
    "    run_id: str,\n",
    "    project_name: str,\n",
    "    experiment_name: str,\n",
    "    experiment_folder: str,\n",
    "    index: int,\n",
    "    overwrite: bool,\n",
    "    final: bool,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> None:\n",
    "    project_dir = os.path.join(experiment_folder, project_name)\n",
    "    if project_dir not in sys.path:\n",
    "        sys.path.append(project_dir)\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "    file_name = f\"{experiment_name}_{run_id}.pkl\"\n",
    "    file_path = os.path.join(project_dir, file_name)\n",
    "    if not overwrite:\n",
    "        assert not os.path.exists(file_path)\n",
    "    t.save(model, file_path)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "\n",
    "\n",
    "def get_experiment_name_pretrained(\n",
    "    model_size: str,\n",
    "    othello_rule: OthelloRule,\n",
    "    index: int,\n",
    "    final: bool = False,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> str:\n",
    "    if fake_probe:\n",
    "        assert linear_probe, \"fake_probe=True requires linear_probe=True\"\n",
    "    prefix = \"\"\n",
    "    if final:\n",
    "        prefix = \"final_\"\n",
    "    if fake_probe:\n",
    "        prefix += fake_probe + \"_\"\n",
    "    if linear_probe:\n",
    "        prefix += \"linear_probe_\"\n",
    "    else:\n",
    "        prefix += \"experiment_\"\n",
    "\n",
    "    return f\"{prefix}{index}_{model_size}_{othello_rule.value}\"\n",
    "\n",
    "\n",
    "def load_model_pretrained_get_matching_files(\n",
    "    project_name: str,\n",
    "    model_size: str,\n",
    "    othello_rule: OthelloRule,\n",
    "    experiment_folder: str,\n",
    "    index: int,\n",
    "    final: bool,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> list[str]:\n",
    "    project_dir = os.path.join(experiment_folder, project_name)\n",
    "    experiment_name = get_experiment_name_pretrained(\n",
    "        model_size, othello_rule, index, final, linear_probe, fake_probe\n",
    "    )\n",
    "    pattern = os.path.join(project_dir, experiment_name + \"*.pkl\")\n",
    "    matching_files = glob.glob(pattern)\n",
    "    return matching_files\n",
    "\n",
    "\n",
    "def load_model_pretrained(\n",
    "    project_name: str,\n",
    "    model_size: str,\n",
    "    othello_rule: OthelloRule,\n",
    "    experiment_folder: str,\n",
    "    device: t.device,\n",
    "    index: int,\n",
    "    final: bool,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> t.nn.Module:\n",
    "    matching_files = load_model_pretrained_get_matching_files(\n",
    "        project_name,\n",
    "        model_size,\n",
    "        othello_rule,\n",
    "        experiment_folder,\n",
    "        index,\n",
    "        final,\n",
    "        linear_probe,\n",
    "        fake_probe,\n",
    "    )\n",
    "    if not matching_files:\n",
    "        print(\n",
    "            f\"No model files found for size {model_size}, othello_rule {othello_rule}, index {index}, final {final}, linear_probe {linear_probe}, fake_probe {fake_probe}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Pick the most recent file based on modification time.\n",
    "    latest_file = max(matching_files, key=os.path.getmtime)\n",
    "    print(f\"Loading model from {latest_file}\")\n",
    "    if linear_probe:\n",
    "        linear_probe_tensor = t.load(\n",
    "            latest_file, weights_only=False, map_location=device\n",
    "        )\n",
    "        return linear_probe_tensor\n",
    "    else:\n",
    "        with t.serialization.safe_globals({HookedTransformer}):\n",
    "            model = t.load(latest_file, weights_only=False, map_location=device)\n",
    "            model = move_to_and_update_config(model, device)\n",
    "        return model\n",
    "\n",
    "\n",
    "def get_experiment_name_finetuned(\n",
    "    weak_model_size: str,\n",
    "    weak_rule: OthelloRule,\n",
    "    strong_model_size: str,\n",
    "    strong_rule: OthelloRule,\n",
    "    index: int,\n",
    "    final: bool = False,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> str:\n",
    "    if fake_probe:\n",
    "        assert linear_probe, \"fake_probe=True requires linear_probe=True\"\n",
    "    prefix = \"\"\n",
    "    if final:\n",
    "        prefix = \"final_\"\n",
    "    if fake_probe:\n",
    "        prefix += fake_probe + \"_\"\n",
    "    if linear_probe:\n",
    "        prefix += \"linear_probe_\"\n",
    "    else:\n",
    "        prefix += \"experiment_\"\n",
    "    return f\"{prefix}{index}_{weak_model_size}_{strong_model_size}_{weak_rule}_to_{strong_rule}\"\n",
    "\n",
    "\n",
    "def load_finetuned_model_get_matching_files(\n",
    "    project_name: str,\n",
    "    weak_model_size: str,\n",
    "    weak_rule: OthelloRule,\n",
    "    strong_model_size: str,\n",
    "    strong_rule: OthelloRule,\n",
    "    experiment_folder: str,\n",
    "    index: int,\n",
    "    final: bool,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> list[str]:\n",
    "    project_dir = os.path.join(experiment_folder, project_name)\n",
    "    experiment_name = get_experiment_name_finetuned(\n",
    "        weak_model_size,\n",
    "        weak_rule,\n",
    "        strong_model_size,\n",
    "        strong_rule,\n",
    "        index,\n",
    "        final,\n",
    "        linear_probe,\n",
    "        fake_probe,\n",
    "    )\n",
    "    pattern = os.path.join(project_dir, experiment_name + \"*.pkl\")\n",
    "    print(\"pattern: \", pattern)\n",
    "    matching_files = glob.glob(pattern)\n",
    "    return matching_files\n",
    "\n",
    "\n",
    "def load_finetuned_model(\n",
    "    project_name: str,\n",
    "    weak_model_size: str,\n",
    "    weak_rule: OthelloRule,\n",
    "    strong_model_size: str,\n",
    "    strong_rule: OthelloRule,\n",
    "    experiment_folder: str,\n",
    "    device: t.device,\n",
    "    index,\n",
    "    final: bool,\n",
    "    linear_probe: bool = False,\n",
    "    fake_probe: str = \"\",\n",
    ") -> t.nn.Module:\n",
    "    matching_files = load_finetuned_model_get_matching_files(\n",
    "        project_name,\n",
    "        weak_model_size,\n",
    "        weak_rule,\n",
    "        strong_model_size,\n",
    "        strong_rule,\n",
    "        experiment_folder,\n",
    "        index,\n",
    "        final,\n",
    "        linear_probe,\n",
    "        fake_probe,\n",
    "    )\n",
    "    print(\"matching_files: \", matching_files)\n",
    "    if not matching_files:\n",
    "        print(\n",
    "            f\"No finetuned model files found for weak_model_size {weak_model_size}, weak_rule {weak_rule}, strong_model_size {strong_model_size}, strong_rule {strong_rule}, index {index}, final {final}, linear_probe {linear_probe}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Return newest model\n",
    "    latest_file = max(matching_files, key=os.path.getmtime)\n",
    "    if linear_probe:\n",
    "        linear_probe_tensor = t.load(\n",
    "            latest_file, weights_only=False, map_location=device\n",
    "        )\n",
    "        return linear_probe_tensor\n",
    "    else:\n",
    "        with t.serialization.safe_globals({HookedTransformer}):\n",
    "            finetuned_model = t.load(\n",
    "                latest_file, weights_only=False, map_location=device\n",
    "            )\n",
    "            finetuned_model = move_to_and_update_config(finetuned_model, device)\n",
    "        return finetuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7iUk7uY8wcE"
   },
   "source": [
    "### trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "l_Fg-yTK8wlL"
   },
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    max_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    validate_every_n_steps: int\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    betas: tuple[float, float]\n",
    "    grad_norm_clip: float\n",
    "    weight_decay: float  # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay = False\n",
    "    warmup_tokens = None  # 375e6 # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n",
    "    final_tokens = None  # 260e9 # (at what point we reach 10% of original LR)\n",
    "    num_workers: int  # for DataLoader\n",
    "    n_games_to_test_legal_moves: int\n",
    "    n_tokens_to_test_and_val: int\n",
    "\n",
    "    # checkpoint settings\n",
    "    experiment_name: str\n",
    "    experiment_folder: str\n",
    "    project_name: str\n",
    "    model_size: ModelSize\n",
    "    othello_rule: OthelloRule\n",
    "    index: int\n",
    "    final: bool\n",
    "\n",
    "    # Wandb\n",
    "    use_wandb: bool\n",
    "    wandb_project: str | None\n",
    "    wandb_name: str | None\n",
    "\n",
    "    # Saving\n",
    "    save_model: bool\n",
    "    save_every_validation: bool\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class TrainerConfigFinetune(TrainerConfig):\n",
    "    weak_supervision_model_size: ModelSize\n",
    "    weak_supervision_rule: OthelloRule\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, model, val_dataset, othello_rule_to_test, config, model_cfg, device\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.val_dataset = val_dataset\n",
    "        self.othello_rule_to_test = othello_rule_to_test\n",
    "        self.config = config\n",
    "        self.model_cfg = model_cfg\n",
    "        self.run_id = 0\n",
    "\n",
    "        # take over whatever gpus are on the system\n",
    "        self.device = device\n",
    "        if self.device != \"cpu\":\n",
    "            self.model = t.nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "    def save_checkpoint(self, index=None, final=None):\n",
    "        # DataParallel wrappers keep raw model object in .module attribute\n",
    "        gpt_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        hooked_transformer_model = convert_gpt_to_hooked_and_verify(\n",
    "            gpt_model, self.model_cfg, self.val_dataset\n",
    "        )\n",
    "        if index is None:\n",
    "            index = self.config.index\n",
    "        experiment_name = self.config.experiment_name\n",
    "        if final is None:\n",
    "            final = self.config.final\n",
    "        if final:\n",
    "            experiment_name = \"final_\" + experiment_name\n",
    "        save_model(\n",
    "            hooked_transformer_model,\n",
    "            self.run_id,\n",
    "            self.config.project_name,\n",
    "            experiment_name,\n",
    "            self.config.experiment_folder,\n",
    "            index=index,\n",
    "            overwrite=True,\n",
    "            final=final,\n",
    "        )\n",
    "\n",
    "    def _get_mean_loss_on_dataset(self, dataset) -> float:\n",
    "        self.model.train(False)\n",
    "        indices = random.sample(\n",
    "            range(len(dataset)), min(self.config.n_tokens_to_test_and_val, len(dataset))\n",
    "        )\n",
    "        subset = Subset(dataset, indices)\n",
    "        data_loader = DataLoader(\n",
    "            subset,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            batch_size=self.config.batch_size,\n",
    "            num_workers=self.config.num_workers,\n",
    "        )\n",
    "        loss_sum = 0\n",
    "        for it, (x, y) in enumerate(data_loader):\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            with t.set_grad_enabled(False):\n",
    "                logits, loss = self.model(x, y)\n",
    "                loss_sum += loss.item()\n",
    "        self.model.train(True)\n",
    "        return loss_sum / len(data_loader)\n",
    "\n",
    "    def _get_legal_move_accuracy(self, dataset, othello_rule) -> float:\n",
    "        self.model.train(False)\n",
    "        indices = random.sample(\n",
    "            range(len(dataset)),\n",
    "            min(self.config.n_games_to_test_legal_moves, len(dataset)),\n",
    "        )\n",
    "        subset = Subset(dataset, indices)\n",
    "        data_loader = DataLoader(\n",
    "            subset, batch_size=self.config.batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "        total_predictions = 0\n",
    "        legal_moves = 0\n",
    "\n",
    "        with t.no_grad():\n",
    "            for x, y in data_loader:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                B, T = x.size()\n",
    "\n",
    "                logits = self.model(x)[0]  # Get logits only\n",
    "\n",
    "                for b in range(B):\n",
    "                    board = OthelloBoardState()\n",
    "                    for t_step in range(T):\n",
    "                        if t_step > 0:\n",
    "                            pred_token_id = logits[b, t_step - 1].argmax().item()\n",
    "                            if pred_token_id != 0:\n",
    "                                pred_square = id_to_square(pred_token_id)\n",
    "                                valid_moves = board.get_valid_moves()\n",
    "                                if pred_square in valid_moves:\n",
    "                                    legal_moves += 1\n",
    "                                total_predictions += 1\n",
    "\n",
    "                        if t_step < T - 1:\n",
    "                            actual_token_id = x[b, t_step].item()\n",
    "                            if actual_token_id != 0:\n",
    "                                actual_square = id_to_square(actual_token_id)\n",
    "                                if othello_rule in [\n",
    "                                    OthelloRule.STANDARD,\n",
    "                                    OthelloRule.BIAS_CLOCK,\n",
    "                                    OthelloRule.CHESS,\n",
    "                                    OthelloRule.UNTRAINED,\n",
    "                                    OthelloRule.TINY_STORIES,\n",
    "                                    OthelloRule.CONSTANT_PARAMETERS,\n",
    "                                ]:\n",
    "                                    board.umpire(actual_square)\n",
    "                                elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "                                    board.place_next_to_opponent(actual_square)\n",
    "                                elif othello_rule == OthelloRule.NO_FLIPPING:\n",
    "                                    board.place_no_flipping(actual_square)\n",
    "                                else:\n",
    "                                    raise ValueError(\n",
    "                                        f\"Unknown OthelloRule: {othello_rule}\"\n",
    "                                    )\n",
    "\n",
    "        self.model.train(True)\n",
    "        return legal_moves / total_predictions if total_predictions > 0 else 0.0\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def perform_extra_tests(self, step):\n",
    "        pass\n",
    "\n",
    "    def _test(self, step) -> str:\n",
    "        self.perform_extra_tests(step)\n",
    "        if self.config.use_wandb:\n",
    "            legal_move_chance = self._get_legal_move_accuracy(\n",
    "                self.get_train_dataset(), self.config.othello_rule\n",
    "            )\n",
    "            wandb.log({\"train/legal_move_chance\": legal_move_chance}, step=step)\n",
    "            # Loss and legal moves for each rule\n",
    "            for othello_rule in self.othello_rule_to_test:\n",
    "                dataset = self.othello_rule_to_test[othello_rule]\n",
    "                loss = self._get_mean_loss_on_dataset(dataset)\n",
    "                legal_move_chance = self._get_legal_move_accuracy(dataset, othello_rule)\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        f\"test/{othello_rule.value}_loss\": loss,\n",
    "                        f\"test/{othello_rule.value}_legal_move_chance\": legal_move_chance,\n",
    "                    },\n",
    "                    step=step,\n",
    "                )\n",
    "\n",
    "    def _validate(self, step):\n",
    "        \"\"\"Returns if True iff. early-stop got triggered\"\"\"\n",
    "        if self.config.save_every_validation:\n",
    "            self.save_checkpoint(index=step)\n",
    "\n",
    "        loss = self._get_mean_loss_on_dataset(self.val_dataset)\n",
    "        if self.config.use_wandb:\n",
    "            wandb.log(\n",
    "                {\"val/loss\": loss, \"val/patience_counter\": self.patience_counter},\n",
    "                step=step,\n",
    "            )\n",
    "\n",
    "        if loss < self.best_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.best_loss = loss\n",
    "            if self.config.save_model:\n",
    "                self.save_checkpoint()\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            if self.patience_counter >= self.config.early_stopping_patience:\n",
    "                print(f\"Early Stop Triggered at step {step}\")\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_train_loss(self, x, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _run_epoch_train(self, optimizer, epoch: int):\n",
    "        \"\"\"Returns if True iff. early-stop got triggered\"\"\"\n",
    "        self.model.train(True)\n",
    "        data = self.get_train_dataset()\n",
    "        train_loader = DataLoader(\n",
    "            data,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            batch_size=self.config.batch_size,\n",
    "            num_workers=self.config.num_workers,\n",
    "        )\n",
    "        train_loader_len = len(train_loader)\n",
    "\n",
    "        losses = []\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for it, (x, y) in pbar:\n",
    "            step = epoch * train_loader_len + it\n",
    "            x = x.to(self.device)  # [B, T]\n",
    "            y = y.to(self.device)  # [B, T]\n",
    "            with t.set_grad_enabled(True):\n",
    "                loss = self.get_train_loss(x, y)\n",
    "                losses.append(loss)\n",
    "\n",
    "            # backprop\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            t.nn.utils.clip_grad_norm_(\n",
    "                self.model.parameters(), self.config.grad_norm_clip\n",
    "            )\n",
    "            optimizer.step()\n",
    "\n",
    "            # decay learning rate\n",
    "            if self.config.lr_decay:\n",
    "                self.tokens += (\n",
    "                    y >= 0\n",
    "                ).sum()  # number of tokens processed this step (i.e. label is not -100)\n",
    "                if self.tokens < self.config.warmup_tokens:\n",
    "                    # linear warmup\n",
    "                    lr_mult = float(self.tokens) / float(\n",
    "                        max(1, self.config.warmup_tokens)\n",
    "                    )\n",
    "                else:\n",
    "                    # cosine learning rate decay\n",
    "                    progress = float(self.tokens - self.config.warmup_tokens) / float(\n",
    "                        max(1, self.config.final_tokens - self.config.warmup_tokens)\n",
    "                    )\n",
    "                    lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "                lr = self.config.learning_rate * lr_mult\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] = lr\n",
    "            else:\n",
    "                lr = self.config.learning_rate\n",
    "\n",
    "            # report progress\n",
    "            pbar.set_description(\n",
    "                f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\"\n",
    "            )\n",
    "            if self.config.use_wandb:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"train/loss\": loss.item(),\n",
    "                        \"train/lr\": lr,\n",
    "                    },\n",
    "                    step=step,\n",
    "                )\n",
    "            if step % self.config.validate_every_n_steps == 0:\n",
    "                self._test(step)\n",
    "                stop = self._validate(step)\n",
    "                if stop:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def train(self):\n",
    "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        optimizer = raw_model.configure_optimizers(self.config)\n",
    "        if self.config.use_wandb:\n",
    "            wandb.init(\n",
    "                project=self.config.wandb_project,\n",
    "                name=self.config.wandb_name,\n",
    "                config=self.config,\n",
    "            )\n",
    "            self.run_id = wandb.run.id\n",
    "\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        self.tokens = 0  # counter used for learning rate decay. Also lets _run_epoch fail if train hasnt been called first (and hence variable doesn't exist).\n",
    "        for epoch in range(self.config.max_epochs):\n",
    "            stop = self._run_epoch_train(optimizer, epoch)\n",
    "            if stop:\n",
    "                break\n",
    "\n",
    "        if self.config.save_model:\n",
    "            self.save_checkpoint(final=True)\n",
    "\n",
    "\n",
    "class TrainerPretrain(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        othello_rule_to_test,\n",
    "        config,\n",
    "        model_cfg,\n",
    "        device,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, val_dataset, othello_rule_to_test, config, model_cfg, device\n",
    "        )\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.train_dataset\n",
    "\n",
    "    def get_train_loss(self, x, y):\n",
    "        logits, loss = self.model(x, y)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TrainerFinetune(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        weak_model,\n",
    "        weak_finetune_dataset,\n",
    "        val_dataset,\n",
    "        othello_rule_to_test,\n",
    "        config,\n",
    "        model_cfg,\n",
    "        device,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, val_dataset, othello_rule_to_test, config, model_cfg, device\n",
    "        )\n",
    "        self.weak_model = weak_model\n",
    "        self.weak_finetune_dataset = weak_finetune_dataset\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.weak_finetune_dataset\n",
    "\n",
    "    def perform_extra_tests(self, step):\n",
    "        if self.config.use_wandb:\n",
    "            self.model.train(False)\n",
    "            indices = random.sample(\n",
    "                range(len(self.val_dataset)),\n",
    "                min(self.config.n_tokens_to_test_and_val, len(self.val_dataset)),\n",
    "            )\n",
    "            subset = Subset(self.val_dataset, indices)\n",
    "            data_loader = DataLoader(\n",
    "                subset,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "                batch_size=self.config.batch_size,\n",
    "                num_workers=self.config.num_workers,\n",
    "            )\n",
    "            loss_sum = 0\n",
    "            for it, (x, y) in enumerate(data_loader):\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                with t.set_grad_enabled(False):\n",
    "                    loss = self.get_train_loss(x, y)\n",
    "                    loss_sum += loss.item()\n",
    "            self.model.train(True)\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"val/loss_soft_weak_labels\": loss_sum / len(data_loader),\n",
    "                },\n",
    "                step=step,\n",
    "            )\n",
    "\n",
    "    def get_train_loss(self, x, y):\n",
    "        logits_weak_supervision, _ = self.weak_model(x)\n",
    "        y_soft_weak_supervision = F.softmax(logits_weak_supervision, dim=-1)\n",
    "        logits, loss = self.model(x, y, y_soft_weak_supervision)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFKAJF7S7aGF"
   },
   "source": [
    "### train_and_load_chess_gpt_embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ymivBhE97YHx"
   },
   "outputs": [],
   "source": [
    "class VocabProjectionGPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around a GPT model to adapt to new n_vocab.\n",
    "    Instead of embedding W, it uses W_new = W @ H, where H is initialized as a\n",
    "    random matrix and can be trained.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_gpt_model, target_vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Base model with freezed parameters\n",
    "        self.base_gpt = base_gpt_model\n",
    "        for param in self.base_gpt.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.source_vocab_size = self.base_gpt.tok_emb.num_embeddings\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.n_embd = self.base_gpt.tok_emb.embedding_dim\n",
    "\n",
    "        # Projection matrices\n",
    "        self.input_projection = nn.Linear(\n",
    "            target_vocab_size, self.source_vocab_size, bias=False\n",
    "        )\n",
    "        self.output_projection = nn.Linear(\n",
    "            self.source_vocab_size, target_vocab_size, bias=False\n",
    "        )\n",
    "        nn.init.normal_(self.input_projection.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.output_projection.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.base_gpt.get_block_size()\n",
    "\n",
    "    def configure_optimizers(self, train_config):\n",
    "        \"\"\"Only optimize the projection matrices\"\"\"\n",
    "        projection_params = list(self.input_projection.parameters()) + list(\n",
    "            self.output_projection.parameters()\n",
    "        )\n",
    "        optim_groups = [\n",
    "            {\"params\": projection_params, \"weight_decay\": train_config.weight_decay}\n",
    "        ]\n",
    "        optimizer = t.optim.AdamW(\n",
    "            optim_groups, lr=train_config.learning_rate, betas=train_config.betas\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, idx, targets=None, y_soft_weak_supervision=None):\n",
    "        \"\"\"\n",
    "        Forward pass with composed embedding matrices\n",
    "\n",
    "        Args:\n",
    "            idx: [B, T] - Othello token IDs\n",
    "            targets: [B, T] - Othello target token IDs (optional)\n",
    "            y_soft_weak_supervision: [B, T, target_vocab_size] - Soft labels (optional)\n",
    "        \"\"\"\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.base_gpt.block_size, (\n",
    "            \"Cannot forward, model block size is exhausted.\"\n",
    "        )\n",
    "\n",
    "        # Create embeddings\n",
    "        composed_embedding_weight = (\n",
    "            self.input_projection.weight.T @ self.base_gpt.tok_emb.weight\n",
    "        )\n",
    "        composed_head_weight = (\n",
    "            self.base_gpt.head.weight.T @ self.output_projection.weight.T\n",
    "        )\n",
    "\n",
    "        # Forward\n",
    "        token_embeddings = F.embedding(idx, composed_embedding_weight)\n",
    "        position_embeddings = self.base_gpt.pos_emb[:, :t, :]  # [B, T, n_embd]\n",
    "        x = self.base_gpt.drop(token_embeddings + position_embeddings)\n",
    "        x = self.base_gpt.blocks(x)\n",
    "        x = self.base_gpt.ln_f(x)\n",
    "        logits = F.linear(x, composed_head_weight.T)  # [B, T, target_vocab_size]\n",
    "\n",
    "        # Calculate loss if targets provided\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            if y_soft_weak_supervision is not None:\n",
    "                # Soft supervision case\n",
    "                mask = (targets != 0).float()  # [B, T]\n",
    "\n",
    "                logits_flat = logits.view(\n",
    "                    -1, logits.size(-1)\n",
    "                )  # [B*T, target_vocab_size]\n",
    "                soft_targets_flat = y_soft_weak_supervision.view(\n",
    "                    -1, y_soft_weak_supervision.size(-1)\n",
    "                )  # [B*T, target_vocab_size]\n",
    "                mask_flat = mask.view(-1)  # [B*T]\n",
    "\n",
    "                loss_per_token = F.cross_entropy(\n",
    "                    logits_flat, soft_targets_flat, reduction=\"none\"\n",
    "                )  # [B*T]\n",
    "                masked_loss = loss_per_token * mask_flat\n",
    "\n",
    "                if mask_flat.sum() > 0:\n",
    "                    loss = masked_loss.sum() / mask_flat.sum()\n",
    "                else:\n",
    "                    loss = t.tensor(0.0, device=logits.device)\n",
    "            else:\n",
    "                # Standard cross-entropy loss\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0\n",
    "                )\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "class ProjectionTrainerConfig(TrainerConfig):\n",
    "    \"\"\"Config for training projection matrices only\"\"\"\n",
    "\n",
    "    target_vocab_size: int  # Othello vocabulary size (61)\n",
    "\n",
    "\n",
    "class ProjectionTrainer(TrainerPretrain):\n",
    "    \"\"\"Trainer of VocabProjectionGPT that only trains the projection matrices\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, train_dataset, val_dataset, othello_rule_to_test, config, device\n",
    "    ):\n",
    "        chess_gpt = self.load_chess_gpt(val_dataset, device)\n",
    "        model = VocabProjectionGPT(\n",
    "            base_gpt_model=chess_gpt, target_vocab_size=config.target_vocab_size\n",
    "        )\n",
    "        model_cfg = None\n",
    "        super().__init__(\n",
    "            model,\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            othello_rule_to_test,\n",
    "            config,\n",
    "            model_cfg,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "    def load_chess_gpt(self, val_dataset, device):\n",
    "        \"\"\"Load the pre-trained ChessGPT model\"\"\"\n",
    "        hooked_chess_gpt = load_hooked_chess_gpt(device, force_othello_vocab=False)\n",
    "        gpt_model, gpt_config = convert_hooked_to_gpt(hooked_chess_gpt, device)\n",
    "        return gpt_model\n",
    "\n",
    "    def save_checkpoint(self, final=False, index=None):\n",
    "        \"\"\"Save only the projection matrices\"\"\"\n",
    "        model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        projection_state = {\n",
    "            \"input_projection\": model.input_projection.state_dict(),\n",
    "            \"output_projection\": model.output_projection.state_dict(),\n",
    "            \"source_vocab_size\": model.source_vocab_size,\n",
    "            \"target_vocab_size\": model.target_vocab_size,\n",
    "        }\n",
    "        save_path = f\"{self.config.experiment_folder}/{self.config.experiment_name}/projection_matrices_{'final' if final else index}.pt\"\n",
    "        t.save(projection_state, save_path)\n",
    "        print(f\"Saved projection matrices to {save_path}\")\n",
    "\n",
    "\n",
    "def create_othello_gpt_from_chess(\n",
    "    projection_matrices_path: str, device: str\n",
    ") -> HookedTransformer:\n",
    "    \"\"\"\n",
    "    Create a HookedTransformer OthelloGPT by loading ChessGPT and applying\n",
    "    learned projection matrices to create new embedding and unembedding layers.\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    hooked_chess_gpt = load_hooked_chess_gpt(device, force_othello_vocab=False)\n",
    "    chess_gpt, chess_config = convert_hooked_to_gpt(hooked_chess_gpt, device)\n",
    "\n",
    "    # Load embedding matrices\n",
    "    projection_data = t.load(projection_matrices_path, map_location=device)\n",
    "    input_proj_weight = projection_data[\"input_projection\"][\"weight\"].to(device)\n",
    "    output_proj_weight = projection_data[\"output_projection\"][\"weight\"].to(device)\n",
    "    target_vocab_size = projection_data[\"target_vocab_size\"]\n",
    "\n",
    "    # Create new embedding matrices and GPT model\n",
    "    with t.no_grad():\n",
    "        composed_embedding_weight = input_proj_weight.T @ chess_gpt.tok_emb.weight\n",
    "        composed_head_weight = chess_gpt.head.weight.T @ output_proj_weight.T\n",
    "\n",
    "    othello_config = GPTConfig(\n",
    "        vocab_size=target_vocab_size,\n",
    "        block_size=chess_gpt.block_size,\n",
    "        n_embd=chess_gpt.tok_emb.embedding_dim,\n",
    "        n_head=chess_gpt.blocks[0].attn.n_head,\n",
    "        n_layer=len(chess_gpt.blocks),\n",
    "    )\n",
    "    othello_gpt = GPT(othello_config).to(device)\n",
    "\n",
    "    # Insert embedding matrices\n",
    "    with t.no_grad():\n",
    "        othello_gpt.blocks.load_state_dict(chess_gpt.blocks.state_dict())\n",
    "        othello_gpt.ln_f.load_state_dict(chess_gpt.ln_f.state_dict())\n",
    "        othello_gpt.drop = chess_gpt.drop\n",
    "        othello_gpt.tok_emb.weight.data.copy_(composed_embedding_weight)\n",
    "        othello_gpt.head.weight.data.copy_(composed_head_weight.T)\n",
    "\n",
    "    # Return HookedTransformer\n",
    "    hooked_othello_gpt = convert_gpt_to_hooked(othello_gpt, othello_config)\n",
    "    return hooked_othello_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5HrM31lME2Qf"
   },
   "outputs": [],
   "source": [
    "# final_othello_gpt = create_othello_gpt_from_chess(\n",
    "#     projection_matrices_path=f\"{experiment_folder}/copy_projection_matrices_None.pt\",\n",
    "#     device=DEVICE\n",
    "# )\n",
    "# test_hooked_transformer(final_othello_gpt, OthelloRule.STANDARD, othello_rule_to_test[OthelloRule.STANDARD], 64, 10, DEVICE)\n",
    "\n",
    "# experiment_name = f\"experiment_0_{ModelSize.HUGE}_{OthelloRule.CHESS.value}\"\n",
    "# save_model(final_othello_gpt, 0, \"pretrain_extra_models\", experiment_name, experiment_folder, index=0, final=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TfjsA4N_aFuq"
   },
   "outputs": [],
   "source": [
    "# tiny_stories = load_tiny_stories_instruct_8m(DEVICE, force_othello_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQE6p_vS0X9C"
   },
   "source": [
    "# --- MultiProbe ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyzic3pGk6qh"
   },
   "source": [
    "### fake_board_state_transform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "OYiz-Qdtk61H"
   },
   "outputs": [],
   "source": [
    "class FakeBoardStateTransform(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FakeBoardStateTransformPlacedBefore(FakeBoardStateTransform):\n",
    "    \"\"\"\n",
    "    I.e. empty -> 0, theirs/mine -> 1. This means we track if this token\n",
    "    has occured before.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"placed_before\"\n",
    "\n",
    "    def forward(self, board_state):\n",
    "        return (board_state != 0).long()\n",
    "\n",
    "\n",
    "class FakeBoardStateTransformBlackWhite(FakeBoardStateTransform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"black_white\"\n",
    "\n",
    "    def forward(self, board_state):\n",
    "        return board_state\n",
    "\n",
    "\n",
    "class FakeBoardStateTransformModulo(FakeBoardStateTransform):\n",
    "    \"\"\"\n",
    "    Transformation that transforms real board states into fake features.\n",
    "    Categorical [8, 8] -> one-hot [8, 8, 3] -> flatten [192]\n",
    "    -> random matrix [192] -> reshape [8, 8, 3] -> argmax -> Categorical [8, 8]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"modulo\"\n",
    "        self.linear = nn.Linear(64, 64, bias=False)\n",
    "        with t.no_grad():\n",
    "            # random {-1, 0, 1}\n",
    "            new_weights = t.randint(0, 3, self.linear.weight.shape) - 1\n",
    "            self.linear.weight.copy_(new_weights.float())\n",
    "\n",
    "    def forward(self, board_state):\n",
    "        # Categorical -> vector\n",
    "        batch, seq_len, rows, cols = board_state.shape\n",
    "        board_flat = einops.rearrange(\n",
    "            board_state.long().float(), \"batch seq rows cols -> batch seq (rows cols)\"\n",
    "        )\n",
    "\n",
    "        # Vector ---fake---> vector\n",
    "        fake_features = self.linear(board_flat) % 3\n",
    "\n",
    "        # Vector -> categorical\n",
    "        fake_features_reshaped = einops.rearrange(\n",
    "            fake_features,\n",
    "            \"batch seq (rows cols) -> batch seq rows cols\",\n",
    "            rows=rows,\n",
    "            cols=cols,\n",
    "        )\n",
    "        fake_state = fake_features_reshaped.floor().long()\n",
    "\n",
    "        unique_values = t.unique(fake_state)\n",
    "        assert t.all(\n",
    "            t.isin(unique_values, t.tensor([0, 1, 2], device=fake_state.device))\n",
    "        ), f\"Output contains invalid classes: {unique_values}. Expected only [0, 1, 2]\"\n",
    "\n",
    "        return fake_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OoPV4riSlp_q"
   },
   "outputs": [],
   "source": [
    "def analyze_transform(\n",
    "    train_board_state_dataset,\n",
    "    fake_board_state_transform,\n",
    "    othello_rule,\n",
    "    pos_start=5,\n",
    "    pos_end=-5,\n",
    "    n_samples=500,\n",
    "):\n",
    "    # Sample games\n",
    "    indices = np.random.choice(\n",
    "        len(train_board_state_dataset),\n",
    "        min(n_samples, len(train_board_state_dataset)),\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    # Get board states\n",
    "    games_square = train_board_state_dataset.board_seqs_square[indices]\n",
    "    state = get_board_states_and_legal_moves(games_square, othello_rule)[0]\n",
    "\n",
    "    if not fake_board_state_transform or fake_board_state_transform.name in [\n",
    "        \"placed_before\",\n",
    "        \"modulo\",\n",
    "    ]:\n",
    "        # Transform: {0: empty, 1: black, -1: white} to {0: empty, 1: theirs, 2: mine}\n",
    "        state[:, ::2][state[:, ::2] == -1] = 2\n",
    "        state[:, 1::2][state[:, 1::2] == 1] = 2\n",
    "        state[:, 1::2][state[:, 1::2] == -1] = 1\n",
    "\n",
    "    # Slice and transform\n",
    "    original_states = state[:, pos_start:pos_end]\n",
    "    if fake_board_state_transform:\n",
    "        with t.no_grad():\n",
    "            fake_states = fake_board_state_transform(original_states)\n",
    "    else:\n",
    "        fake_states = original_states\n",
    "\n",
    "    # Correlation\n",
    "    original_flat = original_states.flatten().cpu().numpy()\n",
    "    fake_flat = fake_states.flatten().cpu().numpy()\n",
    "    correlation = pearsonr(original_flat, fake_flat)[0]\n",
    "\n",
    "    # Field-wise accuracy (64 predictions)\n",
    "    accuracies_fake = []\n",
    "    accuracies_original = []\n",
    "    for r in range(8):\n",
    "        for c in range(8):\n",
    "            fake_field = fake_states[:, :, r, c].flatten().cpu().numpy()\n",
    "            orig_field = original_states[:, :, r, c].flatten().cpu().numpy()\n",
    "\n",
    "            # Most common fake value for this field\n",
    "            most_common_fake = np.bincount(fake_field).argmax()\n",
    "            most_common_original = np.bincount(orig_field).argmax()\n",
    "\n",
    "            # Accuracy if always predicting most_common\n",
    "            accuracy_fake = (most_common_fake == fake_field).mean()\n",
    "            accuracies_fake.append(accuracy_fake)\n",
    "            accuracy_original = (most_common_original == orig_field).mean()\n",
    "            accuracies_original.append(accuracy_original)\n",
    "\n",
    "    print(f\"Correlation: {correlation:.4f}\")\n",
    "    print(f\"Mean field accuracy - Fake: {np.mean(accuracies_fake):.4f}\")\n",
    "    print(f\"Mean field accuracy - Original: {np.mean(accuracies_original):.4f}\")\n",
    "\n",
    "    # Original state value distribution\n",
    "    print(\"Original State Values (%):\")\n",
    "    orig_vals, orig_counts = np.unique(original_flat, return_counts=True)\n",
    "    for value, count in zip(orig_vals, orig_counts):\n",
    "        percentage = (count / len(original_flat)) * 100\n",
    "        print(f\"  Value {int(value)}: {percentage:.2f}%\")\n",
    "\n",
    "    # Fake state value distribution\n",
    "    print(\"\\nFake State Values (%):\")\n",
    "    fake_vals, fake_counts = np.unique(fake_flat, return_counts=True)\n",
    "    for value, count in zip(fake_vals, fake_counts):\n",
    "        percentage = (count / len(fake_flat)) * 100\n",
    "        print(f\"  Value {int(value)}: {percentage:.2f}%\")\n",
    "\n",
    "\n",
    "# fake_board_state_transform = FakeBoardStateTransform()\n",
    "# analyze_transform(train_board_state_dataset, None,\n",
    "#                              OthelloRule.STANDARD, n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNdXLKRdbPXZ"
   },
   "source": [
    "### evaluate_probe_generalization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pxCtqNS1NYSw"
   },
   "outputs": [],
   "source": [
    "def evaluate_probe_generalization(\n",
    "    probe,\n",
    "    model,\n",
    "    board_seqs_square_test,\n",
    "    board_seqs_id_test,\n",
    "    layer,\n",
    "    device,\n",
    "    othello_rule: OthelloRule,\n",
    "    plot_results=True,\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "):\n",
    "    # Focus games\n",
    "    focus_games_id = board_seqs_id_test  # shape [n_games, 60]\n",
    "    focus_games_square = board_seqs_square_test  # shape [n_games, 60]\n",
    "    focus_states, focus_legal_moves, focus_legal_moves_annotation = (\n",
    "        get_board_states_and_legal_moves(focus_games_square, othello_rule)\n",
    "    )\n",
    "\n",
    "    # Focus cache\n",
    "    focus_logits, focus_cache = model.run_with_cache(focus_games_id[:, :-1].to(device))\n",
    "\n",
    "    # Focus their vs. mine (0: empty, 1: theirs, 2: mine)\n",
    "    focus_states_theirs_vs_mine = (\n",
    "        focus_states\n",
    "        * (-1 + 2 * (t.arange(focus_states.shape[1]) % 2))[None, :, None, None]\n",
    "    )\n",
    "    focus_states_theirs_vs_mine[focus_states_theirs_vs_mine == 1] = 2\n",
    "    focus_states_theirs_vs_mine[focus_states_theirs_vs_mine == -1] = 1\n",
    "\n",
    "    if fake_board_state_transform:\n",
    "        focus_states_theirs_vs_mine = fake_board_state_transform(\n",
    "            focus_states_theirs_vs_mine\n",
    "        )\n",
    "\n",
    "    # Here, we test out each of our 3 probe modes (even / odd / both) on each of these 3 settings\n",
    "    # (even / odd / both). Hopefully we should see all 3 probes generalize!\n",
    "    probe_out = einops.einsum(\n",
    "        focus_cache[\"resid_post\", layer],\n",
    "        probe,\n",
    "        \"game move d_model, mode d_model row col options -> mode game move row col options\",\n",
    "    )\n",
    "    probe_out_value = probe_out.argmax(dim=-1).cpu()  # mode game move row col\n",
    "\n",
    "    # For each mode, get the accuracy on even / odd / both\n",
    "    is_correct = (\n",
    "        probe_out_value == focus_states_theirs_vs_mine[:, :-1]\n",
    "    )  # mode game move row col\n",
    "    accuracies_even = einops.reduce(\n",
    "        is_correct[:, 6:-6:2].float(), \"mode game move row col -> mode row col\", \"mean\"\n",
    "    )\n",
    "    accuracies_odd = einops.reduce(\n",
    "        is_correct[:, 5:-5:2].float(), \"mode game move row col -> mode row col\", \"mean\"\n",
    "    )\n",
    "    accuracies_all = einops.reduce(\n",
    "        is_correct[:, 5:-5].float(), \"mode game move row col -> mode row col\", \"mean\"\n",
    "    )\n",
    "\n",
    "    # Print diagonal accuracies (probe mode matching data split)\n",
    "    mean_accuracy_even_on_even = accuracies_even[0].mean()  # mode 0 = even probe\n",
    "    mean_accuracy_odd_on_odd = accuracies_odd[1].mean()  # mode 1 = odd probe\n",
    "    mean_accuracy_both_on_all = accuracies_all[2].mean()  # mode 2 = both probe\n",
    "\n",
    "    # Get all 3x3 accuracies, stacked over first dim\n",
    "    accuracies_stacked = t.concat(\n",
    "        [accuracies_even, accuracies_odd, accuracies_all], dim=0\n",
    "    )\n",
    "\n",
    "    # Plot results!\n",
    "    board_titles = [\n",
    "        f\"{probe_mode} probe on {data_mode} data\"\n",
    "        for data_mode in [\"even\", \"odd\", \"all\"]\n",
    "        for probe_mode in [\"even\", \"odd\", \"both\"]\n",
    "    ]\n",
    "\n",
    "    fig = plot_board_values(\n",
    "        1 - accuracies_stacked,\n",
    "        title=\"Average Error Rate of Linear Probe\",\n",
    "        board_titles=board_titles,\n",
    "        boards_per_row=3,\n",
    "        zmax=0.25,\n",
    "        zmin=-0.25,\n",
    "        height=1000,\n",
    "        width=900,\n",
    "        show=plot_results,\n",
    "    )\n",
    "    return (\n",
    "        fig,\n",
    "        mean_accuracy_even_on_even,\n",
    "        mean_accuracy_odd_on_odd,\n",
    "        mean_accuracy_both_on_all,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7taVfY8YIIm"
   },
   "source": [
    "### linear_multi_probe_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "L6VhGIIT0XLh"
   },
   "outputs": [],
   "source": [
    "class BoardStateDataset:\n",
    "    def __init__(self, char_dataset: CharDataset, n_games: int):\n",
    "        self.char_dataset = char_dataset\n",
    "        self.board_seqs_square, self.board_seqs_id, self.n_skipped = (\n",
    "            get_board_seqs_square_and_id(self.char_dataset, n_games)\n",
    "        )\n",
    "        print(\"Skipped {} games\".format(self.n_skipped))\n",
    "        self.n_games = len(self.board_seqs_square)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert self.n_games == len(self.board_seqs_square)\n",
    "        return self.n_games\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MultiProbeTrainingArgs:\n",
    "    device: str\n",
    "\n",
    "    # Data to train on\n",
    "    othello_rule: OthelloRule = OthelloRule.STANDARD  # What to train on\n",
    "    modes: int = 3  # even, odd, both (i.e. the data we train on)\n",
    "    layer: int = 6\n",
    "    pos_start: int = 5\n",
    "    pos_end: int = -5  # i.e. we slice [pos_start: model.n_ctx + pos_end]\n",
    "\n",
    "    # Game state (options are blank/mine/theirs)\n",
    "    options: int = 3\n",
    "    rows: int = 8\n",
    "    cols: int = 8\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None\n",
    "\n",
    "    # Training\n",
    "    epochs: int = 5\n",
    "    validate_every_n_steps: int = 100\n",
    "    early_stopping_patience: int = 10\n",
    "    n_tokens_to_test_and_val: int = 100\n",
    "    batch_size: int = 32  # Can't be too big, because of memory problems if we load the activations of a model\n",
    "    lr: float = 1e-4  # high for quick testing\n",
    "    betas: tuple[float, float] = (0.9, 0.99)\n",
    "    weight_decay: float = 0.01\n",
    "\n",
    "    # Wandb\n",
    "    experiment_folder: str = \"\"\n",
    "    experiment_name: str = \"\"\n",
    "\n",
    "    use_wandb: bool = True\n",
    "    wandb_project: str | None = None\n",
    "    wandb_name: str | None = None\n",
    "\n",
    "    def setup_linear_probe(self, model: HookedTransformer):\n",
    "        linear_probe = t.randn(\n",
    "            self.modes,\n",
    "            model.cfg.d_model,\n",
    "            self.rows,\n",
    "            self.cols,\n",
    "            self.options,\n",
    "            device=self.device,\n",
    "        ) / np.sqrt(model.cfg.d_model)\n",
    "        linear_probe.requires_grad = True\n",
    "        return linear_probe\n",
    "\n",
    "\n",
    "class LinearMultiProbeTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: HookedTransformer,\n",
    "        args: MultiProbeTrainingArgs,\n",
    "        train_board_state_dataset: BoardStateDataset | None,\n",
    "        val_board_state_dataset: BoardStateDataset | None,\n",
    "        othello_rule_to_board_state_test_dataset: dict[\n",
    "            OthelloRule, list[BoardStateDataset]\n",
    "        ]\n",
    "        | None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "        self.linear_probe = args.setup_linear_probe(self.model)\n",
    "        self.train_board_state_dataset = train_board_state_dataset\n",
    "        self.val_board_state_dataset = val_board_state_dataset\n",
    "        self.othello_rule_to_board_state_test_dataset = (\n",
    "            othello_rule_to_board_state_test_dataset\n",
    "        )\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        \"\"\"Save linear probe and training state.\"\"\"\n",
    "        save_model(\n",
    "            model=self.linear_probe.detach().cpu(),\n",
    "            run_id=self.run_id,\n",
    "            project_name=self.args.wandb_project,\n",
    "            experiment_name=self.args.experiment_name,\n",
    "            experiment_folder=self.args.experiment_folder,\n",
    "            index=0,\n",
    "            overwrite=True,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "\n",
    "    def _get_mean_loss(\n",
    "        self, games_id, games_square, wandb_folder: str, othello_rule: OthelloRule\n",
    "    ):\n",
    "        pos_start = self.args.pos_start\n",
    "        # pos_end = self.args.pos_end + self.model.cfg.n_ctx\n",
    "        pos_end = self.args.pos_end + 61  # TODO CURRENTLY HARDCODED FOR OTHELLO\n",
    "\n",
    "        # Cache resid_post from all our games (ignoring the last one)\n",
    "        with t.inference_mode():\n",
    "            _, cache = self.model.run_with_cache(\n",
    "                games_id[:, :-1].to(self.args.device),\n",
    "                return_type=None,\n",
    "                names_filter=lambda name: name.endswith(\"resid_post\"),\n",
    "            )\n",
    "\n",
    "        # We're training on all modes, so we slice all resid values in our range.\n",
    "        resid_post = cache[\"resid_post\", self.args.layer][:, pos_start:pos_end]\n",
    "\n",
    "        # Get probe output, i.e. probe_logits[m, g, p, r, c] = the 3-vector of logit predictions from\n",
    "        # mode-m probe, for what color is in square [r, c] AFTER the p-th move is played in game g.\n",
    "        probe_logits = einops.einsum(\n",
    "            resid_post,\n",
    "            self.linear_probe,\n",
    "            \"game pos d_model, mode d_model rows cols options -> mode game pos rows cols options\",\n",
    "        )\n",
    "        probe_logprobs = probe_logits.log_softmax(-1)\n",
    "\n",
    "        # Get the actual game state. The original state has {0: empty, 1: black, -1: white} and\n",
    "        # we want our probe to be in the basis {0: empty, 1: theirs, 2: mine}. For even moves,\n",
    "        # mine = white, so we map -1 -> 2. For odd moves, mine = black, so we map {1, -1} -> {2, 1}.\n",
    "        state = get_board_states_and_legal_moves(games_square, othello_rule)[0]\n",
    "        if not fake_board_state_transform or fake_board_state_transform.name in [\n",
    "            \"placed_before\",\n",
    "            \"modulo\",\n",
    "        ]:\n",
    "            # Transform: {0: empty, 1: black, -1: white} to {0: empty, 1: theirs, 2: mine}\n",
    "            state[:, ::2][state[:, ::2] == -1] = 2\n",
    "            state[:, 1::2][state[:, 1::2] == 1] = 2\n",
    "            state[:, 1::2][state[:, 1::2] == -1] = 1\n",
    "        else:\n",
    "            # Transform: {0: empty, 1: black, -1: white} to {0: empty, 1: black, 2: white}\n",
    "            state[state == -1] = 2\n",
    "\n",
    "        if self.args.fake_board_state_transform:\n",
    "            state = self.args.fake_board_state_transform(state)\n",
    "        # pos_start -> pos_end\n",
    "        state = state[:, pos_start:pos_end]\n",
    "\n",
    "        # Index into the probe logprobs with the correct indices (note, each of our 3 probe modes\n",
    "        # gives us a different tensor of logprobs).\n",
    "        # In _get_mean_loss, before eindex:\n",
    "        correct_probe_logprobs = eindex(\n",
    "            probe_logprobs,\n",
    "            state,\n",
    "            \"mode game pos row col [game pos row col]\",  # -> shape [mode game pos row col]\n",
    "        )\n",
    "        # Get the logprobs we'll be using for our 3 different probes. Remember that for the even\n",
    "        # and odd probes we need to take only the even/odd moves respectively (and also that we've\n",
    "        # already sliced logprobs from pos_start: pos_end).\n",
    "        pos_start_even, pos_start_odd = (0, 1) if pos_start % 2 == 0 else (1, 0)\n",
    "        even_probe_logprobs = correct_probe_logprobs[0, pos_start_even::2]\n",
    "        odd_probe_logprobs = correct_probe_logprobs[1, pos_start_odd::2]\n",
    "        both_probe_logprobs = correct_probe_logprobs[2]\n",
    "        # Get our 3 different loss functions\n",
    "        loss_even = -einops.reduce(\n",
    "            even_probe_logprobs, \"game pos row col -> row col\", \"mean\"\n",
    "        ).sum()\n",
    "        loss_odd = -einops.reduce(\n",
    "            odd_probe_logprobs, \"game pos row col -> row col\", \"mean\"\n",
    "        ).sum()\n",
    "        loss_both = -einops.reduce(\n",
    "            both_probe_logprobs, \"game pos row col -> row col\", \"mean\"\n",
    "        ).sum()\n",
    "        # We backprop on the sum of all 3 losses\n",
    "        loss = loss_even + loss_odd + loss_both\n",
    "\n",
    "        if self.args.use_wandb:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    wandb_folder + \"loss\": loss.item(),\n",
    "                    # wandb_folder + \"loss_even\": loss_even.item(),\n",
    "                    # wandb_folder + \"loss_odd\": loss_odd.item(),\n",
    "                    # wandb_folder + \"loss_both\": loss_both.item(),\n",
    "                },\n",
    "                step=self.step,\n",
    "            )\n",
    "        return loss\n",
    "\n",
    "    def shuffle_training_indices(self):\n",
    "        \"\"\"\n",
    "        Returns the tensors you'll use to index into the training data.\n",
    "        \"\"\"\n",
    "        num_games = len(self.train_board_state_dataset)\n",
    "        n_indices = num_games - (num_games % self.args.batch_size)\n",
    "        full_train_indices = t.randperm(num_games)[:n_indices]\n",
    "        full_train_indices = einops.rearrange(\n",
    "            full_train_indices,\n",
    "            \"(batch_idx game_idx) -> batch_idx game_idx\",\n",
    "            game_idx=self.args.batch_size,\n",
    "        )\n",
    "        return full_train_indices\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        self.model.train(False)\n",
    "        indices = random.sample(\n",
    "            range(len(self.val_board_state_dataset)),\n",
    "            min(self.args.n_tokens_to_test_and_val, len(self.val_board_state_dataset)),\n",
    "        )\n",
    "        games_id = self.val_board_state_dataset.board_seqs_id[indices]\n",
    "        games_square = self.val_board_state_dataset.board_seqs_square[indices]\n",
    "        loss = self._get_mean_loss(\n",
    "            games_id,\n",
    "            games_square,\n",
    "            wandb_folder=\"val/\",\n",
    "            othello_rule=self.args.othello_rule,\n",
    "        )\n",
    "\n",
    "        if loss < self.best_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.best_loss = loss\n",
    "            self.save_checkpoint()\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "\n",
    "        if self.patience_counter >= self.args.early_stopping_patience:\n",
    "            print(f\"Early Stop Triggered at step {self.step}\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def test(self):\n",
    "        self.model.train(False)\n",
    "        for (\n",
    "            othello_rule,\n",
    "            dataset,\n",
    "        ) in self.othello_rule_to_board_state_test_dataset.items():\n",
    "            indices = random.sample(\n",
    "                range(len(dataset)),\n",
    "                min(self.args.n_tokens_to_test_and_val, len(dataset)),\n",
    "            )\n",
    "            games_id = dataset.board_seqs_id[indices]\n",
    "            games_square = dataset.board_seqs_square[indices]\n",
    "            loss = self._get_mean_loss(\n",
    "                games_id,\n",
    "                games_square,\n",
    "                wandb_folder=f\"test/{othello_rule.value}_\",\n",
    "                othello_rule=othello_rule,\n",
    "            )\n",
    "            if self.args.use_wandb:\n",
    "                (\n",
    "                    fig,\n",
    "                    mean_accuracy_even_on_even,\n",
    "                    mean_accuracy_odd_on_odd,\n",
    "                    mean_accuracy_both_on_all,\n",
    "                ) = evaluate_probe_generalization(\n",
    "                    self.linear_probe,\n",
    "                    self.model,\n",
    "                    games_square,\n",
    "                    games_id,\n",
    "                    self.args.layer,\n",
    "                    DEVICE,\n",
    "                    othello_rule,\n",
    "                    plot_results=False,\n",
    "                    fake_board_state_transform=self.args.fake_board_state_transform,\n",
    "                )\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"test/mean_accuracy_even_on_even\": mean_accuracy_even_on_even,\n",
    "                        \"test/mean_accuracy_odd_on_odd\": mean_accuracy_odd_on_odd,\n",
    "                        \"test/mean_accuracy_both_on_all\": mean_accuracy_both_on_all,\n",
    "                        \"test/mean_accuracy\": wandb.Plotly(fig),\n",
    "                    },\n",
    "                    step=self.step,\n",
    "                )\n",
    "\n",
    "    def train(self):\n",
    "        assert self.train_board_state_dataset is not None\n",
    "        assert self.val_board_state_dataset is not None\n",
    "        assert self.othello_rule_to_board_state_test_dataset is not None\n",
    "        self.step = 0\n",
    "        self.run_id = 0\n",
    "        if self.args.use_wandb:\n",
    "            wandb.init(\n",
    "                project=self.args.wandb_project,\n",
    "                name=self.args.wandb_name,\n",
    "                config=self.args,\n",
    "            )\n",
    "            self.run_id = wandb.run.id\n",
    "\n",
    "        optimizer = t.optim.AdamW(\n",
    "            [self.linear_probe],\n",
    "            lr=self.args.lr,\n",
    "            betas=self.args.betas,\n",
    "            weight_decay=self.args.weight_decay,\n",
    "        )\n",
    "\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        early_stopped = False\n",
    "        for epoch in range(self.args.epochs):\n",
    "            if early_stopped:\n",
    "                break\n",
    "            print(f\"Epoch {epoch + 1}/{self.args.epochs}\")\n",
    "            full_train_indices = self.shuffle_training_indices()\n",
    "            progress_bar = tqdm(full_train_indices)\n",
    "            for indices in progress_bar:\n",
    "                if early_stopped:\n",
    "                    break\n",
    "                games_id = self.train_board_state_dataset.board_seqs_id[\n",
    "                    indices\n",
    "                ]  # shape [batch n_moves=60]\n",
    "                games_square = self.train_board_state_dataset.board_seqs_square[\n",
    "                    indices\n",
    "                ]  # shape [batch n_moves=60]\n",
    "                loss = self._get_mean_loss(\n",
    "                    games_id,\n",
    "                    games_square,\n",
    "                    wandb_folder=\"train/\",\n",
    "                    othello_rule=self.args.othello_rule,\n",
    "                )\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.set_description(f\"Loss = {loss:.4f}\")\n",
    "\n",
    "                if self.step % self.args.validate_every_n_steps == 0:\n",
    "                    early_stopped = self.validate()\n",
    "                    self.test()\n",
    "\n",
    "                self.step += 1\n",
    "\n",
    "        if self.args.use_wandb:\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD0hMaHVN0ih"
   },
   "source": [
    "# --- Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "b-uoUhhdRF-M"
   },
   "outputs": [],
   "source": [
    "def get_othello_rules_with_data():\n",
    "    return [\n",
    "        OthelloRule.STANDARD\n",
    "    ]  # , OthelloRule.BIAS_CLOCK, OthelloRule.NEXT_TO_OPPONENT, OthelloRule.NO_FLIPPING]\n",
    "\n",
    "\n",
    "def get_othello_rule(goal: Goal) -> OthelloRule:\n",
    "    if goal == Goal.WEAK_GOAL:\n",
    "        return OthelloRule.STANDARD\n",
    "    elif goal == Goal.STRONG_GOAL:\n",
    "        # return OthelloRule.BIAS_CLOCK\n",
    "        return OthelloRule.NEXT_TO_OPPONENT\n",
    "        # return OthelloRule.CHESS\n",
    "        # return OthelloRule.UNTRAINED\n",
    "        # return OthelloRule.CONSTANT_PARAMETERS\n",
    "        # return OthelloRule.NO_FLIPPING\n",
    "    else:\n",
    "        raise Exception(f\"Unknown goal: {goal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O32GEknzUgx0"
   },
   "source": [
    "Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJuk12gDRWUd",
    "outputId": "59b280b7-5ade-47d0-82cc-795127e41cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train games\n",
      "Loaded weak_finetune games\n",
      "Loaded val games\n",
      "Loaded: 26539984 train, 13271044 weak_finetune, 4423295 val, 8853073 test games\n",
      "Skipped 0 games\n",
      "Skipped 0 games\n",
      "Skipped 0 games\n"
     ]
    }
   ],
   "source": [
    "## Data for get_othello_rules_with_data ###\n",
    "# data sets\n",
    "othello = Othello(data_folder, OthelloRule.STANDARD)\n",
    "#### othello.generate_train_weakfinetune_val_test_split()\n",
    "othello.load_train_weakfinetune_val_test()\n",
    "train_dataset = CharDataset(othello.train)\n",
    "val_dataset = CharDataset(othello.val)\n",
    "test_dataset = CharDataset(othello.test)\n",
    "weak_finetune_dataset = CharDataset(othello.weak_finetune)\n",
    "othello_rule_to_test = {}\n",
    "\n",
    "# test data\n",
    "for rule in get_othello_rules_with_data():\n",
    "    othello_rule_to_test[rule] = CharDataset(othello.othello_rule_to_test[rule])\n",
    "\n",
    "# data to train linear probe\n",
    "train_board_state_dataset = BoardStateDataset(train_dataset, 150000)\n",
    "val_board_state_dataset = BoardStateDataset(val_dataset, 100)\n",
    "othello_rule_to_board_state_test_dataset = {}\n",
    "for rule in get_othello_rules_with_data():\n",
    "    char_test_data = othello_rule_to_test[rule]\n",
    "    othello_rule_to_board_state_test_dataset[rule] = BoardStateDataset(\n",
    "        char_test_data, 100\n",
    "    )\n",
    "\n",
    "# ## Data for extra rules ###\n",
    "# for rule in OthelloRule:\n",
    "#     if rule not in othello_rule_to_test:\n",
    "#         othello_rule_to_test[rule] = othello_rule_to_test[OthelloRule.STANDARD]\n",
    "\n",
    "# for rule in OthelloRule:\n",
    "#     if rule not in othello_rule_to_board_state_test_dataset:\n",
    "#         othello_rule_to_board_state_test_dataset[rule] = othello_rule_to_board_state_test_dataset[OthelloRule.STANDARD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wmlLSMNYKyWo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35c0-p14UiYN"
   },
   "source": [
    "Load only test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "b32Gs_cC2Iii"
   },
   "outputs": [],
   "source": [
    "# othello = Othello(data_folder, OthelloRule.STANDARD)\n",
    "# othello.load_test()\n",
    "# othello_rule_to_test = {}\n",
    "# othello_rule_to_board_state_test_dataset = {}\n",
    "# for rule in get_othello_rules_with_data():\n",
    "#     othello_rule_to_test[rule] = CharDataset(othello.othello_rule_to_test[rule])\n",
    "#     othello_rule_to_board_state_test_dataset[rule] = BoardStateDataset(othello_rule_to_test[rule], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "h7nUAceAo9df"
   },
   "outputs": [],
   "source": [
    "# othello = Othello(data_folder, OthelloRule.NEXT_TO_OPPONENT)\n",
    "# games = othello.load_games(1000)\n",
    "# dataset = CharDataset(games)\n",
    "# board_seqs_square, board_seqs_id, n_skipped = get_board_seqs_square_and_id(othello_rule_to_test[OthelloRule.NEXT_TO_OPPONENT], 10000)\n",
    "# print(f\"Skipped {n_skipped} games\")\n",
    "# plot_average_move_index(board_seqs_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "eYLb4I7FGO1y",
    "outputId": "4d43d44b-e1d3-4d4a-ea87-bd74b8c99bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 45, 46, 52, 59, 47, 19, 20, 21, 26, 38, 12, 43, 60, 54, 34, 18, 14, 33, 17, 61, 63, 10, 30, 31, 25, 62, 9, 13, 32, 29, 58, 7, 3, 1, 6, 40, 15, 4, 22, 0, 42, 2, 48, 23, 41, 24, 5, 49, 11, 39, 56, 37, 16, 51, 53, 57, 8, 55]\n",
      "['F4', 'F5', 'F6', 'G4', 'H3', 'F7', 'C3', 'C4', 'C5', 'D2', 'E6', 'B4', 'F3', 'H4', 'G6', 'E2', 'C2', 'B6', 'E1', 'C1', 'H5', 'H7', 'B2', 'D6', 'D7', 'D1', 'H6', 'B1', 'B5', 'E0', 'D5', 'H2', 'A7', 'A3', 'A1', 'A6', 'F0', 'B7', 'A4', 'C6', 'A0', 'F2', 'A2', 'G0', 'C7', 'F1', 'D0', 'A5', 'G1', 'B3', 'E7', 'H0', 'E5', 'C0', 'G3', 'G5', 'H1', 'B0', 'G7']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6b1c5265-67c9-4701-80a8-c3e6ba4ac3ad\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b1c5265-67c9-4701-80a8-c3e6ba4ac3ad\")) {                    Plotly.newPlot(                        \"6b1c5265-67c9-4701-80a8-c3e6ba4ac3ad\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"],\"y\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"],\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,-1,1,0,0,0],[0,0,0,1,-1,0,0,0],[0,0,0,0,1,-1,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"colorscale\":[[0,\"#ff0c0c\"],[1,\"#ff0c0c\"]],\"showscale\":false,\"z\":[[null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null],[null,null,null,1.0,null,null,null,null],[null,null,1.0,null,null,null,null,null],[null,null,null,null,null,1.0,null,null],[null,null,null,null,null,null,1.0,null],[null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.18400000000000002],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.20400000000000001,0.388],\"matches\":\"x\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.40800000000000003,0.5920000000000001],\"matches\":\"x\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.6120000000000001,0.7960000000000002],\"matches\":\"x\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.8160000000000001,1.0],\"matches\":\"x\"},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"State after move 1\",\"x\":0.09200000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(255,255,255)\"],[0.125,\"rgb(240,240,240)\"],[0.25,\"rgb(217,217,217)\"],[0.375,\"rgb(189,189,189)\"],[0.5,\"rgb(150,150,150)\"],[0.625,\"rgb(115,115,115)\"],[0.75,\"rgb(82,82,82)\"],[0.875,\"rgb(37,37,37)\"],[1.0,\"rgb(0,0,0)\"]],\"cmin\":-1,\"cmax\":1,\"showscale\":false},\"title\":{\"text\":\"Board states\"},\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6b1c5265-67c9-4701-80a8-c3e6ba4ac3ad');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example_game = othello.train[0]\n",
    "example_game = [to_square(i) for i in train_dataset[0][0].tolist()]\n",
    "# example_game = othello_rule_to_test[OthelloRule.STANDARD].data[0]\n",
    "# example_game = [to_square(i) for i in othello_rule_to_test[OthelloRule.STANDARD][0][0].tolist()]\n",
    "print(example_game)\n",
    "print([to_label(to_id(s)) for s in example_game])\n",
    "plot_game_moves(example_game, [1], othello_rule=OthelloRule.STANDARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "M3gwrPE1vaUI"
   },
   "outputs": [],
   "source": [
    "# entropy = calculate_legal_move_entropy(othello_rule_to_test[OthelloRule.NEXT_TO_OPPONENT], 10000, OthelloRule.NEXT_TO_OPPONENT)\n",
    "# print(f\"Legal move uniform entropy: {entropy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdfy6jmhFtgU",
    "outputId": "5520fff7-d9f8-4c0f-ec3a-e53915c3e0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FakeBoardStateTransformModulo(\n",
      "  (linear): Linear(in_features=64, out_features=64, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def load_fake_board_state_transform(\n",
    "    experiment_folder: str, fake_board_state_name: str, device: str, overwrite=False\n",
    "):\n",
    "    path = os.path.join(\n",
    "        experiment_folder, f\"fake_board_state_transform_{fake_board_state_name}.pt\"\n",
    "    )\n",
    "    if not overwrite and os.path.exists(path):\n",
    "        return t.load(path, map_location=device, weights_only=False)\n",
    "    else:\n",
    "        if fake_board_state_name == \"placed_before\":\n",
    "            transform = FakeBoardStateTransformPlacedBefore()\n",
    "        elif fake_board_state_name == \"black_white\":\n",
    "            transform = FakeBoardStateTransformBlackWhite()\n",
    "        elif fake_board_state_name == \"modulo\":\n",
    "            transform = FakeBoardStateTransformModulo()\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Unknown fake board state transform: {fake_board_state_name}\"\n",
    "            )\n",
    "        assert transform.name == fake_board_state_name\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        t.save(transform, path)\n",
    "        return transform\n",
    "\n",
    "\n",
    "# fake_board_state_name = 'placed_before'\n",
    "# fake_board_state_name = 'black_white'\n",
    "fake_board_state_name = \"modulo\"\n",
    "fake_board_state_transform = load_fake_board_state_transform(\n",
    "    experiment_folder, fake_board_state_name, DEVICE, overwrite=False\n",
    ")\n",
    "print(fake_board_state_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "oQp8yowuZfD6",
    "outputId": "643cb77f-44fa-4dcd-9b04-3c21e77932f3"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1456987571.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibUnvgVDT2sc"
   },
   "source": [
    "# --- Run Single ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6KeGvQd-xri"
   },
   "source": [
    "### Load OthelloGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4nHYW2XT1-T"
   },
   "outputs": [],
   "source": [
    "othello_gpt = load_othello_gpt(device=DEVICE)\n",
    "get_model_size(othello_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foPiTL1TT4dM"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "results = test_hooked_transformer(\n",
    "    othello_gpt,\n",
    "    othello_rule=OthelloRule.STANDARD,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=512,\n",
    "    n_games=10000,\n",
    "    device=DEVICE,\n",
    ")\n",
    "print(\"\")\n",
    "print(f\"Validation CE Loss: {results['ce_loss']:.6f}\")\n",
    "print(f\"Illegal Move %: {results['illegal_move_percentage']:.6f}%\")\n",
    "print(f\"Total Predictions: {results['total_predictions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLI0jsAcxzDq"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "results = test_hooked_transformer(\n",
    "    hooked_model,\n",
    "    othello_rule=OthelloRule.STANDARD,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=512,\n",
    "    n_games=10000,\n",
    "    device=DEVICE,\n",
    ")\n",
    "print(\"\")\n",
    "print(f\"Validation CE Loss: {results['ce_loss']:.6f}\")\n",
    "print(f\"Illegal Move %: {results['illegal_move_percentage']:.6f}%\")\n",
    "print(f\"Total Predictions: {results['total_predictions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6phKVorZgBJ"
   },
   "outputs": [],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8PxZcUe0zJL"
   },
   "source": [
    "### Pretrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwJL2tBgo5-r"
   },
   "outputs": [],
   "source": [
    "def pretrain_model(\n",
    "    model_size: ModelSize,\n",
    "    othello_rule: OthelloRule,\n",
    "    train_dataset: CharDataset,\n",
    "    val_dataset: CharDataset,\n",
    "    othello_rule_to_test: dict[OthelloRule, list[CharDataset]],\n",
    "    experiment_folder: str,\n",
    "    project_name: str,\n",
    "):\n",
    "    assert othello_rule is not OthelloRule.UNTRAINED\n",
    "    model_cfg = get_model_config(model_size, train_dataset)\n",
    "    model = GPT(model_cfg)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    experiment_name = get_experiment_name_pretrained(model_size, othello_rule, index=0)\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "\n",
    "    max_epochs = 2\n",
    "    validate_n_times = 100\n",
    "    batch_size = 512\n",
    "    validate_every_n_steps = int(\n",
    "        max_epochs * len(train_dataset) / (validate_n_times * batch_size)\n",
    "    )\n",
    "    print(\"validate_every_n_steps: \", validate_every_n_steps)\n",
    "    # initialize a trainer instance and kick off training\n",
    "    t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    trainer_cfg = TrainerConfig(\n",
    "        max_epochs=max_epochs,\n",
    "        early_stopping_patience=float(\"inf\"),\n",
    "        validate_every_n_steps=validate_every_n_steps,\n",
    "        weight_decay=0.1,\n",
    "        batch_size=batch_size,  #  We only have one GPU\n",
    "        learning_rate=5e-4,  # 5e-4\n",
    "        betas=(0.9, 0.95),\n",
    "        grad_norm_clip=1.0,\n",
    "        lr_decay=True,\n",
    "        warmup_tokens=len(train_dataset)\n",
    "        * train_dataset.block_size\n",
    "        * max_epochs\n",
    "        * 0.05,  # Warum up over first 5%\n",
    "        final_tokens=len(train_dataset) * train_dataset.block_size * max_epochs,\n",
    "        num_workers=0,  # For dataloader, was 1 before\n",
    "        n_tokens_to_test_and_val=10**4,\n",
    "        n_games_to_test_legal_moves=20,\n",
    "        # checkpoint settings\n",
    "        save_model=True,\n",
    "        save_every_validation=False,\n",
    "        experiment_folder=experiment_folder,\n",
    "        project_name=project_name,\n",
    "        experiment_name=experiment_name,\n",
    "        model_size=model_size,\n",
    "        othello_rule=othello_rule,\n",
    "        index=0,\n",
    "        final=False,\n",
    "        # wandb\n",
    "        wandb_project=project_name,\n",
    "        use_wandb=True,\n",
    "        wandb_name=experiment_name,\n",
    "    )\n",
    "    trainer = TrainerPretrain(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        othello_rule_to_test,\n",
    "        trainer_cfg,\n",
    "        model_cfg,\n",
    "        DEVICE,\n",
    "    )\n",
    "    device = trainer.device\n",
    "    print(t_start)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "# project_name = \"pretrain_sweep_1\"\n",
    "# project_name = \"pretrain_sweep_1\"\n",
    "# pretrain_model(ModelSize.SMALL, OthelloRule.NO_FLIPPING,\n",
    "#             train_dataset, val_dataset, othello_rule_to_test,\n",
    "#             experiment_folder, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EK7cI0By3_v"
   },
   "outputs": [],
   "source": [
    "def create_untrained_model(\n",
    "    model_size,\n",
    "    experiment_folder,\n",
    "    project_name,\n",
    "    val_dataset,\n",
    "    constant_everything: bool,\n",
    "    device,\n",
    "):\n",
    "    model_cfg = get_model_config(model_size, val_dataset)\n",
    "    model = GPT(model_cfg)\n",
    "    model.to(device)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    if constant_everything:\n",
    "        othello_rule = OthelloRule.CONSTANT_PARAMETERS\n",
    "    else:\n",
    "        othello_rule = OthelloRule.UNTRAINED\n",
    "    experiment_name = get_experiment_name_pretrained(\n",
    "        model_size, othello_rule, index=0, final=False\n",
    "    )\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "    run_id = 0\n",
    "\n",
    "    hooked_transformer_model = convert_gpt_to_hooked_and_verify(\n",
    "        model, model_cfg, val_dataset, device=device\n",
    "    )\n",
    "    if constant_everything:\n",
    "        with t.no_grad():\n",
    "            for name, param in hooked_transformer_model.named_parameters():\n",
    "                if not \"embed\" in name and not name in [\n",
    "                    \"blocks.0.attn.W_Q\",\n",
    "                    \"blocks.0.attn.b_Q\",\n",
    "                    \"blocks.0.attn.W_K\",\n",
    "                    \"blocks.0.attn.b_K\",\n",
    "                ]:\n",
    "                    mean_val = param.mean().item()\n",
    "                    param.fill_(mean_val)\n",
    "\n",
    "    save_model(\n",
    "        hooked_transformer_model,\n",
    "        run_id,\n",
    "        project_name,\n",
    "        experiment_name,\n",
    "        experiment_folder,\n",
    "        index=0,\n",
    "        overwrite=True,\n",
    "        final=True,\n",
    "    )\n",
    "    return hooked_transformer_model\n",
    "\n",
    "\n",
    "# project_name = \"pretrain_sweep_1\"  # \"pretrain_sweep_1\"\n",
    "# for model_size in ModelSize:\n",
    "#     create_untrained_model(model_size, experiment_folder, project_name, val_dataset, constant_everything=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQ6obsmRZhmj"
   },
   "outputs": [],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdOSlYFi6-HI"
   },
   "source": [
    "### train_chess_gpt_embedding_matrices.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iG9OeV6B6-jS"
   },
   "outputs": [],
   "source": [
    "def train_chess_gpt_embedding_matrices(\n",
    "    model_size,\n",
    "    othello_rule,\n",
    "    experiment_folder,\n",
    "    project_name,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    othello_rule_to_test,\n",
    "    device,\n",
    "):\n",
    "    \"\"\"Complete pipeline: train projections, then create final model\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    experiment_name = get_experiment_name_pretrained(model_size, othello_rule, index=0)\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "\n",
    "    max_epochs = 2\n",
    "    validate_n_times = 100\n",
    "    batch_size = 512\n",
    "    validate_every_n_steps = (\n",
    "        100  # int(max_epochs * len(train_dataset) / (validate_n_times * batch_size))\n",
    "    )\n",
    "    print(\"validate_every_n_steps: \", validate_every_n_steps)\n",
    "    # initialize a trainer instance and kick off training\n",
    "    t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    trainer_cfg = ProjectionTrainerConfig(\n",
    "        max_epochs=max_epochs,\n",
    "        early_stopping_patience=float(\"inf\"),\n",
    "        validate_every_n_steps=validate_every_n_steps,\n",
    "        weight_decay=0.1,\n",
    "        batch_size=batch_size,  #  We only have one GPU\n",
    "        learning_rate=5e-4,  # 5e-4\n",
    "        betas=(0.9, 0.95),\n",
    "        grad_norm_clip=1.0,\n",
    "        lr_decay=True,\n",
    "        warmup_tokens=len(train_dataset)\n",
    "        * train_dataset.block_size\n",
    "        * max_epochs\n",
    "        * 0.05,  # Warm up over first 5%\n",
    "        final_tokens=len(train_dataset) * train_dataset.block_size * max_epochs,\n",
    "        num_workers=0,  # For dataloader, was 1 before\n",
    "        n_tokens_to_test_and_val=10**4,\n",
    "        n_games_to_test_legal_moves=20,\n",
    "        # checkpoint settings\n",
    "        save_model=True,\n",
    "        save_every_validation=False,\n",
    "        experiment_folder=experiment_folder,\n",
    "        project_name=project_name,\n",
    "        experiment_name=experiment_name,\n",
    "        model_size=model_size,\n",
    "        othello_rule=othello_rule,\n",
    "        index=0,\n",
    "        final=False,\n",
    "        # wandb\n",
    "        wandb_project=project_name,\n",
    "        use_wandb=True,\n",
    "        wandb_name=experiment_name,\n",
    "        # Llava\n",
    "        target_vocab_size=61,\n",
    "    )\n",
    "\n",
    "    trainer = ProjectionTrainer(\n",
    "        train_dataset, val_dataset, othello_rule_to_test, trainer_cfg, device\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "# project_name = \"playground_othello\"\n",
    "# train_chess_gpt_embedding_matrices(ModelSize.HUGE, OthelloRule.BIAS_CLOCK, experiment_folder, project_name, train_dataset, val_dataset, othello_rule_to_test, DEVICE)\n",
    "\n",
    "\n",
    "# final_othello_gpt = create_othello_gpt_from_chess(\n",
    "#     projection_matrices_path=f\"{experiment_folder}/copy_projection_matrices_None.pt\",\n",
    "#     device=DEVICE\n",
    "# )\n",
    "# test_hooked_transformer(final_othello_gpt, othello_rule_to_test[OthelloRule.BIAS_CLOCK], 64, 100, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V820C1vGXVY1"
   },
   "source": [
    "### Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9UI_0DcUpHv"
   },
   "outputs": [],
   "source": [
    "weak_size = ModelSize.NANO\n",
    "strong_size = ModelSize.LARGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc9xQ7tqBN3E"
   },
   "source": [
    "weak model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELqSFxljV_8t"
   },
   "outputs": [],
   "source": [
    "weak_model = load_model_pretrained(\n",
    "    project_name=\"pretrain_sweep_1\",\n",
    "    model_size=weak_size,\n",
    "    othello_rule=OthelloRule.STANDARD,\n",
    "    experiment_folder=experiment_folder,\n",
    "    device=DEVICE,\n",
    "    index=0,\n",
    "    final=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDYd8HC7BP7O"
   },
   "source": [
    "strong model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5oEB0jMVOCo"
   },
   "outputs": [],
   "source": [
    "strong_model = load_model_pretrained(\n",
    "    project_name=\"playground_othello\",\n",
    "    model_size=strong_size,\n",
    "    othello_rule=OthelloRule.CONSTANT_PARAMETERS,\n",
    "    experiment_folder=experiment_folder,\n",
    "    device=DEVICE,\n",
    "    index=0,\n",
    "    final=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGB5gMY5UyXn"
   },
   "outputs": [],
   "source": [
    "# strong_model = load_model_pretrained(\n",
    "#     project_name=\"pretrain_sweep_1\",\n",
    "#     model_size=strong_size,\n",
    "#     othello_rule=OthelloRule.UNTRAINED,\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     device=DEVICE,\n",
    "#     index=0,\n",
    "#     final=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B45O_uenu9La"
   },
   "outputs": [],
   "source": [
    "# strong_model = load_tiny_stories_instruct_8m(DEVICE)\n",
    "# strong_model = final_othello_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBdADstpV9f8"
   },
   "outputs": [],
   "source": [
    "def finetune(\n",
    "    weak_model,\n",
    "    weak_model_size: ModelSize,\n",
    "    weak_othello_rule: OthelloRule,\n",
    "    strong_model,\n",
    "    strong_model_size: ModelSize,\n",
    "    strong_othello_rule: OthelloRule,\n",
    "    weak_finetune_dataset: CharDataset,\n",
    "    val_dataset: CharDataset,\n",
    "    othello_rule_to_test: dict[OthelloRule, list[CharDataset]],\n",
    "    experiment_folder: str,\n",
    "    project_name: str,\n",
    "):\n",
    "    weak_model, _ = convert_hooked_to_gpt_and_verify(weak_model, val_dataset, DEVICE)\n",
    "    strong_model, model_cfg = convert_hooked_to_gpt_and_verify(\n",
    "        strong_model, val_dataset, DEVICE\n",
    "    )\n",
    "\n",
    "    # model_cfg = get_model_config(strong_model_size, train_dataset)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    experiment_name = get_experiment_name_finetuned(\n",
    "        weak_model_size,\n",
    "        weak_othello_rule,\n",
    "        strong_model_size,\n",
    "        strong_othello_rule,\n",
    "        index=0,\n",
    "    )\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "\n",
    "    max_epochs = 2\n",
    "    batch_size = 512\n",
    "    validate_every_n_steps = 10  # 10  or 100 for untrained/constant_parameters\n",
    "    print(\"validate_every_n_steps: \", validate_every_n_steps)\n",
    "    # initialize a trainer instance and kick off training\n",
    "    t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    trainer_cfg = TrainerConfigFinetune(\n",
    "        max_epochs=max_epochs,\n",
    "        early_stopping_patience=100,\n",
    "        validate_every_n_steps=validate_every_n_steps,\n",
    "        weight_decay=0.1,\n",
    "        batch_size=batch_size,  #  We only have one GPU\n",
    "        learning_rate=1e-5,  # 5e-4\n",
    "        betas=(0.9, 0.95),\n",
    "        grad_norm_clip=1.0,\n",
    "        lr_decay=False,\n",
    "        warmup_tokens=len(weak_finetune_dataset)\n",
    "        * weak_finetune_dataset.block_size\n",
    "        * max_epochs\n",
    "        * 0.05,  # Warum up over first 5%\n",
    "        final_tokens=len(weak_finetune_dataset)\n",
    "        * weak_finetune_dataset.block_size\n",
    "        * max_epochs,\n",
    "        num_workers=0,  # For dataloader, was 1 before\n",
    "        n_tokens_to_test_and_val=10**4,\n",
    "        n_games_to_test_legal_moves=20,\n",
    "        # checkpoint settings\n",
    "        save_model=True,\n",
    "        save_every_validation=False,\n",
    "        experiment_folder=experiment_folder,\n",
    "        project_name=project_name,\n",
    "        experiment_name=experiment_name,\n",
    "        model_size=strong_model_size,\n",
    "        othello_rule=weak_othello_rule,  # We want to measure legal moves on the weak rule on which it gets trained\n",
    "        index=0,\n",
    "        final=False,\n",
    "        # wandb\n",
    "        wandb_project=project_name,\n",
    "        use_wandb=True,\n",
    "        wandb_name=experiment_name,\n",
    "        # finetuning\n",
    "        weak_supervision_model_size=weak_model_size,\n",
    "        weak_supervision_rule=weak_othello_rule,\n",
    "    )\n",
    "    trainer = TrainerFinetune(\n",
    "        strong_model,\n",
    "        weak_model,\n",
    "        weak_finetune_dataset,\n",
    "        val_dataset,\n",
    "        othello_rule_to_test,\n",
    "        trainer_cfg,\n",
    "        model_cfg,\n",
    "        DEVICE,\n",
    "    )\n",
    "    device = trainer.device\n",
    "    print(t_start)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "# project_name = \"playground_othello\"\n",
    "# finetune(weak_model, weak_size, OthelloRule.STANDARD,\n",
    "#          strong_model, strong_size, OthelloRule.UNTRAINED,\n",
    "#             weak_finetune_dataset, val_dataset, othello_rule_to_test,\n",
    "#             experiment_folder, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rs3nOk7_WCrd"
   },
   "outputs": [],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy2e79Ay0ops"
   },
   "source": [
    "### Train MultiProbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqdIKWvEXyCi"
   },
   "outputs": [],
   "source": [
    "# Pretrain\n",
    "othello_rule = OthelloRule.STANDARD\n",
    "model_size = ModelSize.HUGE\n",
    "hooked_model = load_model_pretrained(\n",
    "    project_name=\"pretrain_sweep_1\",\n",
    "    model_size=model_size,\n",
    "    othello_rule=othello_rule,\n",
    "    experiment_folder=experiment_folder,\n",
    "    device=DEVICE,\n",
    "    index=0,\n",
    "    final=False,\n",
    "    linear_probe=False,\n",
    ")\n",
    "\n",
    "# # Finetune\n",
    "# weak_model_size = ModelSize.NANO\n",
    "# weak_rule = OthelloRule.STANDARD\n",
    "# strong_model_size = ModelSize.HUGE\n",
    "# strong_rule = OthelloRule.BIAS_CLOCK\n",
    "# hooked_model = load_finetuned_model(\n",
    "#     project_name=\"finetune_sweep_2\",\n",
    "#     weak_model_size=weak_model_size,\n",
    "#     weak_rule=weak_rule,\n",
    "#     strong_model_size=strong_model_size,\n",
    "#     strong_rule=othello_rule,\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     device=DEVICE,\n",
    "#     index=0,\n",
    "#     final=False,\n",
    "# )\n",
    "\n",
    "layer = int(hooked_model.cfg.n_layers / 4 * 3)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R815OcbQGmlN"
   },
   "outputs": [],
   "source": [
    "fake_board_state_transform.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--HNWhffP3dK"
   },
   "outputs": [],
   "source": [
    "def train_linear_probe(\n",
    "    hooked_model: HookedTransformer,\n",
    "    layer: int,\n",
    "    project_name: str,\n",
    "    experiment_name: str,\n",
    "    experiment_folder: str,\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "):\n",
    "    t.set_grad_enabled(True)\n",
    "    args = MultiProbeTrainingArgs(\n",
    "        device=DEVICE,\n",
    "        layer=layer,\n",
    "        experiment_folder=experiment_folder,\n",
    "        experiment_name=experiment_name,\n",
    "        wandb_project=project_name,\n",
    "        use_wandb=True,\n",
    "        wandb_name=experiment_name,\n",
    "        lr=1e-4,\n",
    "        epochs=1,\n",
    "        validate_every_n_steps=100,\n",
    "        early_stopping_patience=2,\n",
    "        fake_board_state_transform=fake_board_state_transform,\n",
    "    )\n",
    "\n",
    "    # trainer = LinearMultiProbeTrainer(othello_gpt, args)\n",
    "    trainer = LinearMultiProbeTrainer(\n",
    "        hooked_model,\n",
    "        args,\n",
    "        train_board_state_dataset,\n",
    "        val_board_state_dataset,\n",
    "        othello_rule_to_board_state_test_dataset,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def train_linear_probe_pretrained(\n",
    "    hooked_model: HookedTransformer,\n",
    "    layer: int,\n",
    "    project_name: str,\n",
    "    othello_rule: OthelloRule,\n",
    "    model_size: ModelSize,\n",
    "    experiment_folder: str,\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "    final: bool,\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    fake_board_state_transform_name = (\n",
    "        fake_board_state_transform.name\n",
    "        if fake_board_state_transform is not None\n",
    "        else None\n",
    "    )\n",
    "    experiment_name = get_experiment_name_pretrained(\n",
    "        model_size,\n",
    "        othello_rule,\n",
    "        index=0,\n",
    "        final=final,\n",
    "        linear_probe=True,\n",
    "        fake_probe=fake_board_state_transform_name,\n",
    "    )\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "    train_linear_probe(\n",
    "        hooked_model,\n",
    "        layer,\n",
    "        project_name,\n",
    "        experiment_name,\n",
    "        experiment_folder,\n",
    "        train_board_state_dataset,\n",
    "        val_board_state_dataset,\n",
    "        othello_rule_to_board_state_test_dataset,\n",
    "        fake_board_state_transform,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_linear_probe_finetuned(\n",
    "    hooked_model: HookedTransformer,\n",
    "    layer: int,\n",
    "    project_name: str,\n",
    "    weak_model_size: ModelSize,\n",
    "    weak_rule: OthelloRule,\n",
    "    strong_model_size: ModelSize,\n",
    "    strong_rule: OthelloRule,\n",
    "    experiment_folder: str,\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "    final: bool,\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    fake_board_state_transform_name = (\n",
    "        fake_board_state_transform.name\n",
    "        if fake_board_state_transform is not None\n",
    "        else None\n",
    "    )\n",
    "    experiment_name = get_experiment_name_finetuned(\n",
    "        weak_model_size,\n",
    "        weak_rule,\n",
    "        strong_model_size,\n",
    "        strong_rule,\n",
    "        index=0,\n",
    "        final=final,\n",
    "        linear_probe=True,\n",
    "        fake_probe=fake_board_state_transform_name,\n",
    "    )\n",
    "    experiment_name += f\"_{timestamp}\"\n",
    "    train_linear_probe(\n",
    "        hooked_model,\n",
    "        layer,\n",
    "        project_name,\n",
    "        experiment_name,\n",
    "        experiment_folder,\n",
    "        train_board_state_dataset,\n",
    "        val_board_state_dataset,\n",
    "        othello_rule_to_board_state_test_dataset,\n",
    "        fake_board_state_transform,\n",
    "    )\n",
    "\n",
    "\n",
    "# project_name = \"playground_othello\"\n",
    "# train_linear_probe_pretrained(hooked_model, layer, project_name, othello_rule, model_size, experiment_folder,\n",
    "#                    train_board_state_dataset, val_board_state_dataset, othello_rule_to_board_state_test_dataset, final=False,\n",
    "#                    fake_board_state_transform=fake_board_state_transform)\n",
    "# train_linear_probe_finetuned(hooked_model, layer, project_name, weak_model_size, weak_rule, strong_model_size, strong_rule, experiment_folder,\n",
    "#                    train_board_state_dataset, val_board_state_dataset, othello_rule_to_board_state_test_dataset, final=False.\n",
    "#                    fake_board_state_transform=fake_board_state_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvxnImAryZfm"
   },
   "outputs": [],
   "source": [
    "# Pretrain\n",
    "# linear_probe = load_model(\n",
    "#             project_name=project_name,\n",
    "#             model_size=model_size,\n",
    "#             othello_rule=othello_rule,\n",
    "#             experiment_folder=experiment_folder,\n",
    "#             device=DEVICE,\n",
    "#             index=0,\n",
    "#             final=False,\n",
    "#             linear_probe=True\n",
    "#         )\n",
    "\n",
    "# # Finetune\n",
    "linear_probe = load_finetuned_model(\n",
    "    project_name=project_name,\n",
    "    weak_model_size=weak_model_size,\n",
    "    weak_rule=weak_rule,\n",
    "    strong_model_size=strong_model_size,\n",
    "    strong_rule=othello_rule,\n",
    "    experiment_folder=experiment_folder,\n",
    "    device=DEVICE,\n",
    "    index=0,\n",
    "    final=False,\n",
    "    linear_probe=True,\n",
    ")\n",
    "linear_probe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O71UkcTTksvf"
   },
   "outputs": [],
   "source": [
    "board_seqs_square_test, board_seqs_id_test, n_skipped = get_board_seqs_square_and_id(\n",
    "    test_dataset, 100\n",
    ")\n",
    "print(board_seqs_square_test.shape)\n",
    "# evaluate_probe_generalization(trainer.linear_probe, othello_gpt, board_seqs_square_test, board_seqs_id_test, args.layer, DEVICE, plot_results=True)\n",
    "fig, mean_accuracy_even_on_even, mean_accuracy_odd_on_odd, mean_accuracy_both_on_all = (\n",
    "    evaluate_probe_generalization(\n",
    "        linear_probe,\n",
    "        hooked_model,\n",
    "        board_seqs_square_test,\n",
    "        board_seqs_id_test,\n",
    "        layer,\n",
    "        DEVICE,\n",
    "        plot_results=False,\n",
    "    )\n",
    ")\n",
    "print(f\"Even probe on even data: {mean_accuracy_even_on_even:.4f}\")\n",
    "print(f\"Odd probe on odd data: {mean_accuracy_odd_on_odd.mean():.4f}\")\n",
    "print(f\"Both probe on all data: {mean_accuracy_both_on_all.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYtoCnqRhqnM"
   },
   "outputs": [],
   "source": [
    "# # Convert train_dataset to required tensor formats\n",
    "# print(\"Converting game data to tensors...\")\n",
    "# board_seqs_square, board_seqs_id, n_skipped = get_board_seqs_square_and_id(train_dataset, args.num_games)\n",
    "# print(f\"Prepared {len(board_seqs_square)} games\")\n",
    "# print(f\"Skipped {n_skipped} games\")\n",
    "# print(f\"board_seqs_square shape: {board_seqs_square.shape}\")\n",
    "# print(f\"board_seqs_id shape: {board_seqs_id.shape}\")\n",
    "# print(\"Min/max in board_seqs_square:\", board_seqs_square.min(), board_seqs_square.max())\n",
    "# print(\"Unique values:\", board_seqs_square.unique())\n",
    "# check_opening_moves(board_seqs_square)\n",
    "# plot_average_move_index(board_seqs_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NDyhs6_5ix9"
   },
   "outputs": [],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HwS5QTYOjdu"
   },
   "source": [
    "# --- Run Sweeps ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU8sbUsfMa0H"
   },
   "source": [
    "### Results & Folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "pRkiK4AzMaab"
   },
   "outputs": [],
   "source": [
    "pretrained_rule_to_result_file = {\n",
    "    OthelloRule.STANDARD: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_next_to_opponent_results.pkl\",\n",
    "    OthelloRule.BIAS_CLOCK: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_bias_clock_results.pkl\",\n",
    "    OthelloRule.NEXT_TO_OPPONENT: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_next_to_opponent_results.pkl\",\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_chess_results.pkl\",\n",
    "    OthelloRule.UNTRAINED: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_untrained_results.pkl\",\n",
    "    OthelloRule.CONSTANT_PARAMETERS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_constant_parameters_results.pkl\",\n",
    "    OthelloRule.NO_FLIPPING: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1/pretrain_standard_no_flipping_results.pkl\",\n",
    "}\n",
    "pretrained_rule_to_result_file_linear_probe = {\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/chess_1_linear_probe/board_prediction_pretrained.pkl\",\n",
    "}\n",
    "pretrained_rule_to_result_file_fake_linear_probe = {\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/fake_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "}\n",
    "pretrained_rule_to_result_file_black_white_linear_probe = {\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/black_white_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "}\n",
    "pretrained_rule_to_result_file_modulo_linear_probe = {\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/modulo_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "}\n",
    "for othello_rule in [\n",
    "    OthelloRule.STANDARD,\n",
    "    OthelloRule.BIAS_CLOCK,\n",
    "    OthelloRule.NEXT_TO_OPPONENT,\n",
    "    OthelloRule.UNTRAINED,\n",
    "    OthelloRule.CONSTANT_PARAMETERS,\n",
    "    OthelloRule.NO_FLIPPING,\n",
    "]:\n",
    "    pretrained_rule_to_result_file_linear_probe[othello_rule] = (\n",
    "        \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "    )\n",
    "    pretrained_rule_to_result_file_fake_linear_probe[othello_rule] = (\n",
    "        \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/fake_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "    )\n",
    "    pretrained_rule_to_result_file_black_white_linear_probe[othello_rule] = (\n",
    "        \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/black_white_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "    )\n",
    "    pretrained_rule_to_result_file_modulo_linear_probe[othello_rule] = (\n",
    "        \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/modulo_pretrain_sweep_1_linear_probe/board_prediction_pretrained.pkl\"\n",
    "    )\n",
    "\n",
    "\n",
    "finetuned_rule_to_result_file = {\n",
    "    OthelloRule.BIAS_CLOCK: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2/finetune_standard_bias_clock_results.pkl\",\n",
    "    OthelloRule.NEXT_TO_OPPONENT: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_4_next_to_opponent/finetune_standard_next_to_opponent_results.pkl\",\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/chess_1/finetune_standard_chess_results.pkl\",\n",
    "    OthelloRule.UNTRAINED: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_untrained/finetune_standard_untrained_results.pkl\",\n",
    "    OthelloRule.CONSTANT_PARAMETERS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_constant_parameters/finetune_standard_constant_parameters_results.pkl\",\n",
    "    OthelloRule.NO_FLIPPING: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_no_flipping/finetune_standard_no_flipping_results.pkl\",\n",
    "}\n",
    "finetued_rule_to_result_file_linear_probe = {\n",
    "    OthelloRule.BIAS_CLOCK: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_linear_probe/board_accuracy_finetuned_standard_bias_clock.pkl\",\n",
    "    OthelloRule.NEXT_TO_OPPONENT: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_4_next_to_opponent_linear_probe/board_accuracy_finetuned_standard_next_to_opponent.pkl\",\n",
    "    OthelloRule.CHESS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/chess_1_linear_probe/board_accuracy_finetuned_standard_chess.pkl\",\n",
    "    OthelloRule.UNTRAINED: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_untrained_linear_probe/board_accuracy_finetuned_standard_untrained.pkl\",\n",
    "    OthelloRule.CONSTANT_PARAMETERS: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_constant_parameters_linear_probe/board_accuracy_finetuned_standard_constant_parameters.pkl\",\n",
    "    OthelloRule.NO_FLIPPING: \"/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_no_flipping_linear_probe/board_accuracy_finetuned_standard_no_flipping.pkl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "DCQDRrlM0Eev"
   },
   "outputs": [],
   "source": [
    "othello_rule_to_optimization_step = {\n",
    "    OthelloRule.BIAS_CLOCK: {\n",
    "        ModelSize.MICRO: {ModelSize.NANO: 2050},\n",
    "        ModelSize.MINI: {ModelSize.NANO: 180, ModelSize.MICRO: 380},\n",
    "        ModelSize.SMALL: {ModelSize.NANO: 30, ModelSize.MICRO: 80, ModelSize.MINI: 290},\n",
    "        ModelSize.MEDIUM: {\n",
    "            ModelSize.NANO: 20,\n",
    "            ModelSize.MICRO: 20,\n",
    "            ModelSize.MINI: 330,\n",
    "            ModelSize.SMALL: 1020,\n",
    "        },\n",
    "        ModelSize.LARGE: {\n",
    "            ModelSize.NANO: 30,\n",
    "            ModelSize.MICRO: 30,\n",
    "            ModelSize.MINI: 110,\n",
    "            ModelSize.SMALL: 210,\n",
    "            ModelSize.MEDIUM: 310,\n",
    "        },\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 20,\n",
    "            ModelSize.MICRO: 20,\n",
    "            ModelSize.MINI: 110,\n",
    "            ModelSize.SMALL: 380,\n",
    "            ModelSize.MEDIUM: 240,\n",
    "            ModelSize.LARGE: 770,\n",
    "        },\n",
    "    },\n",
    "    OthelloRule.NEXT_TO_OPPONENT: {\n",
    "        ModelSize.MICRO: {ModelSize.NANO: 0},\n",
    "        ModelSize.MINI: {ModelSize.NANO: 0, ModelSize.MICRO: 0},\n",
    "        ModelSize.SMALL: {ModelSize.NANO: 10, ModelSize.MICRO: 20, ModelSize.MINI: 280},\n",
    "        ModelSize.MEDIUM: {\n",
    "            ModelSize.NANO: 70,\n",
    "            ModelSize.MICRO: 70,\n",
    "            ModelSize.MINI: 270,\n",
    "            ModelSize.SMALL: 8750,\n",
    "        },\n",
    "        ModelSize.LARGE: {\n",
    "            ModelSize.NANO: 100,\n",
    "            ModelSize.MICRO: 100,\n",
    "            ModelSize.MINI: 320,\n",
    "            ModelSize.SMALL: 15100,\n",
    "            ModelSize.MEDIUM: 15840,\n",
    "        },\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 90,\n",
    "            ModelSize.MICRO: 320,\n",
    "            ModelSize.MINI: 280,\n",
    "            ModelSize.SMALL: 11000,\n",
    "            ModelSize.MEDIUM: 7050,\n",
    "            ModelSize.LARGE: 20530,\n",
    "        },\n",
    "    },\n",
    "    OthelloRule.CHESS: {\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 7900,\n",
    "            ModelSize.MICRO: 8100,\n",
    "            ModelSize.MINI: 17300,\n",
    "            ModelSize.SMALL: 17700,\n",
    "            ModelSize.MEDIUM: 21700,\n",
    "            ModelSize.LARGE: 25200,\n",
    "        },\n",
    "    },\n",
    "    OthelloRule.UNTRAINED: {\n",
    "        ModelSize.MICRO: {ModelSize.NANO: 31300},\n",
    "        ModelSize.MINI: {ModelSize.NANO: 29500, ModelSize.MICRO: 28100},\n",
    "        ModelSize.SMALL: {\n",
    "            ModelSize.NANO: 16900,\n",
    "            ModelSize.MICRO: 16500,\n",
    "            ModelSize.MINI: 32900,\n",
    "        },\n",
    "        ModelSize.MEDIUM: {\n",
    "            ModelSize.NANO: 19000,\n",
    "            ModelSize.MICRO: 19800,\n",
    "            ModelSize.MINI: 50800,\n",
    "            ModelSize.SMALL: 24800,\n",
    "        },\n",
    "        ModelSize.LARGE: {\n",
    "            ModelSize.NANO: 24600,\n",
    "            ModelSize.MICRO: 14600,\n",
    "            ModelSize.MINI: 34400,\n",
    "            ModelSize.SMALL: 50800,\n",
    "            ModelSize.MEDIUM: 42200,\n",
    "        },\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 25700,\n",
    "            ModelSize.MICRO: 13200,\n",
    "            ModelSize.MINI: 26100,\n",
    "            ModelSize.SMALL: 50800,\n",
    "            ModelSize.MEDIUM: 50800,\n",
    "            ModelSize.LARGE: 50800,\n",
    "        },\n",
    "    },\n",
    "    OthelloRule.CONSTANT_PARAMETERS: {\n",
    "        ModelSize.MICRO: {ModelSize.NANO: 35200},\n",
    "        ModelSize.MINI: {ModelSize.NANO: 27200, ModelSize.MICRO: 27700},\n",
    "        ModelSize.SMALL: {\n",
    "            ModelSize.NANO: 29300,\n",
    "            ModelSize.MICRO: 22200,\n",
    "            ModelSize.MINI: 33900,\n",
    "        },\n",
    "        ModelSize.MEDIUM: {\n",
    "            ModelSize.NANO: 50800,\n",
    "            ModelSize.MICRO: 22500,\n",
    "            ModelSize.MINI: 26600,\n",
    "            ModelSize.SMALL: 31800,\n",
    "        },\n",
    "        ModelSize.LARGE: {\n",
    "            ModelSize.NANO: 26600,\n",
    "            ModelSize.MICRO: 23500,\n",
    "            ModelSize.MINI: 24300,\n",
    "            ModelSize.SMALL: 41800,\n",
    "            ModelSize.MEDIUM: 22300,\n",
    "        },\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 18400,\n",
    "            ModelSize.MICRO: 50600,\n",
    "            ModelSize.MINI: 21700,\n",
    "            ModelSize.SMALL: 20400,\n",
    "            ModelSize.MEDIUM: 19600,\n",
    "            ModelSize.LARGE: 24900,\n",
    "        },\n",
    "    },\n",
    "    OthelloRule.NO_FLIPPING: {\n",
    "        ModelSize.MICRO: {ModelSize.NANO: 0},\n",
    "        ModelSize.MINI: {ModelSize.NANO: 0, ModelSize.MICRO: 0},\n",
    "        ModelSize.SMALL: {ModelSize.NANO: 0, ModelSize.MICRO: 10, ModelSize.MINI: 30},\n",
    "        ModelSize.MEDIUM: {\n",
    "            ModelSize.NANO: 20,\n",
    "            ModelSize.MICRO: 30,\n",
    "            ModelSize.MINI: 20,\n",
    "            ModelSize.SMALL: 17520,\n",
    "        },\n",
    "        ModelSize.LARGE: {\n",
    "            ModelSize.NANO: 30,\n",
    "            ModelSize.MICRO: 30,\n",
    "            ModelSize.MINI: 40,\n",
    "            ModelSize.SMALL: 14170,\n",
    "            ModelSize.MEDIUM: 50800,\n",
    "        },\n",
    "        ModelSize.HUGE: {\n",
    "            ModelSize.NANO: 20,\n",
    "            ModelSize.MICRO: 30,\n",
    "            ModelSize.MINI: 30,\n",
    "            ModelSize.SMALL: 26500,\n",
    "            ModelSize.MEDIUM: 41300,\n",
    "            ModelSize.LARGE: 50800,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "FhNnFw8ULiIl"
   },
   "outputs": [],
   "source": [
    "RULE_TO_MARKER = {\n",
    "    OthelloRule.CONSTANT_PARAMETERS: \"s\",\n",
    "    OthelloRule.UNTRAINED: \"D\",\n",
    "    OthelloRule.CHESS: \"*\",\n",
    "    OthelloRule.NO_FLIPPING: \"o\",\n",
    "    OthelloRule.NEXT_TO_OPPONENT: \"P\",\n",
    "    OthelloRule.BIAS_CLOCK: \"^\",\n",
    "}\n",
    "THRESHOLD = 0.02\n",
    "\n",
    "\n",
    "def wsg_score_to_alpha_color(wsg_score: float) -> tuple[float, str]:\n",
    "    alpha = min(0.9, 0.5 + abs(wsg_score))\n",
    "    if wsg_score > THRESHOLD:\n",
    "        color = \"green\"\n",
    "    elif wsg_score < -THRESHOLD:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"black\"\n",
    "        alpha = 0.7\n",
    "\n",
    "    return alpha, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PUmIifXOJpRc"
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# https://www.dmcdougall.co.uk/publication-ready-the-first-time-beautiful-reproducible-plots-with-matplotlib\n",
    "factor = 1.2\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 14 * factor,\n",
    "        \"axes.titlesize\": 16 * factor,\n",
    "        \"axes.labelsize\": 14 * factor,\n",
    "        \"xtick.labelsize\": 12 * factor,\n",
    "        \"ytick.labelsize\": 12 * factor,\n",
    "        \"legend.fontsize\": 12 * factor,\n",
    "        \"lines.linewidth\": 2.0 * factor,\n",
    "        \"lines.markersize\": 8.0 * factor,\n",
    "        \"xtick.major.width\": 1.0 * factor,\n",
    "        \"ytick.major.width\": 1.0 * factor,\n",
    "        \"xtick.major.size\": 6 * factor,\n",
    "        \"ytick.major.size\": 6 * factor,\n",
    "    }\n",
    ")\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD6EzWo5OmJf"
   },
   "source": [
    "### plot_pretrain_sweep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abvKPKeyOnH3"
   },
   "outputs": [],
   "source": [
    "def compute_loss_pretrain_models(\n",
    "    data_folder: str,\n",
    "    experiment_folder: str,\n",
    "    project_name_pretrain: str,\n",
    "    othello_rule_to_test: dict[OthelloRule, CharDataset],\n",
    "    index: int,\n",
    "    device: t.device,\n",
    "    final: bool = True,\n",
    "    overwrite: bool = False,\n",
    ") -> dict[str, float]:\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    results_filename = f\"pretrain_{weak_rule.value}_{strong_rule.value}_results.pkl\"\n",
    "    results_path = os.path.join(\n",
    "        experiment_folder, project_name_pretrain, results_filename\n",
    "    )\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "            print(f\"Loaded {len(results)} existing results\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    weak_test_dataset = othello_rule_to_test[weak_rule]\n",
    "    strong_test_dataset = othello_rule_to_test[strong_rule]\n",
    "    batch_size = 64\n",
    "    n_games = 1000\n",
    "\n",
    "    # Evaluate models\n",
    "    results = []\n",
    "    for model_size in [\n",
    "        ModelSize.NANO,\n",
    "        ModelSize.MICRO,\n",
    "        ModelSize.MINI,\n",
    "        ModelSize.SMALL,\n",
    "        ModelSize.MEDIUM,\n",
    "        ModelSize.LARGE,\n",
    "        ModelSize.HUGE,\n",
    "    ]:\n",
    "        for goal in [Goal.WEAK_GOAL, Goal.STRONG_GOAL]:\n",
    "            othello_rule = get_othello_rule(goal)\n",
    "            model = load_model_pretrained(\n",
    "                project_name_pretrain,\n",
    "                model_size,\n",
    "                othello_rule,\n",
    "                experiment_folder,\n",
    "                device,\n",
    "                index,\n",
    "                final,\n",
    "            )\n",
    "            if not model:\n",
    "                print(\"Missing: \", index, model_size, goal)\n",
    "                continue\n",
    "\n",
    "            # Evaluate\n",
    "            n_parameters = count_parameters(model)\n",
    "\n",
    "            res = test_hooked_transformer(\n",
    "                model, weak_rule, weak_test_dataset, batch_size, n_games, device\n",
    "            )\n",
    "            avg_weak_loss = res[\"ce_loss\"]\n",
    "            weak_illegal_move_percentage = res[\"illegal_move_percentage\"]\n",
    "            res = test_hooked_transformer(\n",
    "                model, strong_rule, strong_test_dataset, batch_size, n_games, device\n",
    "            )\n",
    "            avg_strong_loss = res[\"ce_loss\"]\n",
    "            strong_illegal_move_percentage = res[\"illegal_move_percentage\"]\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"goal\": goal,\n",
    "                    \"othello_rule\": othello_rule,\n",
    "                    \"model_size\": model_size,\n",
    "                    \"n_parameters\": n_parameters,\n",
    "                    \"avg_weak_loss\": avg_weak_loss,\n",
    "                    \"weak_illegal_move_percentage\": weak_illegal_move_percentage,\n",
    "                    \"avg_strong_loss\": avg_strong_loss,\n",
    "                    \"strong_illegal_move_percentage\": strong_illegal_move_percentage,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Clean memory\n",
    "            model.cpu()\n",
    "            del model\n",
    "            t.cuda.empty_cache()\n",
    "\n",
    "    if len(results) == 0:\n",
    "        print(\"No models found.\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def othello_rule_to_minimum_CE_loss(othello_rule: OthelloRule):\n",
    "    if othello_rule in [\n",
    "        OthelloRule.STANDARD,\n",
    "        OthelloRule.CHESS,\n",
    "        OthelloRule.UNTRAINED,\n",
    "        OthelloRule.TINY_STORIES,\n",
    "        OthelloRule.NO_FLIPPING,\n",
    "    ]:\n",
    "        return 2.086631\n",
    "    elif othello_rule == OthelloRule.BIAS_CLOCK:\n",
    "        return 0.772031\n",
    "    elif othello_rule == OthelloRule.NEXT_TO_OPPONENT:\n",
    "        return 2.190385\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown OthelloRule: {othello_rule}\")\n",
    "\n",
    "\n",
    "def plot_pretrain_sweep(results: dict, save_path: str | None = None):\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    minimal_loss_weak = othello_rule_to_minimum_CE_loss(weak_rule)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "    minimal_loss_strong = othello_rule_to_minimum_CE_loss(strong_rule)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "    def plot_metric(ax, df_subset, y_metric, title, ylabel, ylim, horizontal_line=None):\n",
    "        df_weak_trained = df_subset[df_subset[\"goal\"] == Goal.WEAK_GOAL]\n",
    "        df_strong_trained = df_subset[df_subset[\"goal\"] == Goal.STRONG_GOAL]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=df_weak_trained,\n",
    "            x=\"n_parameters\",\n",
    "            y=y_metric,\n",
    "            label=f\"Trained on {weak_rule.value}\",\n",
    "            marker=\"s\",\n",
    "            linestyle=\"-\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            data=df_strong_trained,\n",
    "            x=\"n_parameters\",\n",
    "            y=y_metric,\n",
    "            label=f\"Trained on {strong_rule.value}\",\n",
    "            marker=\"d\",\n",
    "            linestyle=\"-\",\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        if horizontal_line:\n",
    "            ax.axhline(\n",
    "                y=horizontal_line, color=\"gray\", linestyle=\"--\", label=f\"Min Achievable\"\n",
    "            )\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlabel(\"Number of Parameters (log scale)\")\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "    # Top row: CE Loss\n",
    "    plot_metric(\n",
    "        axes[0, 0],\n",
    "        df,\n",
    "        \"avg_weak_loss\",\n",
    "        f\"CE-Loss vs. Params (Evaluated on {weak_rule.value} test set)\",\n",
    "        \"CE-Loss\",\n",
    "        (0, 6),\n",
    "        minimal_loss_weak,\n",
    "    )\n",
    "\n",
    "    plot_metric(\n",
    "        axes[0, 1],\n",
    "        df,\n",
    "        \"avg_strong_loss\",\n",
    "        f\"CE-Loss vs. Params (Evaluated on {strong_rule.value} test set)\",\n",
    "        \"CE-Loss\",\n",
    "        (0, 6),\n",
    "        minimal_loss_strong,\n",
    "    )\n",
    "\n",
    "    # Bottom row: Illegal Move Percentage\n",
    "    plot_metric(\n",
    "        axes[1, 0],\n",
    "        df,\n",
    "        \"weak_illegal_move_percentage\",\n",
    "        f\"Illegal Move % vs. Params (Evaluated on {weak_rule.value} test set)\",\n",
    "        \"Illegal Move %\",\n",
    "        (0, 100),\n",
    "    )\n",
    "\n",
    "    plot_metric(\n",
    "        axes[1, 1],\n",
    "        df,\n",
    "        \"strong_illegal_move_percentage\",\n",
    "        f\"Illegal Move % vs. Params (Evaluated on {strong_rule.value} test set)\",\n",
    "        \"Illegal Move %\",\n",
    "        (0, 100),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        save_dir = os.path.dirname(save_path)\n",
    "        if save_dir and not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(\n",
    "            save_path, f\"pretrain_{weak_rule.value}_{strong_rule.value}.png\"\n",
    "        )\n",
    "        try:\n",
    "            plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to {save_path}: {e}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# project_name_pretrain = 'pretrain_sweep_1'\n",
    "# results = compute_loss_pretrain_models(\n",
    "#     data_folder=data_folder,\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     project_name_pretrain=project_name_pretrain,\n",
    "#     othello_rule_to_test=othello_rule_to_test,\n",
    "#     index=0,\n",
    "#     device=DEVICE,\n",
    "#     final=False,\n",
    "#     overwrite=False,\n",
    "# )\n",
    "\n",
    "# save_path = os.path.join(experiment_folder, project_name_pretrain)\n",
    "# plot_pretrain_sweep(results, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "bf5iSO5I-ABA",
    "outputId": "27932af6-dfde-4102-9eeb-9838c8649d7a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_rule_performance_on_weak_task(\n",
    "    pretrained_rule_to_result_file: dict[OthelloRule, str],\n",
    "    pretrained_rule_to_result_file_linear_probe: dict[OthelloRule, str],\n",
    "    finetuned_rule_to_result_file: dict[tuple[OthelloRule, OthelloRule], str],\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots performance on weak task (standard Othello) for each othello_rule.\n",
    "\n",
    "    x-axis: model size (number of parameters, log-scale)\n",
    "    y-axis: CE-loss on weak rule (standard Othello)\n",
    "\n",
    "    One line for each othello_rule.\n",
    "    \"\"\"\n",
    "    # Load the data using the existing function\n",
    "    (\n",
    "        model_size_to_n_parameters,\n",
    "        rule_to_model_size_to_CE_loss,\n",
    "        rule_to_model_size_to_LP_accuracy,\n",
    "        rule_to_model_size_pair_to_wsg_score,\n",
    "    ) = load_wsg_precomputed_data(\n",
    "        pretrained_rule_to_result_file,\n",
    "        pretrained_rule_to_result_file_linear_probe,\n",
    "        finetuned_rule_to_result_file,\n",
    "    )\n",
    "\n",
    "    # Default colors\n",
    "    colors = [\n",
    "        \"#1f77b4\",\n",
    "        \"#ff7f0e\",\n",
    "        \"#2ca02c\",\n",
    "        \"#d62728\",\n",
    "        \"#9467bd\",\n",
    "        \"#8c564b\",\n",
    "        \"#e377c2\",\n",
    "        \"#7f7f7f\",\n",
    "    ]\n",
    "    rules = list(rule_to_model_size_to_CE_loss.keys())\n",
    "    rule_to_color = {rule: colors[i % len(colors)] for i, rule in enumerate(rules)}\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "    # Plot line for each rule\n",
    "    for rule, model_size_to_loss in rule_to_model_size_to_CE_loss.items():\n",
    "        if not model_size_to_loss:  # Skip if no data\n",
    "            continue\n",
    "\n",
    "        # Sort by model size for proper line plotting\n",
    "        sorted_items = sorted(\n",
    "            model_size_to_loss.items(),\n",
    "            key=lambda x: model_size_to_n_parameters.get(x[0], 0),\n",
    "        )\n",
    "\n",
    "        model_sizes = [item[0] for item in sorted_items]\n",
    "        losses = [item[1] for item in sorted_items]\n",
    "        n_parameters = [\n",
    "            model_size_to_n_parameters[size]\n",
    "            for size in model_sizes\n",
    "            if size in model_size_to_n_parameters\n",
    "        ]\n",
    "\n",
    "        if len(n_parameters) == len(\n",
    "            losses\n",
    "        ):  # Only plot if we have parameter counts for all model sizes\n",
    "            ax.plot(\n",
    "                n_parameters,\n",
    "                losses,\n",
    "                marker=\"o\",\n",
    "                label=rule.name,\n",
    "                color=rule_to_color.get(rule, \"#1f77b4\"),\n",
    "                linewidth=2,\n",
    "                markersize=6,\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Warning: Missing parameter data for some model sizes in rule {rule.name}\"\n",
    "            )\n",
    "\n",
    "    # Add horizontal line for minimum achievable weak loss\n",
    "    ax.axhline(\n",
    "        y=2.086631,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1,\n",
    "        label=\"Min Achievable Weak Loss\",\n",
    "    )\n",
    "\n",
    "    # Set axes properties\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Model size (Number of Parameters, log scale)\")\n",
    "    ax.set_ylabel(\"CE-loss on weak rule (standard Othello)\")\n",
    "    ax.set_title(\"Performance on Weak Task by Othello Rule\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Create legend with mixed fonts (monospace for rules, regular for reference line)\n",
    "    legend = ax.legend(prop={\"size\": 12})\n",
    "    # Set monospace only for rule labels (all except the last one which is the reference line)\n",
    "    for i, text in enumerate(legend.get_texts()[:-1]):  # All except last\n",
    "        text.set_fontfamily(\"monospace\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save if path provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "save_path = os.path.join(experiment_folder, \"rule_performance_weak_task\")\n",
    "plot_rule_performance_on_weak_task(\n",
    "    pretrained_rule_to_result_file=pretrained_rule_to_result_file,\n",
    "    pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_linear_probe,\n",
    "    finetuned_rule_to_result_file=finetuned_rule_to_result_file,\n",
    "    save_path=save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIgr9l_8BS-p"
   },
   "source": [
    "### finetune_sweep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVevaqm5BTU3"
   },
   "outputs": [],
   "source": [
    "def finetune_sweep(\n",
    "    project_name_finetune: str,\n",
    "    project_name_pretrain: str,\n",
    "    experiment_folder: str,\n",
    "    strong_model_sizes_filter: list[ModelSize] | None = None,\n",
    "):\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    weak_strong_pairs = get_weak_strong_pairs()\n",
    "    for weak_size, strong_size in weak_strong_pairs:\n",
    "        if strong_model_sizes_filter and strong_size not in strong_model_sizes_filter:\n",
    "            continue\n",
    "        print(weak_size, strong_size)\n",
    "\n",
    "        weak_model = load_model_pretrained(\n",
    "            project_name=project_name_pretrain,\n",
    "            model_size=weak_size,\n",
    "            othello_rule=weak_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=DEVICE,\n",
    "            index=0,\n",
    "            final=False,\n",
    "        )\n",
    "        strong_model = load_model_pretrained(\n",
    "            project_name=project_name_pretrain,\n",
    "            model_size=strong_size,\n",
    "            othello_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=DEVICE,\n",
    "            index=0,\n",
    "            final=False,\n",
    "        )\n",
    "        if not weak_model or not strong_model:\n",
    "            print(\"Missing: \", weak_size, strong_size)\n",
    "            continue\n",
    "\n",
    "        finetune(\n",
    "            weak_model,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            strong_model,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            weak_finetune_dataset,\n",
    "            val_dataset,\n",
    "            othello_rule_to_test,\n",
    "            experiment_folder,\n",
    "            project_name_finetune,\n",
    "        )\n",
    "\n",
    "\n",
    "project_name_finetune = \"finetune_sweep_2_no_flipping\"  # 'finetune_sweep_2_constant_parameters'  # 'playground_othello' #\n",
    "project_name_pretrain = \"pretrain_sweep_1\"\n",
    "finetune_sweep(\n",
    "    project_name_finetune,\n",
    "    project_name_pretrain,\n",
    "    experiment_folder,\n",
    "    strong_model_sizes_filter=[ModelSize.MINI, ModelSize.MICRO, ModelSize.NANO],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqeD1NyB0KSs"
   },
   "source": [
    "### plot_finetune_sweep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgzmeJ5PBYVy"
   },
   "outputs": [],
   "source": [
    "def compute_loss_finetune_models(\n",
    "    data_folder: str,\n",
    "    experiment_folder: str,\n",
    "    project_name_pretrain: str,\n",
    "    results_path: str,\n",
    "    othello_rule_to_test: dict[OthelloRule, CharDataset],\n",
    "    index: int,\n",
    "    device: t.device,\n",
    "    final: bool = True,\n",
    "    overwrite: bool = False,\n",
    ") -> tuple[\n",
    "    dict[ModelSize, int], dict[tuple[ModelSize, ModelSize], tuple[float, float]]\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns two dict:\n",
    "        model_to_size: model_size -> n_parameters\n",
    "        weak_strong_pair_to_wsg: (weak_model_size, strong_model_size) -> (wsg_pretrained, wsg_finetuned)\n",
    "    \"\"\"\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    # results_prefix = f\"finetune_{weak_rule.value}_{strong_rule.value}_results\"\n",
    "    # results_filename = results_prefix + \".pkl\"\n",
    "    # results_path = os.path.join(experiment_folder, project_name_finetune, results_filename)\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                model_to_size, weak_strong_pair_to_wsg = pickle.load(f)\n",
    "            print(f\"Loaded existing results\")\n",
    "            return model_to_size, weak_strong_pair_to_wsg\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    weak_test_dataset = othello_rule_to_test[weak_rule]\n",
    "    strong_test_dataset = othello_rule_to_test[strong_rule]\n",
    "    batch_size = 64\n",
    "    n_games = 1000\n",
    "    model_to_size = {}\n",
    "    weak_strong_pair_to_wsg = {}\n",
    "\n",
    "    # Evaluate models\n",
    "    weak_strong_pairs = get_weak_strong_pairs()\n",
    "    for weak_size, strong_size in weak_strong_pairs:\n",
    "        print(weak_size, strong_size)\n",
    "        weak_model_weak_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=final,\n",
    "        )\n",
    "        strong_model_weak_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            strong_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=final,\n",
    "        )\n",
    "        strong_model_strong_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=final,\n",
    "        )\n",
    "        finetuned_model = load_finetuned_model(\n",
    "            project_name_finetune,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "        if (\n",
    "            not weak_model_weak_rule\n",
    "            or not strong_model_strong_rule\n",
    "            or not strong_model_weak_rule\n",
    "            or not finetuned_model\n",
    "        ):\n",
    "            print(\"Missing: \", index, weak_size, strong_size)\n",
    "            continue\n",
    "\n",
    "        if not weak_size in model_to_size:\n",
    "            model_to_size[weak_size] = count_parameters(weak_model_weak_rule)\n",
    "        if not strong_size in model_to_size:\n",
    "            model_to_size[strong_size] = count_parameters(strong_model_weak_rule)\n",
    "\n",
    "        # Evaluate\n",
    "        n_parameters = count_parameters(finetuned_model)\n",
    "        loss_weak_model_weak_rule = test_hooked_transformer(\n",
    "            weak_model_weak_rule,\n",
    "            weak_rule,\n",
    "            weak_test_dataset,\n",
    "            batch_size,\n",
    "            n_games,\n",
    "            device,\n",
    "        )[\"ce_loss\"]\n",
    "        loss_strong_model_weak_rule = test_hooked_transformer(\n",
    "            strong_model_weak_rule,\n",
    "            weak_rule,\n",
    "            weak_test_dataset,\n",
    "            batch_size,\n",
    "            n_games,\n",
    "            device,\n",
    "        )[\"ce_loss\"]\n",
    "        loss_strong_model_strong_rule = test_hooked_transformer(\n",
    "            strong_model_strong_rule,\n",
    "            weak_rule,\n",
    "            weak_test_dataset,\n",
    "            batch_size,\n",
    "            n_games,\n",
    "            device,\n",
    "        )[\"ce_loss\"]\n",
    "        loss_finetuned_model = test_hooked_transformer(\n",
    "            finetuned_model, weak_rule, weak_test_dataset, batch_size, n_games, device\n",
    "        )[\"ce_loss\"]\n",
    "\n",
    "        wsg_pretrained = (loss_weak_model_weak_rule - loss_strong_model_strong_rule) / (\n",
    "            loss_weak_model_weak_rule - loss_strong_model_weak_rule\n",
    "        )\n",
    "        wsg_finetuned = (loss_weak_model_weak_rule - loss_finetuned_model) / (\n",
    "            loss_weak_model_weak_rule - loss_strong_model_weak_rule\n",
    "        )\n",
    "        weak_strong_pair_to_wsg[(weak_size, strong_size)] = (\n",
    "            wsg_pretrained,\n",
    "            wsg_finetuned,\n",
    "        )\n",
    "\n",
    "    results = (model_to_size, weak_strong_pair_to_wsg)\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return model_to_size, weak_strong_pair_to_wsg\n",
    "\n",
    "\n",
    "def plot_finetune_sweep(\n",
    "    model_to_size: dict[ModelSize, int],\n",
    "    weak_strong_pair_to_wsg: dict[tuple[ModelSize, ModelSize], tuple[float, float]],\n",
    "    image_path: str,\n",
    "    title: str,\n",
    "    overwrite: bool = False,\n",
    "    plot_legend: bool = True,\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    # Get unique weak models and sort them by size for consistent plotting order\n",
    "    weak_models = sorted(\n",
    "        set(pair[0] for pair in weak_strong_pair_to_wsg.keys()),\n",
    "        key=lambda x: model_to_size[x],\n",
    "    )\n",
    "\n",
    "    # Create a color map to assign a unique color to each weak model series\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(weak_models)))\n",
    "\n",
    "    # Collect all y-values (both pretrain and finetune) to determine a shared y-axis range\n",
    "    all_y_values = []\n",
    "    for pre, fine in weak_strong_pair_to_wsg.values():\n",
    "        all_y_values.extend([pre, fine])\n",
    "\n",
    "    # Define the y-axis range with a 10% margin for better visualization\n",
    "    y_min, y_max = min(all_y_values), max(all_y_values)\n",
    "    y_margin = (y_max - y_min) * 0.1\n",
    "    y_range = (y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "    # Iterate through each weak model to plot its corresponding data series\n",
    "    for i, weak_model in enumerate(weak_models):\n",
    "        strong_params = []\n",
    "        wsg_pretrain = []\n",
    "        wsg_finetune = []\n",
    "\n",
    "        # Gather data points corresponding to the current weak model\n",
    "        for (w, s), (pre, fine) in weak_strong_pair_to_wsg.items():\n",
    "            if w == weak_model:\n",
    "                strong_params.append(model_to_size[s])\n",
    "                wsg_pretrain.append(pre)\n",
    "                wsg_finetune.append(fine)\n",
    "\n",
    "        # Sort the data by the strong model's size to ensure lines are drawn correctly\n",
    "        sorted_data = sorted(zip(strong_params, wsg_pretrain, wsg_finetune))\n",
    "        if sorted_data:\n",
    "            x, y_pre, y_fine = zip(*sorted_data)\n",
    "\n",
    "            # Plot finetuned data with a solid line and a label for the weak model\n",
    "            ax.plot(x, y_fine, \"s-\", color=colors[i], label=f\"{weak_model.value}\")\n",
    "            # Plot pretrained data with a dotted line (no label to avoid clutter)\n",
    "            ax.plot(x, y_pre, \"o:\", color=colors[i], alpha=0.5)\n",
    "\n",
    "    # --- Plot Formatting ---\n",
    "    ax.set_xscale(\"log\")\n",
    "    # Use a symmetric log scale for the y-axis to handle positive and negative values\n",
    "    ax.set_yscale(\"symlog\", linthresh=1.0, linscale=2.0)\n",
    "    ax.set_xlabel(\"Strong Model Parameters\")\n",
    "    ax.set_ylabel(\"PGR\")  # Renamed y-axis label\n",
    "    # ax.set_title(title, fontdict={'family': 'monospace'})\n",
    "    ax.set_ylim(y_range)\n",
    "\n",
    "    # Add a horizontal line at y=0 for reference\n",
    "    ax.axhline(y=0, color=\"red\", linewidth=0.8, alpha=1.0)\n",
    "\n",
    "    # Add shaded regions to distinguish the logarithmic parts of the y-axis\n",
    "    ax.axhspan(1, y_range[1], alpha=0.15, color=\"gray\", zorder=0)\n",
    "    ax.axhspan(y_range[0], -1, alpha=0.15, color=\"gray\", zorder=0)\n",
    "\n",
    "    # --- Custom Y-axis Ticks for Symlog Scale ---\n",
    "    linear_ticks = [-0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8]\n",
    "    log_ticks_pos = [2, 5, 10, 20, 50, 100] if y_range[1] > 1 else []\n",
    "    log_ticks_neg = [-2, -5, -10, -20, -50, -100] if y_range[0] < -1 else []\n",
    "\n",
    "    all_ticks = (\n",
    "        [t for t in log_ticks_neg if t >= y_range[0]]\n",
    "        + [-1]\n",
    "        + linear_ticks\n",
    "        + [1]\n",
    "        + [t for t in log_ticks_pos if t <= y_range[1]]\n",
    "    )\n",
    "    # Format tick labels for clarity\n",
    "    tick_labels = [f\"{tick:.1f}\" if -1 < tick < 1 else f\"{tick}\" for tick in all_ticks]\n",
    "    ax.set_yticks(all_ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # --- Custom Legend ---\n",
    "    if plot_legend:\n",
    "        # Get the handles and labels from the model plots (e.g., for weak model sizes)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        # Create custom legend entries for the line styles (Finetuned vs. Pretrained)\n",
    "        linestyle_handles = [\n",
    "            Line2D([0], [0], color=\"gray\", linestyle=\"-\", lw=2, label=\"Finetuned\"),\n",
    "            Line2D([0], [0], color=\"gray\", linestyle=\":\", lw=2, label=\"Pretrained\"),\n",
    "        ]\n",
    "\n",
    "        # Combine handles and draw the legend with a title and custom fonts\n",
    "        ax.legend(\n",
    "            handles=handles + linestyle_handles,\n",
    "            title=\"Weak Model Size\",\n",
    "            # Sets the font for the labels (e.g., 'Weak: 70M')\n",
    "            prop={\"family\": \"monospace\"},\n",
    "            # Sets the font for the title ('Weak Model Size')\n",
    "            title_fontproperties={\"family\": \"monospace\"},\n",
    "        )\n",
    "\n",
    "    # Adjust layout to prevent labels from overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)  # Adjust bottom to make space for the text\n",
    "\n",
    "    # Save the plot if a path is provided\n",
    "    if image_path:\n",
    "        # Ensure the directory exists\n",
    "        # os.makedirs(image_path, exist_ok=True)\n",
    "        if overwrite and os.path.exists(image_path):\n",
    "            print(f\"Overwriting existing file: {image_path}\")\n",
    "            os.remove(image_path)\n",
    "        # Save the figure with a tight bounding box to minimize whitespace\n",
    "        print(f\"Saving plot to {image_path}\")\n",
    "        plt.savefig(image_path, bbox_inches=\"tight\", pad_inches=0.05, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "othello_rule = OthelloRule.CHESS\n",
    "\n",
    "project_name_pretrain = \"pretrain_sweep_1\"\n",
    "results_path = finetuned_rule_to_result_file[othello_rule]\n",
    "image_path = results_path[:-4] + \".png\"\n",
    "model_to_size, weak_strong_pair_to_wsg = compute_loss_finetune_models(\n",
    "    data_folder=data_folder,\n",
    "    experiment_folder=experiment_folder,\n",
    "    project_name_pretrain=project_name_pretrain,\n",
    "    results_path=results_path,\n",
    "    othello_rule_to_test=othello_rule_to_test,\n",
    "    index=0,\n",
    "    device=DEVICE,\n",
    "    final=False,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "plot_finetune_sweep(\n",
    "    model_to_size,\n",
    "    weak_strong_pair_to_wsg,\n",
    "    image_path,\n",
    "    str(othello_rule)[12:].lower(),\n",
    "    overwrite=True,\n",
    "    plot_legend=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9hvwWKsGku4"
   },
   "source": [
    "### linear_probe_sweep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dI4nJNtIGk-0"
   },
   "outputs": [],
   "source": [
    "def linear_probe_pretrained_sweep(\n",
    "    pretrained_project_name: str,\n",
    "    project_name: str,\n",
    "    experiment_folder: str,\n",
    "    othello_rule: OthelloRule,\n",
    "    model_size_filter: list[ModelSize],\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "):\n",
    "    print(\"fake_board_state_transform: \", fake_board_state_transform)\n",
    "    for model_size in model_size_filter:\n",
    "        print(model_size)\n",
    "        hooked_model = load_model_pretrained(\n",
    "            project_name=pretrained_project_name,\n",
    "            model_size=model_size,\n",
    "            othello_rule=othello_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=DEVICE,\n",
    "            index=0,\n",
    "            final=False,\n",
    "        )\n",
    "        if hooked_model is None:\n",
    "            print(f\"Failed to load model for {model_size}, skipping...\")\n",
    "            continue\n",
    "        layer = int(hooked_model.cfg.n_layers / 4 * 3)\n",
    "        print(layer)\n",
    "        train_linear_probe_pretrained(\n",
    "            hooked_model,\n",
    "            layer,\n",
    "            project_name,\n",
    "            othello_rule,\n",
    "            model_size,\n",
    "            experiment_folder,\n",
    "            train_board_state_dataset,\n",
    "            val_board_state_dataset,\n",
    "            othello_rule_to_board_state_test_dataset,\n",
    "            final=False,\n",
    "            fake_board_state_transform=fake_board_state_transform,\n",
    "        )\n",
    "\n",
    "\n",
    "# linear_probe_pretrained_sweep(\n",
    "#     \"pretrain_sweep_1\",\n",
    "#     \"modulo_pretrain_sweep_1_linear_probe\",  # \"pretrain_sweep_1_linear_probe\", \"chess_1_linear_probe\"\n",
    "#     # \"playground_othello\",\n",
    "#     experiment_folder,\n",
    "#     OthelloRule.STANDARD,\n",
    "#     [ModelSize.NANO, ModelSize.MICRO, ModelSize.MINI, ModelSize.SMALL, ModelSize.MEDIUM, ModelSize.LARGE, ModelSize.HUGE],\n",
    "#     train_board_state_dataset,\n",
    "#     val_board_state_dataset,\n",
    "#     othello_rule_to_board_state_test_dataset,\n",
    "#     fake_board_state_transform=fake_board_state_transform,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrl0AgyEGqcC"
   },
   "outputs": [],
   "source": [
    "def linear_probe_finetuned_sweep(\n",
    "    finetuned_project_name: str,\n",
    "    project_name: str,\n",
    "    experiment_folder: str,\n",
    "    notebook_index: int,\n",
    "    n_notebooks: int,\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "    final: bool,\n",
    "):\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    weak_strong_pairs = get_weak_strong_pairs()\n",
    "    total_tasks = len(weak_strong_pairs)\n",
    "    base_tasks_per_notebook = total_tasks // n_notebooks\n",
    "    extra_tasks = total_tasks % n_notebooks\n",
    "    if notebook_index < extra_tasks:  # This notebook gets one extra task\n",
    "        start_idx = notebook_index * (base_tasks_per_notebook + 1)\n",
    "        end_idx = start_idx + base_tasks_per_notebook + 1\n",
    "    else:  # This notebook gets base number of tasks\n",
    "        start_idx = (\n",
    "            extra_tasks * (base_tasks_per_notebook + 1)\n",
    "            + (notebook_index - extra_tasks) * base_tasks_per_notebook\n",
    "        )\n",
    "        end_idx = start_idx + base_tasks_per_notebook\n",
    "\n",
    "    print(\n",
    "        f\"Notebook {notebook_index}/{n_notebooks}: Processing tasks {start_idx} to {end_idx - 1} (total: {end_idx - start_idx} tasks)\"\n",
    "    )\n",
    "    print(weak_strong_pairs[start_idx:end_idx])\n",
    "    for weak_model_size, strong_model_size in weak_strong_pairs[start_idx:end_idx]:\n",
    "        print(weak_model_size, strong_model_size)\n",
    "        hooked_model = load_finetuned_model(\n",
    "            project_name=finetuned_project_name,\n",
    "            weak_model_size=weak_model_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_model_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=DEVICE,\n",
    "            index=0,\n",
    "            final=final,\n",
    "        )\n",
    "        if hooked_model is None:\n",
    "            print(\n",
    "                f\"Failed to load finetuned model for {weak_model_size}-{strong_model_size}, skipping...\"\n",
    "            )\n",
    "            continue\n",
    "        layer = int(hooked_model.cfg.n_layers / 4 * 3)\n",
    "        print(layer)\n",
    "        train_linear_probe_finetuned(\n",
    "            hooked_model,\n",
    "            layer,\n",
    "            project_name,\n",
    "            weak_model_size,\n",
    "            weak_rule,\n",
    "            strong_model_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            train_board_state_dataset,\n",
    "            val_board_state_dataset,\n",
    "            othello_rule_to_board_state_test_dataset,\n",
    "            final,\n",
    "        )\n",
    "\n",
    "\n",
    "# linear_probe_finetuned_sweep(\n",
    "#     finetuned_project_name=\"finetune_sweep_2_no_flipping\",\n",
    "#     project_name=\"finetune_sweep_2_no_flipping_linear_probe\",\n",
    "#     # project_name=\"playground_othello\",\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     notebook_index=2,\n",
    "#     n_notebooks=7,\n",
    "#     train_board_state_dataset=train_board_state_dataset,\n",
    "#     val_board_state_dataset=val_board_state_dataset,\n",
    "#     othello_rule_to_board_state_test_dataset=othello_rule_to_board_state_test_dataset,\n",
    "#     final=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBIyzWRluaH1"
   },
   "outputs": [],
   "source": [
    "!ls '/content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_sweep_2_untrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orCzD9XX1Ic4"
   },
   "outputs": [],
   "source": [
    "def linear_probe_finetuned_over_time_sweep(\n",
    "    finetuned_project_name: str,\n",
    "    project_name: str,\n",
    "    experiment_folder: str,\n",
    "    weak_rule: OthelloRule,\n",
    "    weak_model_size: ModelSize,\n",
    "    strong_rule: OthelloRule,\n",
    "    strong_model_size: ModelSize,\n",
    "    steps: list[int],\n",
    "    notebook_index: int,\n",
    "    n_notebooks: int,\n",
    "    train_board_state_dataset: BoardStateDataset,\n",
    "    val_board_state_dataset: BoardStateDataset,\n",
    "    othello_rule_to_board_state_test_dataset: dict[\n",
    "        OthelloRule, list[BoardStateDataset]\n",
    "    ],\n",
    "):\n",
    "    total_tasks = len(steps)\n",
    "    base_tasks_per_notebook = total_tasks // n_notebooks\n",
    "    extra_tasks = total_tasks % n_notebooks\n",
    "    if notebook_index < extra_tasks:  # This notebook gets one extra task\n",
    "        start_idx = notebook_index * (base_tasks_per_notebook + 1)\n",
    "        end_idx = start_idx + base_tasks_per_notebook + 1\n",
    "    else:  # This notebook gets base number of tasks\n",
    "        start_idx = (\n",
    "            extra_tasks * (base_tasks_per_notebook + 1)\n",
    "            + (notebook_index - extra_tasks) * base_tasks_per_notebook\n",
    "        )\n",
    "        end_idx = start_idx + base_tasks_per_notebook\n",
    "\n",
    "    print(\n",
    "        f\"Notebook {notebook_index}/{n_notebooks}: Processing tasks {start_idx} to {end_idx - 1} (total: {end_idx - start_idx} tasks)\"\n",
    "    )\n",
    "    print(steps[start_idx:end_idx])\n",
    "    for step_index in steps[start_idx:end_idx]:\n",
    "        hooked_model = load_finetuned_model(\n",
    "            project_name=finetuned_project_name,\n",
    "            weak_model_size=weak_model_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_model_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=DEVICE,\n",
    "            index=step_index,\n",
    "            final=False,\n",
    "        )\n",
    "        if hooked_model is None:\n",
    "            print(f\"Failed to load finetuned model for step {step_index}, skipping...\")\n",
    "            continue\n",
    "        layer = int(hooked_model.cfg.n_layers / 4 * 3)\n",
    "        print(layer)\n",
    "        train_linear_probe_finetuned(\n",
    "            hooked_model,\n",
    "            layer,\n",
    "            project_name,\n",
    "            weak_model_size,\n",
    "            weak_rule,\n",
    "            strong_model_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            train_board_state_dataset,\n",
    "            val_board_state_dataset,\n",
    "            othello_rule_to_board_state_test_dataset,\n",
    "            False,\n",
    "        )\n",
    "\n",
    "\n",
    "# steps = [10 * n for n in range(0, 40)] + [400 + 60 * n for n in range(20)]\n",
    "# linear_probe_finetuned_over_time_sweep(\n",
    "#     finetuned_project_name=\"finetune_many_checkpoints\",\n",
    "#     project_name=\"finetune_many_checkpoints_linear_probe\",\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     weak_rule=OthelloRule.STANDARD,\n",
    "#     weak_model_size=ModelSize.MINI,\n",
    "#     strong_rule=OthelloRule.BIAS_CLOCK,\n",
    "#     strong_model_size=ModelSize.HUGE,\n",
    "#     steps,\n",
    "#     notebook_index=0,\n",
    "#     n_notebooks=10,\n",
    "#     train_board_state_dataset=train_board_state_dataset,\n",
    "#     val_board_state_dataset=val_board_state_dataset,\n",
    "#     othello_rule_to_board_state_test_dataset=othello_rule_to_board_state_test_dataset,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZEfASMX0Gjy"
   },
   "source": [
    "### plot_linear_probe_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7sTVscj0F-8"
   },
   "outputs": [],
   "source": [
    "def compute_board_prediction_pretrained(\n",
    "    experiment_folder: str,\n",
    "    project_name_linear_probe: str,\n",
    "    project_name_pretrain: str,\n",
    "    othello_rule_to_board_state_test_dataset: dict[OthelloRule, BoardStateDataset],\n",
    "    list_othello_rules: list[OthelloRule],\n",
    "    index: int,\n",
    "    device: t.device,\n",
    "    final: bool = False,\n",
    "    fake_board_state_transform: FakeBoardStateTransform | None = None,\n",
    "    overwrite: bool = False,\n",
    ") -> list[dict]:\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    test_board_state_dataset = othello_rule_to_board_state_test_dataset[weak_rule]\n",
    "\n",
    "    results_filename = f\"board_prediction_pretrained.pkl\"\n",
    "    results_path = os.path.join(\n",
    "        experiment_folder, project_name_linear_probe, results_filename\n",
    "    )\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "            print(f\"Loaded {len(results)} existing results\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    results = []\n",
    "    if fake_board_state_transform:\n",
    "        fake_probe = fake_board_state_transform.name\n",
    "    else:\n",
    "        fake_probe = \"\"\n",
    "    print(\"fake_board_state_transform: \", fake_board_state_transform)\n",
    "    print(\"fake_probe: \", fake_probe)\n",
    "\n",
    "    for model_size in [\n",
    "        ModelSize.NANO,\n",
    "        ModelSize.MICRO,\n",
    "        ModelSize.MINI,\n",
    "        ModelSize.SMALL,\n",
    "        ModelSize.MEDIUM,\n",
    "        ModelSize.LARGE,\n",
    "        ModelSize.HUGE,\n",
    "    ]:\n",
    "        for othello_rule in list_othello_rules:\n",
    "            # Load the base model\n",
    "            model = load_model_pretrained(\n",
    "                project_name_pretrain,\n",
    "                model_size,\n",
    "                othello_rule,\n",
    "                experiment_folder,\n",
    "                device,\n",
    "                index,\n",
    "                final=final,\n",
    "            )\n",
    "            if not model:\n",
    "                print(f\"Missing model: {index}, {model_size}, {othello_rule}\")\n",
    "                continue\n",
    "\n",
    "            # Load the linear probe\n",
    "            linear_probe = load_model_pretrained(\n",
    "                project_name_linear_probe,\n",
    "                model_size,\n",
    "                othello_rule,\n",
    "                experiment_folder,\n",
    "                device,\n",
    "                index,\n",
    "                final=final,\n",
    "                linear_probe=True,\n",
    "                fake_probe=fake_probe,\n",
    "            )\n",
    "            if linear_probe is None:\n",
    "                print(f\"Missing linear probe: {index}, {model_size}, {othello_rule}\")\n",
    "                model.cpu()\n",
    "                del model\n",
    "                t.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "            # Evaluate probe generalization\n",
    "            layer = int(model.cfg.n_layers / 4 * 3)\n",
    "            _, _, _, mean_accuracy_both_on_all = evaluate_probe_generalization(\n",
    "                probe=linear_probe,\n",
    "                model=model,\n",
    "                board_seqs_square_test=test_board_state_dataset.board_seqs_square,\n",
    "                board_seqs_id_test=test_board_state_dataset.board_seqs_id,\n",
    "                layer=layer,\n",
    "                device=device,\n",
    "                othello_rule=weak_rule,\n",
    "                plot_results=False,\n",
    "                fake_board_state_transform=fake_board_state_transform,\n",
    "            )\n",
    "            print(\"mean_accuracy_both_on_all: \", mean_accuracy_both_on_all)\n",
    "\n",
    "            n_parameters = count_parameters(model)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"othello_rule\": othello_rule,\n",
    "                    \"model_size\": model_size,\n",
    "                    \"n_parameters\": n_parameters,\n",
    "                    \"mean_accuracy\": mean_accuracy_both_on_all.item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Clean memory\n",
    "            model.cpu()\n",
    "            linear_probe.cpu()\n",
    "            del model, linear_probe\n",
    "            t.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    if len(results) == 0:\n",
    "        print(\"No models found.\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_board_prediction_pretrained(\n",
    "    results: list[dict],\n",
    "    save_path: str | None = None,\n",
    "    list_othello_rules: list[OthelloRule] = None,\n",
    "):\n",
    "    if list_othello_rules is None:\n",
    "        print(\"Please provide a list of othello rules to plot\")\n",
    "        return\n",
    "    df = pd.DataFrame(results)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    unique_rules = df[\"othello_rule\"].unique()\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(unique_rules)))\n",
    "\n",
    "    # Plot each rule with a different color\n",
    "    for i, rule in enumerate(unique_rules):\n",
    "        rule_data = df[df[\"othello_rule\"] == rule]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=rule_data,\n",
    "            x=\"n_parameters\",\n",
    "            y=\"mean_accuracy\",\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            ax=ax,\n",
    "            color=colors[i],\n",
    "            label=f\"Trained on {rule.value}\",\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_xlabel(\"Number of Parameters (log scale)\")\n",
    "    ax.set_ylabel(\"Mean Board State Prediction Accuracy\")\n",
    "    ax.set_title(\"Board State Prediction Accuracy by Othello Rule\")\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        save_dir = os.path.dirname(save_path)\n",
    "        if save_dir and not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_path, \"board_prediction_pretrained.png\")\n",
    "        try:\n",
    "            plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to {save_path}: {e}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# project_name_pretrain = 'pretrain_sweep_1'\n",
    "# project_name_linear_probe = 'modulo_pretrain_sweep_1_linear_probe' # 'pretrain_sweep_1_linear_probe', 'chess_1_linear_probe'\n",
    "# # list_othello_rules = [othello_rule for othello_rule in OthellRule]\n",
    "# # print(\"list_othello_rules: \", list_othello_rules)\n",
    "# # list_othello_rules = [OthelloRule.STANDARD]  #\n",
    "# list_othello_rules = [OthelloRule.NO_FLIPPING, OthelloRule.CONSTANT_PARAMETERS, OthelloRule.UNTRAINED, OthelloRule.STANDARD, OthelloRule.BIAS_CLOCK, OthelloRule.NEXT_TO_OPPONENT, OthelloRule.CHESS]\n",
    "# results = compute_board_prediction_pretrained(\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     project_name_linear_probe=project_name_linear_probe,\n",
    "#     project_name_pretrain=project_name_pretrain,\n",
    "#     othello_rule_to_board_state_test_dataset=othello_rule_to_board_state_test_dataset,\n",
    "#     list_othello_rules=list_othello_rules,\n",
    "#     index=0,\n",
    "#     device=DEVICE,\n",
    "#     final=False,\n",
    "#     fake_board_state_transform=fake_board_state_transform,\n",
    "#     overwrite=True,\n",
    "# )\n",
    "\n",
    "# save_path = os.path.join(experiment_folder, project_name_linear_probe)\n",
    "# plot_board_prediction_pretrained(results, save_path, list_othello_rules=list_othello_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zk42Fvpp9LCl"
   },
   "outputs": [],
   "source": [
    "def compute_board_prediction_finetuned(\n",
    "    experiment_folder: str,\n",
    "    project_name_pretrain: str,\n",
    "    project_name_finetune: str,\n",
    "    project_name_pretrained_linear_probe: str,\n",
    "    project_name_finetuned_linear_probe: str,\n",
    "    othello_rule_to_test: dict[OthelloRule, CharDataset],\n",
    "    index: int,\n",
    "    device: t.device,\n",
    "    overwrite: bool = False,\n",
    ") -> tuple[\n",
    "    dict[ModelSize, int], dict[tuple[ModelSize, ModelSize], tuple[float, float, float]]\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns two dict:\n",
    "        model_to_size: model_size -> n_parameters\n",
    "        weak_strong_pair_to_wsg: (weak_model_size, strong_model_size) -> (wsg_pretrained, wsg_finetuned, wsg_finetuned_final)\n",
    "    \"\"\"\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    results_filename = (\n",
    "        f\"board_prediction_finetuned_{weak_rule.value}_{strong_rule.value}.pkl\"\n",
    "    )\n",
    "    results_path = os.path.join(\n",
    "        experiment_folder, project_name_pretrain, results_filename\n",
    "    )\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "            print(f\"Loaded {len(results)} existing results\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    weak_test_dataset = othello_rule_to_test[weak_rule]\n",
    "    test_board_state_dataset = BoardStateDataset(weak_test_dataset, n_games=1000)\n",
    "\n",
    "    model_to_size = {}\n",
    "    weak_strong_pair_to_wsg = {}\n",
    "\n",
    "    # Cache for accuracies: (model_key) -> accuracy\n",
    "    accuracy_cache = {}\n",
    "\n",
    "    def get_cached_accuracy(model_key, model, probe, layer):\n",
    "        \"\"\"Get accuracy from cache or compute and cache it.\"\"\"\n",
    "        if model_key in accuracy_cache:\n",
    "            print(f\"  Using cached accuracy for {model_key}\")\n",
    "            return accuracy_cache[model_key]\n",
    "\n",
    "        print(f\"Computing accuracy for {model_key}\")\n",
    "        _, _, _, accuracy = evaluate_probe_generalization(\n",
    "            probe,\n",
    "            model,\n",
    "            test_board_state_dataset.board_seqs_square,\n",
    "            test_board_state_dataset.board_seqs_id,\n",
    "            layer,\n",
    "            device,\n",
    "            plot_results=False,\n",
    "        )\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        accuracy_cache[model_key] = accuracy\n",
    "        return accuracy\n",
    "\n",
    "    weak_strong_pairs = get_weak_strong_pairs()\n",
    "    for weak_size, strong_size in weak_strong_pairs:\n",
    "        print(\n",
    "            \"----------\",\n",
    "            weak_size,\n",
    "            strong_size,\n",
    "            len(weak_strong_pair_to_wsg),\n",
    "            \"----------\",\n",
    "        )\n",
    "\n",
    "        # Load models\n",
    "        weak_model_weak_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "        strong_model_weak_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            strong_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "        strong_model_strong_rule = load_model_pretrained(\n",
    "            project_name_pretrain,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "        finetuned_model = load_finetuned_model(\n",
    "            project_name_finetune,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "        finetuned_model_final = load_finetuned_model(\n",
    "            project_name_finetune,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=True,\n",
    "        )\n",
    "\n",
    "        # Load linear probes\n",
    "        weak_probe = load_model(\n",
    "            project_name_pretrained_linear_probe,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "        strong_weak_probe = load_model(\n",
    "            project_name_pretrained_linear_probe,\n",
    "            strong_size,\n",
    "            weak_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "        strong_strong_probe = load_model(\n",
    "            project_name_pretrained_linear_probe,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "\n",
    "        # Load finetuned linear probes using load_finetuned_model\n",
    "        finetuned_probe = load_finetuned_model(\n",
    "            project_name=project_name_finetuned_linear_probe,\n",
    "            weak_model_size=weak_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=device,\n",
    "            index=index,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "        finetuned_probe_final = load_finetuned_model(\n",
    "            project_name=project_name_finetuned_linear_probe,\n",
    "            weak_model_size=weak_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=device,\n",
    "            index=index,\n",
    "            final=True,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "\n",
    "        # Check if all required models/probes are available\n",
    "        models_and_probes = [\n",
    "            weak_model_weak_rule,\n",
    "            strong_model_weak_rule,\n",
    "            strong_model_strong_rule,\n",
    "            finetuned_model,\n",
    "            finetuned_model_final,\n",
    "            weak_probe,\n",
    "            strong_weak_probe,\n",
    "            strong_strong_probe,\n",
    "            finetuned_probe,\n",
    "            finetuned_probe_final,\n",
    "        ]\n",
    "        if any(item is None for item in models_and_probes):\n",
    "            print(f\"Missing models/probes: {index}, {weak_size}, {strong_size}\")\n",
    "            continue\n",
    "\n",
    "        # Store model sizes\n",
    "        if weak_size not in model_to_size:\n",
    "            model_to_size[weak_size] = count_parameters(weak_model_weak_rule)\n",
    "        if strong_size not in model_to_size:\n",
    "            model_to_size[strong_size] = count_parameters(strong_model_weak_rule)\n",
    "\n",
    "        # Calculate layers\n",
    "        weak_layer = int(weak_model_weak_rule.cfg.n_layers / 4 * 3)\n",
    "        strong_layer = int(strong_model_weak_rule.cfg.n_layers / 4 * 3)\n",
    "        finetuned_layer = int(finetuned_model.cfg.n_layers / 4 * 3)\n",
    "\n",
    "        # Evaluate board prediction accuracies with caching\n",
    "        acc_weak_model = get_cached_accuracy(\n",
    "            f\"pretrain_{weak_size}_{weak_rule}\",\n",
    "            weak_model_weak_rule,\n",
    "            weak_probe,\n",
    "            weak_layer,\n",
    "        )\n",
    "        acc_strong_model_weak_rule = get_cached_accuracy(\n",
    "            f\"pretrain_{strong_size}_{weak_rule}\",\n",
    "            strong_model_weak_rule,\n",
    "            strong_weak_probe,\n",
    "            strong_layer,\n",
    "        )\n",
    "        acc_strong_model_strong_rule = get_cached_accuracy(\n",
    "            f\"pretrain_{strong_size}_{strong_rule}\",\n",
    "            strong_model_strong_rule,\n",
    "            strong_strong_probe,\n",
    "            strong_layer,\n",
    "        )\n",
    "        acc_finetuned_model = get_cached_accuracy(\n",
    "            f\"finetune_{weak_size}_{strong_size}_{weak_rule}_to_{strong_rule}_non_final\",\n",
    "            finetuned_model,\n",
    "            finetuned_probe,\n",
    "            finetuned_layer,\n",
    "        )\n",
    "        acc_finetuned_model_final = get_cached_accuracy(\n",
    "            f\"finetune_{weak_size}_{strong_size}_{weak_rule}_to_{strong_rule}_final\",\n",
    "            finetuned_model_final,\n",
    "            finetuned_probe_final,\n",
    "            finetuned_layer,\n",
    "        )\n",
    "\n",
    "        # Calculate WSG scores (using accuracy instead of loss, so formula is flipped)\n",
    "        wsg_pretrained = (acc_strong_model_strong_rule - acc_weak_model) / (\n",
    "            acc_strong_model_weak_rule - acc_weak_model\n",
    "        )\n",
    "        wsg_finetuned = (acc_finetuned_model - acc_weak_model) / (\n",
    "            acc_strong_model_weak_rule - acc_weak_model\n",
    "        )\n",
    "        wsg_finetuned_final = (acc_finetuned_model_final - acc_weak_model) / (\n",
    "            acc_strong_model_weak_rule - acc_weak_model\n",
    "        )\n",
    "\n",
    "        weak_strong_pair_to_wsg[(weak_size, strong_size)] = (\n",
    "            wsg_pretrained.item(),\n",
    "            wsg_finetuned.item(),\n",
    "            wsg_finetuned_final.item(),\n",
    "        )\n",
    "\n",
    "        # Clean memory\n",
    "        for model in [\n",
    "            weak_model_weak_rule,\n",
    "            strong_model_weak_rule,\n",
    "            strong_model_strong_rule,\n",
    "            finetuned_model,\n",
    "            finetuned_model_final,\n",
    "        ]:\n",
    "            model.cpu()\n",
    "            del model\n",
    "        del (\n",
    "            weak_probe,\n",
    "            strong_weak_probe,\n",
    "            strong_strong_probe,\n",
    "            finetuned_probe,\n",
    "            finetuned_probe_final,\n",
    "        )\n",
    "        t.cuda.empty_cache()\n",
    "\n",
    "    results = (model_to_size, weak_strong_pair_to_wsg)\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return model_to_size, weak_strong_pair_to_wsg\n",
    "\n",
    "\n",
    "def plot_board_prediction_finetuned(\n",
    "    model_to_size: dict[ModelSize, int],\n",
    "    weak_strong_pair_to_wsg: dict[\n",
    "        tuple[ModelSize, ModelSize], tuple[float, float, float]\n",
    "    ],\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Get unique weak models and sort by size\n",
    "    weak_models = sorted(\n",
    "        set(pair[0] for pair in weak_strong_pair_to_wsg.keys()),\n",
    "        key=lambda x: model_to_size[x],\n",
    "    )\n",
    "\n",
    "    # Create color map based on weak model parameters\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(weak_models)))\n",
    "\n",
    "    # Collect all y-values to determine shared y-axis range\n",
    "    all_y_values = []\n",
    "    for (w, s), (pre, fine, fine_final) in weak_strong_pair_to_wsg.items():\n",
    "        all_y_values.extend([pre, fine, fine_final])\n",
    "\n",
    "    y_min, y_max = min(all_y_values), max(all_y_values)\n",
    "    y_margin = (y_max - y_min) * 0.1\n",
    "    y_range = (y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "    for i, weak_model in enumerate(weak_models):\n",
    "        # Get data for this weak model\n",
    "        strong_params = []\n",
    "        wsg_pretrain = []\n",
    "        wsg_finetune = []\n",
    "        wsg_finetune_final = []\n",
    "\n",
    "        for (w, s), (pre, fine, fine_final) in weak_strong_pair_to_wsg.items():\n",
    "            if w == weak_model:\n",
    "                strong_params.append(model_to_size[s])\n",
    "                wsg_pretrain.append(pre)\n",
    "                wsg_finetune.append(fine)\n",
    "                wsg_finetune_final.append(fine_final)\n",
    "\n",
    "        # Sort by strong model size\n",
    "        sorted_data = sorted(\n",
    "            zip(strong_params, wsg_pretrain, wsg_finetune, wsg_finetune_final)\n",
    "        )\n",
    "        if sorted_data:\n",
    "            x, y_pre, y_fine, y_fine_final = zip(*sorted_data)\n",
    "\n",
    "            ax1.plot(x, y_pre, \"o-\", color=colors[i], label=f\"{weak_model.value}\")\n",
    "            ax2.plot(x, y_fine, \"o-\", color=colors[i], label=f\"{weak_model.value}\")\n",
    "            ax3.plot(\n",
    "                x, y_fine_final, \"o-\", color=colors[i], label=f\"{weak_model.value}\"\n",
    "            )\n",
    "\n",
    "    # Formatting\n",
    "    titles = [\"WSG Pretrained\", \"WSG Finetuned\", \"WSG Finetuned Final\"]\n",
    "    for ax, title in zip([ax1, ax2, ax3], titles):\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"symlog\", linthresh=1.0, linscale=2.0)\n",
    "        ax.set_xlabel(\"Strong Model Parameters\")\n",
    "        ax.set_ylabel(\"WSG Score (Board Prediction)\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(y_range)\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        ax.axhline(y=0, color=\"red\", linewidth=0.8, alpha=0.8)\n",
    "\n",
    "        # Add shading for logarithmic regions\n",
    "        ax.axhspan(1, y_range[1], alpha=0.15, color=\"gray\", zorder=0)\n",
    "        ax.axhspan(y_range[0], -1, alpha=0.15, color=\"gray\", zorder=0)\n",
    "\n",
    "        # Custom y-ticks\n",
    "        linear_ticks = [-0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8]\n",
    "        log_ticks_pos = [2, 5, 10, 20, 50, 100] if y_range[1] > 1 else []\n",
    "        log_ticks_neg = [-2, -5, -10, -20, -50, -100] if y_range[0] < -1 else []\n",
    "\n",
    "        all_ticks = (\n",
    "            [t for t in log_ticks_neg if t >= y_range[0]]\n",
    "            + [-1]\n",
    "            + linear_ticks\n",
    "            + [1]\n",
    "            + [t for t in log_ticks_pos if t <= y_range[1]]\n",
    "        )\n",
    "\n",
    "        tick_labels = []\n",
    "        for tick in all_ticks:\n",
    "            if tick == 1:\n",
    "                tick_labels.append(\"1\")\n",
    "            elif tick == -1:\n",
    "                tick_labels.append(\"-1\")\n",
    "            elif -1 < tick < 1:\n",
    "                tick_labels.append(f\"{tick:.1f}\")\n",
    "            else:\n",
    "                tick_labels.append(f\"{tick}\")\n",
    "\n",
    "        ax.set_yticks(all_ticks)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "\n",
    "        # Make linear region ticks smaller\n",
    "        for j, (tick, label) in enumerate(zip(all_ticks, tick_labels)):\n",
    "            if -1 < tick < 1 and tick != 0:\n",
    "                ax.get_yticklabels()[j].set_fontsize(8)\n",
    "\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    # Add text annotations\n",
    "    fig.text(\n",
    "        0.5,\n",
    "        -0.05,\n",
    "        \"White background: Linear scale [-1,1] | Gray background: Logarithmic scale\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "        style=\"italic\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.1)\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(\n",
    "            os.path.join(save_path, \"wsg_board_prediction.png\"),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# project_name_pretrain = 'pretrain_sweep_1'\n",
    "# project_name_finetune = 'finetune_sweep_4_next_to_opponent'\n",
    "# project_name_pretrained_linear_probe = ''pretrain_sweep_1_linear_probe'\n",
    "# project_name_finetuned_linear_probe = 'finetune_sweep_4_next_to_opponent_linear_probe'\n",
    "\n",
    "# model_to_size, weak_strong_pair_to_wsg = compute_board_prediction_finetuned(\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     project_name_pretrain=project_name_pretrain,\n",
    "#     project_name_finetune=project_name_finetune,\n",
    "#     project_name_pretrained_linear_probe=project_name_pretrained_linear_probe,\n",
    "#     project_name_finetuned_linear_probe=project_name_finetuned_linear_probe,\n",
    "#     othello_rule_to_test=othello_rule_to_test,\n",
    "#     index=0,\n",
    "#     device=DEVICE,\n",
    "#     overwrite=False,\n",
    "# )\n",
    "\n",
    "# save_path = os.path.join(experiment_folder, project_name_finetune)\n",
    "# plot_board_prediction_finetuned(model_to_size, weak_strong_pair_to_wsg, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PYl7sb1MkhB"
   },
   "outputs": [],
   "source": [
    "def compute_and_save_board_accuracy_finetuned(\n",
    "    experiment_folder: str,\n",
    "    project_name_finetune: str,\n",
    "    project_name_finetuned_linear_probe: str,\n",
    "    othello_rule_to_board_state_test_dataset: dict[OthelloRule, BoardStateDataset],\n",
    "    index: int,\n",
    "    device: t.device,\n",
    "    overwrite: bool = False,\n",
    ") -> dict[tuple[ModelSize, ModelSize], float]:\n",
    "    \"\"\"\n",
    "    Computes board representation accuracies for finetuning pairs.\n",
    "    Returns:\n",
    "        dict mapping (weak_size, strong_size) -> finetuned_accuracy\n",
    "    \"\"\"\n",
    "    weak_rule = get_othello_rule(Goal.WEAK_GOAL)\n",
    "    strong_rule = get_othello_rule(Goal.STRONG_GOAL)\n",
    "\n",
    "    results_filename = (\n",
    "        f\"board_accuracy_finetuned_{weak_rule.value}_{strong_rule.value}.pkl\"\n",
    "    )\n",
    "    results_path = os.path.join(\n",
    "        experiment_folder, project_name_finetuned_linear_probe, results_filename\n",
    "    )\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing board accuracy results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "            print(f\"Loaded {len(results)} existing board accuracy results\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    test_board_state_dataset = othello_rule_to_board_state_test_dataset[weak_rule]\n",
    "    accuracy_results = {}\n",
    "\n",
    "    weak_strong_pairs = get_weak_strong_pairs()\n",
    "    for weak_size, strong_size in weak_strong_pairs:\n",
    "        print(\"----------\", weak_size, strong_size, len(accuracy_results), \"----------\")\n",
    "        # Load model\n",
    "        finetuned_model = load_finetuned_model(\n",
    "            project_name_finetune,\n",
    "            weak_size,\n",
    "            weak_rule,\n",
    "            strong_size,\n",
    "            strong_rule,\n",
    "            experiment_folder,\n",
    "            device,\n",
    "            index,\n",
    "            final=False,\n",
    "        )\n",
    "\n",
    "        # Load probe\n",
    "        finetuned_probe = load_finetuned_model(\n",
    "            project_name=project_name_finetuned_linear_probe,\n",
    "            weak_model_size=weak_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=device,\n",
    "            index=index,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "\n",
    "        # Check if all required models/probes are available\n",
    "        if finetuned_model is None or finetuned_probe is None:\n",
    "            print(f\"Missing models/probes: {index}, {weak_size}, {strong_size}\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate board prediction accuracies\n",
    "        layer = int(finetuned_model.cfg.n_layers / 4 * 3)\n",
    "        _, _, _, accuracy = evaluate_probe_generalization(\n",
    "            finetuned_probe,\n",
    "            finetuned_model,\n",
    "            test_board_state_dataset.board_seqs_square,\n",
    "            test_board_state_dataset.board_seqs_id,\n",
    "            layer,\n",
    "            device,\n",
    "            weak_rule,\n",
    "            plot_results=False,\n",
    "        )\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        accuracy_results[(weak_size, strong_size)] = accuracy.item()\n",
    "\n",
    "        # Clean memory\n",
    "        finetuned_model.cpu()\n",
    "        finetuned_probe.cpu()\n",
    "        del finetuned_model\n",
    "        del finetuned_probe\n",
    "        t.cuda.empty_cache()\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(accuracy_results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Board accuracy results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return accuracy_results\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# project_name_finetune = 'finetune_sweep_2_no_flipping' # 'finetune_sweep_4_next_to_opponent'\n",
    "# project_name_finetuned_linear_probe = 'finetune_sweep_2_no_flipping_linear_probe' # 'finetune_sweep_4_next_to_opponent_linear_probe'\n",
    "# accuracy_results = compute_and_save_board_accuracy_finetuned(\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     project_name_finetune=project_name_finetune,\n",
    "#     project_name_finetuned_linear_probe=project_name_finetuned_linear_probe,\n",
    "#     othello_rule_to_board_state_test_dataset=othello_rule_to_board_state_test_dataset,\n",
    "#     index=0,\n",
    "#     device=DEVICE,\n",
    "#     overwrite=False,\n",
    "# )\n",
    "# print(accuracy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "CxNSQsZQDKSv",
    "outputId": "de1a4661-d052-4da6-d64d-649e7caeeb64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing results from /content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/pretrain_1/board_prediction_over_time.pkl\n",
      "Loaded 51 existing results\n",
      "Plot saved to /content/drive/MyDrive/Colab Notebooks/WSG_masterthesis/experiments/finetune_many_checkpoints_linear_probe/board_prediction_accuracy_over_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_board_prediction_accuracy_over_time(\n",
    "    experiment_folder: str,\n",
    "    finetuned_project_name: str,\n",
    "    project_name_pretrain: str,\n",
    "    linear_probe_project_name: str,\n",
    "    weak_rule: OthelloRule,\n",
    "    weak_model_size: ModelSize,\n",
    "    strong_rule: OthelloRule,\n",
    "    strong_model_size: ModelSize,\n",
    "    steps: list[int],\n",
    "    othello_rule_to_board_state_test_dataset: dict[OthelloRule, BoardStateDataset],\n",
    "    device: t.device,\n",
    "    overwrite: bool = False,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Compute board prediction accuracies for finetuned models at different training steps.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with keys: 'step', 'accuracy', 'n_parameters'\n",
    "    \"\"\"\n",
    "    results_filename = f\"board_prediction_over_time.pkl\"\n",
    "    results_path = os.path.join(\n",
    "        experiment_folder, project_name_pretrain, results_filename\n",
    "    )\n",
    "\n",
    "    if not overwrite and os.path.exists(results_path):\n",
    "        print(f\"Loading existing results from {results_path}\")\n",
    "        try:\n",
    "            with open(results_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "            print(f\"Loaded {len(results)} existing results\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing results: {e}\")\n",
    "            print(\"Computing new results...\")\n",
    "\n",
    "    weak_test_dataset = othello_rule_to_board_state_test_dataset[weak_rule]\n",
    "    results = []\n",
    "\n",
    "    for step in steps:\n",
    "        print(f\"Processing step {step}...\")\n",
    "\n",
    "        # Load corresponding linear probe\n",
    "        linear_probe = load_finetuned_model(\n",
    "            project_name=linear_probe_project_name,\n",
    "            weak_model_size=weak_model_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_model_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=device,\n",
    "            index=step,\n",
    "            final=False,\n",
    "            linear_probe=True,\n",
    "        )\n",
    "\n",
    "        if linear_probe is None:\n",
    "            print(f\"  Failed to load linear probe for step {step}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load finetuned model at this step\n",
    "        finetuned_model = load_finetuned_model(\n",
    "            project_name=finetuned_project_name,\n",
    "            weak_model_size=weak_model_size,\n",
    "            weak_rule=weak_rule,\n",
    "            strong_model_size=strong_model_size,\n",
    "            strong_rule=strong_rule,\n",
    "            experiment_folder=experiment_folder,\n",
    "            device=device,\n",
    "            index=step,\n",
    "            final=False,\n",
    "        )\n",
    "\n",
    "        if finetuned_model is None:\n",
    "            print(f\"  Failed to load finetuned model for step {step}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Evaluate probe accuracy\n",
    "            layer = int(finetuned_model.cfg.n_layers / 4 * 3)\n",
    "            _, _, _, mean_accuracy_both_on_all = evaluate_probe_generalization(\n",
    "                probe=linear_probe,\n",
    "                model=finetuned_model,\n",
    "                board_seqs_square_test=weak_test_dataset.board_seqs_square,\n",
    "                board_seqs_id_test=weak_test_dataset.board_seqs_id,\n",
    "                layer=layer,\n",
    "                device=device,\n",
    "                plot_results=False,\n",
    "                othello_rule=weak_rule,  # Added missing parameter\n",
    "            )\n",
    "\n",
    "            n_parameters = count_parameters(finetuned_model)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"accuracy\": mean_accuracy_both_on_all.item(),\n",
    "                    \"n_parameters\": n_parameters,\n",
    "                    \"weak_model_size\": weak_model_size,\n",
    "                    \"strong_model_size\": strong_model_size,\n",
    "                    \"weak_rule\": weak_rule,\n",
    "                    \"strong_rule\": strong_rule,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"  Step {step}: Accuracy = {mean_accuracy_both_on_all.item():.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error evaluating step {step}: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # Clean memory\n",
    "            if \"finetuned_model\" in locals():\n",
    "                finetuned_model.cpu()\n",
    "                del finetuned_model\n",
    "            if \"linear_probe\" in locals():\n",
    "                del linear_probe\n",
    "            t.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    print(f\"Completed processing {len(results)}/{len(steps)} steps\")\n",
    "\n",
    "    # Save results (fixed the incorrect assignment)\n",
    "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "    try:\n",
    "        with open(results_path, \"wb\") as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Results saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_board_prediction_accuracy_over_time(\n",
    "    results: list[dict], save_path: str | None = None, title_suffix: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot board prediction accuracy over training steps.\n",
    "\n",
    "    Args:\n",
    "        results: List of dictionaries from compute_board_prediction_accuracy_over_time\n",
    "        save_path: Optional path to save the plot\n",
    "        title_suffix: Optional suffix to add to plot title\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "    # Plot accuracy over steps\n",
    "    sns.lineplot(data=df, x=\"step\", y=\"accuracy\", marker=\"o\", linestyle=\"-\", ax=ax)\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_xlabel(\"Finetuning step\")\n",
    "    ax.set_ylabel(\"Linear Probe Accuracy [empty/mine/yours]\")\n",
    "    ax.set_ylim((0.7, 1))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Create title from the data\n",
    "    if results:\n",
    "        sample = results[0]\n",
    "        weak_size = sample[\"weak_model_size\"].value\n",
    "        strong_size = sample[\"strong_model_size\"].value\n",
    "        weak_rule = sample[\"weak_rule\"].value\n",
    "        strong_rule = sample[\"strong_rule\"].value\n",
    "        title = f\"Linear probe accuracy during finetuning\\n{weak_size}{strong_size}, {weak_rule}{strong_rule}\"\n",
    "        if title_suffix:\n",
    "            title += f\" {title_suffix}\"\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # Add some statistics as text\n",
    "    # if len(results) > 1:\n",
    "    #     initial_acc = results[0]['accuracy']\n",
    "    #     final_acc = results[-1]['accuracy']\n",
    "    #     max_acc = max(r['accuracy'] for r in results)\n",
    "    #     min_acc = min(r['accuracy'] for r in results)\n",
    "\n",
    "    #     stats_text = f\"Initial: {initial_acc:.3f}\\nFinal: {final_acc:.3f}\\nMax: {max_acc:.3f}\\nMin: {min_acc:.3f}\"\n",
    "    #     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n",
    "    #             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    if save_path:\n",
    "        save_dir = os.path.dirname(save_path)\n",
    "        if save_dir and not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        plot_file_path = os.path.join(\n",
    "            save_path, \"board_prediction_accuracy_over_time.png\"\n",
    "        )\n",
    "        try:\n",
    "            plt.savefig(plot_file_path, bbox_inches=\"tight\", dpi=300)\n",
    "            print(f\"Plot saved to {plot_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to {plot_file_path}: {e}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# steps = [10 * n for n in range(0, 40)] + [400 + 60 * n for n in range(20)]\n",
    "# # steps = [10]\n",
    "\n",
    "# results = compute_board_prediction_accuracy_over_time(\n",
    "#     experiment_folder=experiment_folder,\n",
    "#     finetuned_project_name=\"finetune_many_checkpoints\",\n",
    "#     project_name_pretrain=\"pretrain_1\",\n",
    "#     linear_probe_project_name=\"finetune_many_checkpoints_linear_probe\",\n",
    "#     weak_rule=OthelloRule.STANDARD,\n",
    "#     weak_model_size=ModelSize.MINI,\n",
    "#     strong_rule=OthelloRule.BIAS_CLOCK,\n",
    "#     strong_model_size=ModelSize.HUGE,\n",
    "#     steps=steps,\n",
    "#     othello_rule_to_board_state_test_dataset=othello_rule_to_board_state_test_dataset,\n",
    "#     device=DEVICE,\n",
    "#     overwrite=False,\n",
    "# )\n",
    "\n",
    "# save_path = os.path.join(experiment_folder, \"finetune_many_checkpoints_linear_probe\")\n",
    "# plot_board_prediction_accuracy_over_time(results, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4L5Qx66M_1A"
   },
   "source": [
    "### plot_all_wsg_results.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "IB-NYnKVNACR",
    "outputId": "75beeac4-688f-4728-fd88-70dc161f2ecf"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1070399792.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wsg_all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m plot_all_wsg_results(\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mpretrained_rule_to_result_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_rule_to_result_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mpretrained_rule_to_result_file_linear_probe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_rule_to_result_file_linear_probe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1070399792.py\u001b[0m in \u001b[0;36mplot_all_wsg_results\u001b[0;34m(pretrained_rule_to_result_file, pretrained_rule_to_result_file_linear_probe, finetuned_rule_to_result_file, rule_to_marker, threshold, save_path)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mStar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCHESS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     model_size_to_n_parameters, rule_to_model_size_to_CE_loss, rule_to_model_size_to_LP_accuracy, rule_to_model_size_pair_to_wsg_score = load_wsg_precomputed_data(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mpretrained_rule_to_result_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mpretrained_rule_to_result_file_linear_probe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1070399792.py\u001b[0m in \u001b[0;36mload_wsg_precomputed_data\u001b[0;34m(pretrained_rule_to_result_file, pretrained_rule_to_result_file_linear_probe, finetuned_rule_to_result_file)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# rule_to_model_size_pair_to_wsg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinetuned_rule_to_result_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mrule_to_model_size_pair_to_wsg_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1070399792.py\u001b[0m in \u001b[0;36mload_pickle\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error loading {file_path}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start, boundary, *values)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_not_given\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \"\"\"\n\u001b[1;32m    722\u001b[0m         \u001b[0mEither\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0mexisting\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_wsg_precomputed_data(\n",
    "    pretrained_rule_to_result_file: dict[OthelloRule, str],\n",
    "    pretrained_rule_to_result_file_linear_probe: dict[OthelloRule, str],\n",
    "    finetuned_rule_to_result_file: dict[tuple[OthelloRule, OthelloRule], str],\n",
    "):\n",
    "    if pretrained_rule_to_result_file_linear_probe:\n",
    "        assert (\n",
    "            pretrained_rule_to_result_file.keys()\n",
    "            == pretrained_rule_to_result_file_linear_probe.keys()\n",
    "        )\n",
    "    model_size_to_n_parameters = {}  # Top left\n",
    "    rule_to_model_size_to_CE_loss = {}  # Top right\n",
    "    rule_to_model_size_to_LP_accuracy = {}  # Bottom left\n",
    "    rule_to_model_size_pair_to_wsg_score = {}  # What to plot\n",
    "\n",
    "    def load_pickle(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # model_size_to_n_parameters, rule_to_model_size_to_CE_loss\n",
    "    for rule, path in pretrained_rule_to_result_file.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_to_CE_loss[rule] = {}\n",
    "            for res in results:\n",
    "                if res[\"othello_rule\"] == rule:\n",
    "                    rule_to_model_size_to_CE_loss[rule][res[\"model_size\"]] = res[\n",
    "                        \"avg_weak_loss\"\n",
    "                    ]\n",
    "                    model_size_to_n_parameters[res[\"model_size\"]] = res[\"n_parameters\"]\n",
    "\n",
    "    # rule_to_model_size_to_LP_accuracy\n",
    "    if pretrained_rule_to_result_file_linear_probe:\n",
    "        for rule, path in pretrained_rule_to_result_file_linear_probe.items():\n",
    "            results = load_pickle(path)\n",
    "            if results:\n",
    "                rule_to_model_size_to_LP_accuracy[rule] = {}\n",
    "                for res in results:\n",
    "                    if res[\"othello_rule\"] == rule:\n",
    "                        rule_to_model_size_to_LP_accuracy[rule][res[\"model_size\"]] = (\n",
    "                            res[\"mean_accuracy\"]\n",
    "                        )\n",
    "\n",
    "    # rule_to_model_size_pair_to_wsg_score\n",
    "    for rule, path in finetuned_rule_to_result_file.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_pair_to_wsg_score[rule] = {}\n",
    "            for (weak_model_size, strong_model_size), res in results[\n",
    "                1\n",
    "            ].items():  # First element of tuple is only model sizes again\n",
    "                rule_to_model_size_pair_to_wsg_score[rule][\n",
    "                    (weak_model_size, strong_model_size)\n",
    "                ] = res[1]\n",
    "\n",
    "    return (\n",
    "        model_size_to_n_parameters,\n",
    "        rule_to_model_size_to_CE_loss,\n",
    "        rule_to_model_size_to_LP_accuracy,\n",
    "        rule_to_model_size_pair_to_wsg_score,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_all_wsg_results(\n",
    "    pretrained_rule_to_result_file: dict[OthelloRule, str],\n",
    "    pretrained_rule_to_result_file_linear_probe: dict[OthelloRule, str],\n",
    "    finetuned_rule_to_result_file: dict[tuple[OthelloRule, OthelloRule], str],\n",
    "    rule_to_marker: dict[OthelloRule, str],\n",
    "    threshold: float,\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots all WSG results.\n",
    "    Top Left:\n",
    "        x-axis: n_parameters strong model\n",
    "        y-axis: n_parameters weak model\n",
    "    Top Right:\n",
    "        x-axis: strong model CE-loss (on standard rule)\n",
    "        y-axis: weak model CE-loss (on standard rule)\n",
    "    Bottom Left:\n",
    "        x-axis: linear probe accuracy strong model (on standard rule)\n",
    "        y-axis: linear probe accuracy weak model (on standard rule)\n",
    "\n",
    "    Each dot is one pair of (weak_model, strong_model).\n",
    "        color: wsg score (green > 0 and red < 0)\n",
    "        symbol: strong-model rule\n",
    "            - Circle: BIAS_CLOCK\n",
    "            - Square: NEXT_TO_OPPONENT\n",
    "            - Star: CHESS\n",
    "    \"\"\"\n",
    "    (\n",
    "        model_size_to_n_parameters,\n",
    "        rule_to_model_size_to_CE_loss,\n",
    "        rule_to_model_size_to_LP_accuracy,\n",
    "        rule_to_model_size_pair_to_wsg_score,\n",
    "    ) = load_wsg_precomputed_data(\n",
    "        pretrained_rule_to_result_file,\n",
    "        pretrained_rule_to_result_file_linear_probe,\n",
    "        finetuned_rule_to_result_file,\n",
    "    )\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Plot data\n",
    "    print(rule_to_model_size_pair_to_wsg_score)\n",
    "    # Plot data\n",
    "    counter_positive_wsg = 0\n",
    "    counter_negative_wsg = 0\n",
    "    for strong_rule, wsg_pairs in rule_to_model_size_pair_to_wsg_score.items():\n",
    "        weak_rule = OthelloRule.STANDARD  # Assuming weak is always STANDARD\n",
    "        marker = rule_to_marker.get(strong_rule, \"o\")\n",
    "\n",
    "        for (weak_size, strong_size), wsg_score in wsg_pairs.items():\n",
    "            alpha, color = wsg_score_to_alpha_color(wsg_score)\n",
    "            if wsg_score > 0:\n",
    "                counter_positive_wsg += 1\n",
    "            else:\n",
    "                counter_negative_wsg += 1\n",
    "\n",
    "            # Top Left: n_parameters\n",
    "            if (\n",
    "                weak_size in model_size_to_n_parameters\n",
    "                and strong_size in model_size_to_n_parameters\n",
    "            ):\n",
    "                ax1.scatter(\n",
    "                    model_size_to_n_parameters[strong_size],\n",
    "                    model_size_to_n_parameters[weak_size],\n",
    "                    c=color,\n",
    "                    marker=marker,\n",
    "                    s=100,\n",
    "                    alpha=alpha,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "\n",
    "            # Top Right: CE loss\n",
    "            if (\n",
    "                weak_rule in rule_to_model_size_to_CE_loss\n",
    "                and strong_rule in rule_to_model_size_to_CE_loss\n",
    "                and weak_size in rule_to_model_size_to_CE_loss[weak_rule]\n",
    "                and strong_size in rule_to_model_size_to_CE_loss[strong_rule]\n",
    "            ):\n",
    "                ax2.scatter(\n",
    "                    rule_to_model_size_to_CE_loss[strong_rule][strong_size],\n",
    "                    rule_to_model_size_to_CE_loss[weak_rule][weak_size],\n",
    "                    c=color,\n",
    "                    marker=marker,\n",
    "                    s=100,\n",
    "                    alpha=alpha,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                weak_rule in rule_to_model_size_to_LP_accuracy\n",
    "                and strong_rule in rule_to_model_size_to_LP_accuracy\n",
    "                and weak_size in rule_to_model_size_to_LP_accuracy[weak_rule]\n",
    "                and strong_size in rule_to_model_size_to_LP_accuracy[strong_rule]\n",
    "            ):\n",
    "                ax3.scatter(\n",
    "                    rule_to_model_size_to_LP_accuracy[strong_rule][strong_size],\n",
    "                    rule_to_model_size_to_LP_accuracy[weak_rule][weak_size],\n",
    "                    c=color,\n",
    "                    marker=marker,\n",
    "                    s=100,\n",
    "                    alpha=alpha,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Missing data for {weak_rule}{strong_rule}, {weak_size}{strong_size}\"\n",
    "                )\n",
    "\n",
    "    print(\n",
    "        \"Positive WSG score: \",\n",
    "        counter_positive_wsg,\n",
    "        \" Negative WSG Score: \",\n",
    "        counter_negative_wsg,\n",
    "    )\n",
    "    # Set scales FIRST (before drawing lines)\n",
    "    ax1.set_xscale(\"log\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "\n",
    "    # Add diagonal reference lines (x=y) that extend beyond boundaries\n",
    "    # For ax1 (parameters plot)\n",
    "    ax1_xlim = ax1.get_xlim()\n",
    "    ax1_ylim = ax1.get_ylim()\n",
    "    # Extend beyond the limits\n",
    "    extend_factor = 10  # For log scale\n",
    "    ax1.plot(\n",
    "        [ax1_xlim[0] / extend_factor, ax1_xlim[1] * extend_factor],\n",
    "        [ax1_xlim[0] / extend_factor, ax1_xlim[1] * extend_factor],\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    ax1.set_xlim(ax1_xlim)  # Restore original limits\n",
    "    ax1.set_ylim(ax1_ylim)\n",
    "\n",
    "    # For ax2 (CE loss plot)\n",
    "    ax2_xlim = ax2.get_xlim()\n",
    "    ax2_ylim = ax2.get_ylim()\n",
    "    # Extend beyond the limits\n",
    "    extend_range = max(ax2_xlim[1] - ax2_xlim[0], ax2_ylim[1] - ax2_ylim[0])\n",
    "    ax2.plot(\n",
    "        [ax2_xlim[0] - extend_range, ax2_xlim[1] + extend_range],\n",
    "        [ax2_xlim[0] - extend_range, ax2_xlim[1] + extend_range],\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    ax2.set_xlim(ax2_xlim)  # Restore original limits\n",
    "    ax2.set_ylim(ax2_ylim)\n",
    "\n",
    "    # For ax3 (linear probe accuracy plot)\n",
    "    ax3_xlim = ax3.get_xlim()\n",
    "    ax3_ylim = ax3.get_ylim()\n",
    "    # Extend beyond the limits\n",
    "    extend_range = max(ax3_xlim[1] - ax3_xlim[0], ax3_ylim[1] - ax3_ylim[0])\n",
    "    ax3.plot(\n",
    "        [ax3_xlim[0] - extend_range, ax3_xlim[1] + extend_range],\n",
    "        [ax3_xlim[0] - extend_range, ax3_xlim[1] + extend_range],\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    ax3.set_xlim(ax3_xlim)  # Restore original limits\n",
    "    ax3.set_ylim(ax3_ylim)\n",
    "\n",
    "    # Set labels and titles\n",
    "    ax1.set_xlabel(\"Strong Model Parameters\")\n",
    "    ax1.set_ylabel(\"Weak Model Parameters\")\n",
    "    ax1.set_title(\"WSG by Model Parameters\")\n",
    "    ax1.set_xscale(\"log\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "\n",
    "    ax2.set_xlabel(\"Strong Model CE Loss\")\n",
    "    ax2.set_ylabel(\"Weak Model CE Loss\")\n",
    "    ax2.set_title(\"WSG by CE Loss\")\n",
    "\n",
    "    ax3.set_xlabel(\"Strong Model Linear Probe Accuracy\")\n",
    "    ax3.set_ylabel(\"Weak Model Linear Probe Accuracy\")\n",
    "    ax3.set_title(\"WSG by Linear Probe Accuracy\")\n",
    "\n",
    "    # Create legend\n",
    "    legend_elements = []\n",
    "    for rule, marker in rule_to_marker.items():\n",
    "        legend_elements.append(\n",
    "            plt.Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=marker,\n",
    "                color=\"black\",\n",
    "                linestyle=\"None\",\n",
    "                markersize=10,\n",
    "                label=rule.name,\n",
    "            )\n",
    "        )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"green\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"WSG > {threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"WSG < -{threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"black\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"-{threshold} < WSG < {threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D([0], [0], color=\"black\", linestyle=\"--\", linewidth=1, label=\"y = x\")\n",
    "    )\n",
    "\n",
    "    ax4.legend(handles=legend_elements, loc=\"center\")\n",
    "    ax4.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# save_path = os.path.join(experiment_folder, 'wsg_all')\n",
    "# plot_all_wsg_results(\n",
    "#     pretrained_rule_to_result_file=pretrained_rule_to_result_file,\n",
    "#     pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_linear_probe,\n",
    "#     # pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_fake_linear_probe,\n",
    "#     # pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_black_white_linear_probe,\n",
    "#     # pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_modulo_linear_probe,\n",
    "#     finetuned_rule_to_result_file=finetuned_rule_to_result_file,\n",
    "#     threshold=THRESHOLD,\n",
    "#     rule_to_marker=RULE_TO_MARKER,\n",
    "#     save_path=save_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3xtYLFeYiAx"
   },
   "outputs": [],
   "source": [
    "def plot_wsg_vs_accuracy_difference(\n",
    "    pretrained_rule_to_result_file: dict[OthelloRule, str],\n",
    "    pretrained_rule_to_result_file_linear_probe: dict[OthelloRule, str],\n",
    "    finetuned_rule_to_result_file: dict[tuple[OthelloRule, OthelloRule], str],\n",
    "    title: str,\n",
    "    plot_x: str,\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots WSG score vs the difference in linear probe accuracy (strong - weak).\n",
    "    Calculates the accuracy of predicting the sign of the WSG score.\n",
    "    Uses the same y-axis scaling as plot_wsg_vs_metric.\n",
    "    \"\"\"\n",
    "    rule_to_marker = {\n",
    "        OthelloRule.CONSTANT_PARAMETERS: \"s\",\n",
    "        OthelloRule.UNTRAINED: \"D\",\n",
    "        OthelloRule.CHESS: \"*\",\n",
    "        OthelloRule.NO_FLIPPING: \"o\",\n",
    "        OthelloRule.NEXT_TO_OPPONENT: \"P\",\n",
    "        OthelloRule.BIAS_CLOCK: \"^\",\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Use the same data loading function\n",
    "    (\n",
    "        model_size_to_n_parameters,\n",
    "        rule_to_model_size_to_CE_loss,\n",
    "        rule_to_model_size_to_LP_accuracy,\n",
    "        rule_to_model_size_pair_to_wsg_score,\n",
    "    ) = load_wsg_precomputed_data(\n",
    "        pretrained_rule_to_result_file,\n",
    "        pretrained_rule_to_result_file_linear_probe,\n",
    "        finetuned_rule_to_result_file,\n",
    "    )\n",
    "\n",
    "    # Collect data points for plotting and correlation analysis\n",
    "    all_x_values = []  # accuracy differences\n",
    "    all_y_values = []  # WSG scores\n",
    "    correct_sign_predictions = 0\n",
    "    threshold = 0.02\n",
    "\n",
    "    # Plot data - handle both single rules and tuple keys\n",
    "    for rule_key, wsg_pairs in rule_to_model_size_pair_to_wsg_score.items():\n",
    "        # Check if it's a tuple or single rule\n",
    "        if isinstance(rule_key, tuple):\n",
    "            weak_rule, strong_rule = rule_key\n",
    "        else:\n",
    "            strong_rule = rule_key\n",
    "            weak_rule = OthelloRule.STANDARD\n",
    "\n",
    "        marker = rule_to_marker.get(strong_rule, \"o\")\n",
    "\n",
    "        for (weak_size, strong_size), wsg_score in wsg_pairs.items():\n",
    "            # Calculate accuracy difference\n",
    "            x_value = None\n",
    "            data_available = False\n",
    "            if plot_x.startswith(\"accuracy_difference\") or plot_x == \"modulo\":\n",
    "                if (\n",
    "                    weak_rule in rule_to_model_size_to_LP_accuracy\n",
    "                    and strong_rule in rule_to_model_size_to_LP_accuracy\n",
    "                    and weak_size in rule_to_model_size_to_LP_accuracy[weak_rule]\n",
    "                    and strong_size in rule_to_model_size_to_LP_accuracy[strong_rule]\n",
    "                ):\n",
    "                    weak_acc = rule_to_model_size_to_LP_accuracy[weak_rule][weak_size]\n",
    "                    strong_acc = rule_to_model_size_to_LP_accuracy[strong_rule][\n",
    "                        strong_size\n",
    "                    ]\n",
    "                    x_value = strong_acc - weak_acc\n",
    "                    data_available = True\n",
    "\n",
    "            elif plot_x == \"ce_loss\":\n",
    "                if (\n",
    "                    weak_rule in rule_to_model_size_to_CE_loss\n",
    "                    and strong_rule in rule_to_model_size_to_CE_loss\n",
    "                    and weak_size in rule_to_model_size_to_CE_loss[weak_rule]\n",
    "                    and strong_size in rule_to_model_size_to_CE_loss[strong_rule]\n",
    "                ):\n",
    "                    weak_loss = rule_to_model_size_to_CE_loss[weak_rule][weak_size]\n",
    "                    strong_loss = rule_to_model_size_to_CE_loss[strong_rule][\n",
    "                        strong_size\n",
    "                    ]\n",
    "                    # x > 0 means strong model is better (has lower loss)\n",
    "                    x_value = weak_loss - strong_loss\n",
    "                    data_available = True\n",
    "\n",
    "            elif plot_x == \"n_parameters\":\n",
    "                if (\n",
    "                    weak_size in model_size_to_n_parameters\n",
    "                    and strong_size in model_size_to_n_parameters\n",
    "                ):\n",
    "                    weak_params = model_size_to_n_parameters[weak_size]\n",
    "                    strong_params = model_size_to_n_parameters[strong_size]\n",
    "                    # As requested: Ratio of parameters\n",
    "                    x_value = np.log(strong_params) - np.log(weak_params)\n",
    "                    data_available = True\n",
    "\n",
    "            if data_available and x_value is not None:\n",
    "                all_x_values.append(x_value)\n",
    "                all_y_values.append(wsg_score)\n",
    "\n",
    "                # Check if the sign prediction is correct\n",
    "                is_positive = (\n",
    "                    (x_value > 0) if plot_x == \"n_parameters\" else (x_value > 0)\n",
    "                )\n",
    "                if (is_positive and wsg_score > 0) or (\n",
    "                    not is_positive and wsg_score <= 0\n",
    "                ):\n",
    "                    correct_sign_predictions += 1\n",
    "\n",
    "                # Determine color based on WSG score\n",
    "                alpha = min(0.9, 0.5 + abs(wsg_score))\n",
    "                if wsg_score > threshold:\n",
    "                    color = \"green\"\n",
    "                elif wsg_score < -threshold:\n",
    "                    color = \"red\"\n",
    "                else:\n",
    "                    color = \"black\"\n",
    "                    alpha = 0.7\n",
    "\n",
    "                # Use the generic x_value variable which holds the result for any metric\n",
    "                ax.scatter(\n",
    "                    x_value,\n",
    "                    wsg_score,\n",
    "                    c=color,\n",
    "                    marker=marker,\n",
    "                    s=100,\n",
    "                    alpha=alpha,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "            else:\n",
    "                # Debug: print what's missing\n",
    "                if weak_rule not in rule_to_model_size_to_LP_accuracy:\n",
    "                    print(f\"Missing weak rule {weak_rule} in LP data\")\n",
    "                elif strong_rule not in rule_to_model_size_to_LP_accuracy:\n",
    "                    print(f\"Missing strong rule {strong_rule} in LP data\")\n",
    "                elif weak_size not in rule_to_model_size_to_LP_accuracy.get(\n",
    "                    weak_rule, {}\n",
    "                ):\n",
    "                    print(f\"Missing weak size {weak_size} for rule {weak_rule}\")\n",
    "                elif strong_size not in rule_to_model_size_to_LP_accuracy.get(\n",
    "                    strong_rule, {}\n",
    "                ):\n",
    "                    print(f\"Missing strong size {strong_size} for rule {strong_rule}\")\n",
    "\n",
    "    # Check if we have enough data points\n",
    "    if len(all_x_values) < 2:\n",
    "        print(\n",
    "            f\"\\nWarning: Not enough data points ({len(all_x_values)}) to calculate correlations.\"\n",
    "        )\n",
    "        print(\n",
    "            \"Please check that the data files contain matching model sizes and rules.\"\n",
    "        )\n",
    "        plt.close()\n",
    "        return\n",
    "\n",
    "    # Convert to numpy arrays for correlation analysis\n",
    "    x_arr = np.array(all_x_values)\n",
    "    y_arr = np.array(all_y_values)\n",
    "\n",
    "    # Set up y-axis with symlog scale\n",
    "    y_min, y_max = min(all_y_values), max(all_y_values)\n",
    "    y_margin = (y_max - y_min) * 0.1\n",
    "    y_range = (y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "    ax.set_yscale(\"symlog\", linthresh=1.0, linscale=2.0)\n",
    "    # --- DYNAMIC X-AXIS LABEL ---\n",
    "    x_axis_labels = {\n",
    "        \"accuracy_difference\": \"Linear Probe Accuracy Difference (Strong - Weak) [empty/mine/yours]\",\n",
    "        \"accuracy_difference_fake\": \"LP Accuracy Difference (Strong - Weak) [empty/filled]\",\n",
    "        \"accuracy_difference_black_white\": \"LP Accuracy Difference (Strong - Weak) [empty/black/white]\",\n",
    "        \"modulo\": \"LP Accuracy Difference (Strong - Weak) [linear*board%3]]\",\n",
    "        \"ce_loss\": \"CE Loss Difference (Weak - Strong)\",\n",
    "        \"n_parameters\": \"Parameter Count Log-Ratio (Log(Strong/Weak))\",\n",
    "    }\n",
    "    ax.set_xlabel(x_axis_labels.get(plot_x, \"Metric Difference\"))\n",
    "    ax.set_ylabel(\"PGR\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(y_range)\n",
    "\n",
    "    # Add horizontal line at y=0\n",
    "    ax.axhline(y=0, color=\"red\", linewidth=0.8, alpha=0.8)\n",
    "\n",
    "    # Add vertical line at x=0\n",
    "    ax.axvline(x=0, color=\"gray\", linewidth=0.5, alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "    # Add shading for logarithmic regions\n",
    "    ax.axhspan(1, y_range[1], alpha=0.15, color=\"gray\", zorder=0)\n",
    "    ax.axhspan(y_range[0], -1, alpha=0.15, color=\"gray\", zorder=0)\n",
    "\n",
    "    # Custom y-ticks\n",
    "    linear_ticks = [-0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8]\n",
    "    log_ticks_pos = [2, 5, 10, 20, 50, 100] if y_range[1] > 1 else []\n",
    "    log_ticks_neg = [-2, -5, -10, -20, -50, -100] if y_range[0] < -1 else []\n",
    "\n",
    "    all_ticks = (\n",
    "        [t for t in log_ticks_neg if t >= y_range[0]]\n",
    "        + [-1]\n",
    "        + linear_ticks\n",
    "        + [1]\n",
    "        + [t for t in log_ticks_pos if t <= y_range[1]]\n",
    "    )\n",
    "\n",
    "    tick_labels = []\n",
    "    for tick in all_ticks:\n",
    "        if tick == 1:\n",
    "            tick_labels.append(\"1\")\n",
    "        elif tick == -1:\n",
    "            tick_labels.append(\"-1\")\n",
    "        elif -1 < tick < 1:\n",
    "            tick_labels.append(f\"{tick:.1f}\")\n",
    "        else:\n",
    "            tick_labels.append(f\"{tick}\")\n",
    "\n",
    "    ax.set_yticks(all_ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Create legend\n",
    "    legend_elements = []\n",
    "\n",
    "    # Add rule markers - extract unique strong rules\n",
    "    unique_strong_rules = set()\n",
    "    for rule_key in rule_to_model_size_pair_to_wsg_score.keys():\n",
    "        if isinstance(rule_key, tuple):\n",
    "            _, strong_rule = rule_key\n",
    "        else:\n",
    "            strong_rule = rule_key\n",
    "        unique_strong_rules.add(strong_rule)\n",
    "\n",
    "    for rule, marker in rule_to_marker.items():\n",
    "        if rule in unique_strong_rules:\n",
    "            legend_elements.append(\n",
    "                plt.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=marker,\n",
    "                    color=\"black\",\n",
    "                    linestyle=\"None\",\n",
    "                    markersize=10,\n",
    "                    label=rule.name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Add color coding\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"green\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"WSG > {threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"WSG < -{threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"black\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"-{threshold} < WSG < {threshold}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ax.legend(handles=legend_elements)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.1)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_x = \"accuracy_difference\"\n",
    "if plot_x == \"accuracy_difference\":\n",
    "    title_suffix = \"difference of LP accuracy in basis (empty/mine/yours)\"\n",
    "    save_path = os.path.join(experiment_folder, \"wsg_vs_accuracy_difference\")\n",
    "    pretrained_rule_to_result_file_linear_probe = (\n",
    "        pretrained_rule_to_result_file_linear_probe\n",
    "    )\n",
    "elif plot_x == \"accuracy_difference_fake\":\n",
    "    title_suffix = \"difference of LP accuracy in basis (empty/filled)\"\n",
    "    save_path = os.path.join(experiment_folder, \"wsg_vs_accuracy_difference_fake\")\n",
    "    pretrained_rule_to_result_file_linear_probe = (\n",
    "        pretrained_rule_to_result_file_fake_linear_probe\n",
    "    )\n",
    "elif plot_x == \"accuracy_difference_black_white\":\n",
    "    title_suffix = \"difference of LP accuracy in basis (empty/black/white)\"\n",
    "    save_path = os.path.join(\n",
    "        experiment_folder, \"wsg_vs_accuracy_difference_black_white\"\n",
    "    )\n",
    "    pretrained_rule_to_result_file_linear_probe = (\n",
    "        pretrained_rule_to_result_file_black_white_linear_probe\n",
    "    )\n",
    "elif plot_x == \"modulo\":\n",
    "    title_suffix = (\n",
    "        \"difference of LP accuracy on highly non-linear board (linear*board%3)\"\n",
    "    )\n",
    "    save_path = os.path.join(experiment_folder, \"wsg_vs_accuracy_difference_modulo\")\n",
    "    pretrained_rule_to_result_file_linear_probe = (\n",
    "        pretrained_rule_to_result_file_modulo_linear_probe\n",
    "    )\n",
    "elif plot_x == \"ce_loss\":\n",
    "    title_suffix = \"difference CE-loss difference\"\n",
    "    save_path = os.path.join(experiment_folder, \"wsg_vs_ce_loss_difference.png\")\n",
    "    # Linear probe data is not needed for this plot\n",
    "    pretrained_rule_to_result_file_linear_probe = None\n",
    "elif plot_x == \"n_parameters\":\n",
    "    title_suffix = \"ratio of parameter counts\"\n",
    "    save_path = os.path.join(experiment_folder, \"wsg_vs_n_parameters_ratio.png\")\n",
    "    # Linear probe data is not needed for this plot\n",
    "    pretrained_rule_to_result_file_linear_probe = None\n",
    "else:\n",
    "    raise Exception(\"Unknown plot_x\")\n",
    "\n",
    "plot_wsg_vs_accuracy_difference(\n",
    "    pretrained_rule_to_result_file=pretrained_rule_to_result_file,\n",
    "    pretrained_rule_to_result_file_linear_probe=pretrained_rule_to_result_file_linear_probe,\n",
    "    finetuned_rule_to_result_file=finetuned_rule_to_result_file,\n",
    "    plot_x=plot_x,\n",
    "    title=\"PGR vs. \" + title_suffix,\n",
    "    save_path=save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csZz91Ca4l9e"
   },
   "outputs": [],
   "source": [
    "def compute_table(\n",
    "    pretrained_rule_to_result_file: Dict[Any, str],\n",
    "    pretrained_rule_to_result_file_linear_probe: Dict[Any, str],\n",
    "    transform_to_pretrained_rule_to_result_file_linear_probe: Dict[str, Dict[Any, str]],\n",
    "    finetuned_rule_to_result_file: Dict[Any, str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads model performance data, computes differences between weak and strong models,\n",
    "    and prints a table of correlation metrics against the weak-to-strong generalization (WSG) score.\n",
    "    \"\"\"\n",
    "    # --- Sections 1 & 2 remain unchanged ---\n",
    "\n",
    "    # --- 1. Data Loading ---\n",
    "    model_size_to_n_parameters = {}\n",
    "    rule_to_model_size_to_CE_loss = {}\n",
    "    rule_to_model_size_to_LP_accuracy = {}\n",
    "    transform_to_rule_to_model_size_to_LP_accuracy = {}\n",
    "    rule_to_model_size_pair_to_wsg_score = {}\n",
    "\n",
    "    def load_pickle(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    for rule, path in pretrained_rule_to_result_file.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_to_CE_loss[rule] = {\n",
    "                res[\"model_size\"]: res[\"avg_weak_loss\"]\n",
    "                for res in results\n",
    "                if res.get(\"othello_rule\") == rule\n",
    "            }\n",
    "            for res in results:\n",
    "                if res.get(\"othello_rule\") == rule:\n",
    "                    model_size_to_n_parameters[res[\"model_size\"]] = res[\"n_parameters\"]\n",
    "\n",
    "    for rule, path in pretrained_rule_to_result_file_linear_probe.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_to_LP_accuracy[rule] = {\n",
    "                res[\"model_size\"]: res[\"mean_accuracy\"]\n",
    "                for res in results\n",
    "                if res.get(\"othello_rule\") == rule\n",
    "            }\n",
    "\n",
    "    for (\n",
    "        transform_name,\n",
    "        rule_to_path,\n",
    "    ) in transform_to_pretrained_rule_to_result_file_linear_probe.items():\n",
    "        transform_to_rule_to_model_size_to_LP_accuracy[transform_name] = {}\n",
    "        for rule, path in rule_to_path.items():\n",
    "            results = load_pickle(path)\n",
    "            if results:\n",
    "                transform_to_rule_to_model_size_to_LP_accuracy[transform_name][rule] = {\n",
    "                    res[\"model_size\"]: res[\"mean_accuracy\"]\n",
    "                    for res in results\n",
    "                    if res.get(\"othello_rule\") == rule\n",
    "                }\n",
    "\n",
    "    for rule, path in finetuned_rule_to_result_file.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_pair_to_wsg_score[rule] = results[1]\n",
    "\n",
    "    # --- 2. Data Aggregation and Calculation ---\n",
    "    all_data_points = []\n",
    "    for rule_key, wsg_pairs in rule_to_model_size_pair_to_wsg_score.items():\n",
    "        weak_rule, strong_rule = (\n",
    "            rule_key\n",
    "            if isinstance(rule_key, tuple)\n",
    "            else (OthelloRule.STANDARD, rule_key)\n",
    "        )\n",
    "\n",
    "        for (weak_size, strong_size), wsg_result_tuple in wsg_pairs.items():\n",
    "            wsg_score = wsg_result_tuple[1]\n",
    "            point = {\"wsg_score\": wsg_score}\n",
    "            try:\n",
    "                point[\"N_Params(S) - N_Params(W)\"] = (\n",
    "                    model_size_to_n_parameters[strong_size]\n",
    "                    - model_size_to_n_parameters[weak_size]\n",
    "                )\n",
    "                point[\"CE Loss(W) - CE Loss(S)\"] = (\n",
    "                    rule_to_model_size_to_CE_loss[weak_rule][weak_size]\n",
    "                    - rule_to_model_size_to_CE_loss[strong_rule][strong_size]\n",
    "                )\n",
    "                if rule_to_model_size_to_LP_accuracy:\n",
    "                    point[\"Empty/Mine/Yours: LP-Acc(S) - LP-Acc(W)\"] = (\n",
    "                        rule_to_model_size_to_LP_accuracy[strong_rule][strong_size]\n",
    "                        - rule_to_model_size_to_LP_accuracy[weak_rule][weak_size]\n",
    "                    )\n",
    "                for (\n",
    "                    name,\n",
    "                    data,\n",
    "                ) in transform_to_rule_to_model_size_to_LP_accuracy.items():\n",
    "                    key = f\"{name}: LP Acc(S) - LP Acc(W)\"\n",
    "                    point[key] = (\n",
    "                        data[strong_rule][strong_size] - data[weak_rule][weak_size]\n",
    "                    )\n",
    "                all_data_points.append(point)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    if not all_data_points:\n",
    "        print(\n",
    "            \"No complete data points found to generate table. Check input files and keys.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    y_wsg_scores = [p[\"wsg_score\"] for p in all_data_points]\n",
    "    x_variables_data = {\n",
    "        key: [p[key] for p in all_data_points]\n",
    "        for key in all_data_points[0]\n",
    "        if key != \"wsg_score\"\n",
    "    }\n",
    "\n",
    "    def calculate_metrics(x_list: list, y_list: list) -> Tuple[float, float, float]:\n",
    "        if len(x_list) < 2:\n",
    "            return (float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "        x_arr, y_arr = np.array(x_list), np.array(y_list)\n",
    "        pearson_r, _ = stats.pearsonr(x_arr, y_arr)\n",
    "        r_squared = pearson_r**2 if not np.isnan(pearson_r) else float(\"nan\")\n",
    "        spearman_rho, p_value = stats.spearmanr(x_arr, y_arr)\n",
    "        correct_signs = np.sum(np.sign(x_arr) == np.sign(y_arr))\n",
    "        sign_accuracy = correct_signs / len(x_arr) if len(x_arr) > 0 else 0\n",
    "        return r_squared, spearman_rho, p_value, sign_accuracy\n",
    "\n",
    "    # --- 3. Print Table ---\n",
    "    # This section is modified to reorder columns and highlight max values.\n",
    "\n",
    "    results = []\n",
    "    for name, x_values in x_variables_data.items():\n",
    "        metrics = calculate_metrics(x_values, y_wsg_scores)\n",
    "        results.append((name, *metrics))\n",
    "\n",
    "    # Sort results by the original Sign Accuracy (index 3) to maintain the requested order\n",
    "    sorted_results = sorted(results, key=lambda item: item[4], reverse=True)\n",
    "\n",
    "    # Find the maximum value in each metric column for bolding\n",
    "    if sorted_results:\n",
    "        # The tuple is (name, r_squared, spearman_rho, sign_accuracy)\n",
    "        max_r2 = max(item[1] for item in sorted_results)\n",
    "        max_rho = max(item[2] for item in sorted_results)\n",
    "        max_acc = max(item[4] for item in sorted_results)\n",
    "    else:\n",
    "        # Set to a very low number if no results exist\n",
    "        max_r2, max_rho, max_acc = float(\"-inf\"), float(\"-inf\"), float(\"-inf\")\n",
    "\n",
    "    # Define column widths for consistent padding\n",
    "    max_name_len = (\n",
    "        max(len(name) for name, _, _, _, _ in sorted_results) if sorted_results else 35\n",
    "    )\n",
    "    acc_width = 15\n",
    "    rho_width = 12\n",
    "    pval_width = 12\n",
    "    r2_width = 10\n",
    "    total_width = max_name_len + acc_width + rho_width + pval_width + r2_width + 10\n",
    "\n",
    "    print(\n",
    "        f\"\\n Correlation Metrics vs. WSG Score (N={len(y_wsg_scores)}) -- Sorted by Sign Accuracy\"\n",
    "    )\n",
    "    print(\"-\" * total_width)\n",
    "    # Print the reordered header\n",
    "    print(\n",
    "        f\"{'X-Variable':<{max_name_len}} | \"\n",
    "        f\"{'Sign Accuracy':<{acc_width}} | \"\n",
    "        f\"{'Spearman ':<{rho_width}} | \"\n",
    "        f\"{'p-value':<{pval_width}} | \"\n",
    "        f\"{'R':<{r2_width}}\"\n",
    "    )\n",
    "    print(\"-\" * total_width)\n",
    "\n",
    "    # Loop over the sorted results and print each row with new formatting\n",
    "    for name, r2, rho, p_val, acc in sorted_results:\n",
    "        # Format each value, adding '**' for bolding if it is the maximum\n",
    "        acc_str = f\"**{acc:.3f}**\" if acc == max_acc else f\"{acc:.3f}\"\n",
    "        rho_str = f\"**{rho:.3f}**\" if rho == max_rho else f\"{rho:.3f}\"\n",
    "        r2_str = f\"**{r2:.3f}**\" if r2 == max_r2 else f\"{r2:.3f}\"\n",
    "        pval_str = f\"{p_val:.2e}\"\n",
    "\n",
    "        # Print the reordered, formatted row with left-justified columns\n",
    "        print(\n",
    "            f\"{name:<{max_name_len}} | \"\n",
    "            f\"{acc_str:<{acc_width}} | \"\n",
    "            f\"{rho_str:<{rho_width}} | \"\n",
    "            f\"{pval_str:<{pval_width}} | \"\n",
    "            f\"{r2_str:<{r2_width}}\"\n",
    "        )\n",
    "    print(\"-\" * total_width)\n",
    "\n",
    "\n",
    "transform_to_pretrained_rule_to_result_file_linear_probe = {\n",
    "    \"Empty/Filled\": pretrained_rule_to_result_file_fake_linear_probe,\n",
    "    \"Empty/Black/White\": pretrained_rule_to_result_file_black_white_linear_probe,\n",
    "    \"Linear*board % 3\": pretrained_rule_to_result_file_modulo_linear_probe,\n",
    "}\n",
    "compute_table(\n",
    "    pretrained_rule_to_result_file,\n",
    "    pretrained_rule_to_result_file_linear_probe,\n",
    "    transform_to_pretrained_rule_to_result_file_linear_probe,\n",
    "    finetuned_rule_to_result_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0nMvQJLJzf8"
   },
   "source": [
    "### plot_wsg_vs_metric.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMhY044C5hns"
   },
   "outputs": [],
   "source": [
    "def plot_wsg_vs_metric(\n",
    "    othello_rule_to_metric: dict,\n",
    "    finetuned_rule_to_result_file: dict,\n",
    "    x_axis_name: str,\n",
    "    title: str,\n",
    "    save_path: str | None = None,\n",
    "    x_axis_log: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots WSG score vs metric for different Othello rules.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    rule_to_marker = {\n",
    "        OthelloRule.CONSTANT_PARAMETERS: \"s\",\n",
    "        OthelloRule.UNTRAINED: \"D\",\n",
    "        OthelloRule.CHESS: \"*\",\n",
    "        OthelloRule.NO_FLIPPING: \"o\",\n",
    "        OthelloRule.NEXT_TO_OPPONENT: \"P\",\n",
    "        OthelloRule.BIAS_CLOCK: \"^\",\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Load WSG data\n",
    "    def load_pickle(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    rule_to_model_size_pair_to_wsg_score = {}\n",
    "    for rule, path in finetuned_rule_to_result_file.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            rule_to_model_size_pair_to_wsg_score[rule] = {}\n",
    "            for (weak_model_size, strong_model_size), res in results[1].items():\n",
    "                rule_to_model_size_pair_to_wsg_score[rule][\n",
    "                    (weak_model_size, strong_model_size)\n",
    "                ] = res[1]\n",
    "\n",
    "    # Collect all y-values to determine shared y-axis range\n",
    "    all_y_values = []\n",
    "    for rule_data in rule_to_model_size_pair_to_wsg_score.values():\n",
    "        all_y_values.extend(rule_data.values())\n",
    "\n",
    "    y_min, y_max = min(all_y_values), max(all_y_values)\n",
    "    y_margin = (y_max - y_min) * 0.1\n",
    "    y_range = (y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "    # Plot data for each rule\n",
    "    threshold = 0.02\n",
    "    for rule, ms_to_ms_to_metric in othello_rule_to_metric.items():\n",
    "        if rule not in rule_to_model_size_pair_to_wsg_score:\n",
    "            continue\n",
    "\n",
    "        marker = rule_to_marker.get(rule, \"o\")\n",
    "\n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        for (weak_size, strong_size), wsg_data in rule_to_model_size_pair_to_wsg_score[\n",
    "            rule\n",
    "        ].items():\n",
    "            if (\n",
    "                strong_size in ms_to_ms_to_metric\n",
    "                and weak_size in ms_to_ms_to_metric[strong_size]\n",
    "            ):\n",
    "                metric_value = ms_to_ms_to_metric[strong_size][weak_size]\n",
    "                # Add small offset for zero values to handle log scale\n",
    "                if metric_value == 0:\n",
    "                    metric_value = 0.1\n",
    "                x_values.append(metric_value)\n",
    "                y_values.append(wsg_data)\n",
    "\n",
    "                alpha = min(0.9, 0.5 + abs(wsg_data))\n",
    "                if wsg_data > threshold:\n",
    "                    color = \"green\"\n",
    "                elif wsg_data < -threshold:\n",
    "                    color = \"red\"\n",
    "                else:\n",
    "                    color = \"black\"\n",
    "                    alpha = 0.7\n",
    "\n",
    "                ax.scatter(\n",
    "                    metric_value,\n",
    "                    wsg_data,\n",
    "                    marker=marker,\n",
    "                    s=100,\n",
    "                    c=color,\n",
    "                    alpha=alpha,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "\n",
    "        # Add legend entry (single point to avoid duplicates)\n",
    "        ax.scatter(\n",
    "            [],\n",
    "            [],\n",
    "            marker=marker,\n",
    "            s=100,\n",
    "            c=\"black\",\n",
    "            alpha=0.7,\n",
    "            edgecolors=\"black\",\n",
    "            linewidth=0.5,\n",
    "            label=rule.name,\n",
    "        )\n",
    "\n",
    "    # Apply same formatting as plot_finetune_sweep\n",
    "    if x_axis_log:\n",
    "        ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"symlog\", linthresh=1.0, linscale=2.0)\n",
    "    ax.set_xlabel(x_axis_name)\n",
    "    ax.set_ylabel(\"PGR\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(y_range)\n",
    "\n",
    "    # Add horizontal line at y=0\n",
    "    ax.axhline(y=0, color=\"red\", linewidth=0.8, alpha=0.8)\n",
    "\n",
    "    # Add shading for logarithmic regions\n",
    "    ax.axhspan(1, y_range[1], alpha=0.15, color=\"gray\", zorder=0)\n",
    "    ax.axhspan(y_range[0], -1, alpha=0.15, color=\"gray\", zorder=0)\n",
    "\n",
    "    # Custom y-ticks\n",
    "    linear_ticks = [-0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8]\n",
    "    log_ticks_pos = [2, 5, 10, 20, 50, 100] if y_range[1] > 1 else []\n",
    "    log_ticks_neg = [-2, -5, -10, -20, -50, -100] if y_range[0] < -1 else []\n",
    "\n",
    "    all_ticks = (\n",
    "        [t for t in log_ticks_neg if t >= y_range[0]]\n",
    "        + [-1]\n",
    "        + linear_ticks\n",
    "        + [1]\n",
    "        + [t for t in log_ticks_pos if t <= y_range[1]]\n",
    "    )\n",
    "\n",
    "    tick_labels = []\n",
    "    for tick in all_ticks:\n",
    "        if tick == 1:\n",
    "            tick_labels.append(\"1\")\n",
    "        elif tick == -1:\n",
    "            tick_labels.append(\"-1\")\n",
    "        elif -1 < tick < 1:\n",
    "            tick_labels.append(f\"{tick:.1f}\")\n",
    "        else:\n",
    "            tick_labels.append(f\"{tick}\")\n",
    "\n",
    "    ax.set_yticks(all_ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "\n",
    "    # Make linear region ticks smaller\n",
    "    # for i, (tick, label) in enumerate(zip(all_ticks, tick_labels)):\n",
    "    #    if -1 < tick < 1 and tick != 0:\n",
    "    #        ax.get_yticklabels()[i].set_fontsize(8)\n",
    "\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Create combined legend with markers and colors\n",
    "    legend_elements = []\n",
    "\n",
    "    # Add rule markers\n",
    "    for rule, marker in rule_to_marker.items():\n",
    "        if rule in othello_rule_to_metric:\n",
    "            legend_elements.append(\n",
    "                plt.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=marker,\n",
    "                    color=\"black\",\n",
    "                    linestyle=\"None\",\n",
    "                    markersize=10,\n",
    "                    label=rule.name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Add color coding\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"green\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"PGR > {threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"PGR < -{threshold}\",\n",
    "        )\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"black\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=10,\n",
    "            label=f\"-{threshold} < PGR < {threshold}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc=\"lower left\")\n",
    "\n",
    "    # Add text annotations\n",
    "    # fig.text(0.5, -0.05, 'White background: Linear scale [-1,1] | Gray background: Logarithmic scale',\n",
    "    #           ha='center', fontsize=10, style='italic')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.1)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "save_path = os.path.join(experiment_folder, \"optimization_step\")\n",
    "plot_wsg_vs_metric(\n",
    "    othello_rule_to_optimization_step,\n",
    "    finetuned_rule_to_result_file,\n",
    "    x_axis_name=\"Early-stop optimization step based on ground-truth labels\",\n",
    "    title=\"PGR vs. Optimzation step at which ground truth validation is minimized\",\n",
    "    save_path=save_path,\n",
    "    x_axis_log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP3lSuGyK_F3"
   },
   "outputs": [],
   "source": [
    "def load_board_accuracy_degradation_metric(\n",
    "    finetuned_rule_to_result_file_linear_probe: dict,\n",
    "    pretrained_rule_to_result_file_linear_probe: dict,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Computes degradation metric: pretrained_accuracy - finetuned_accuracy\n",
    "\n",
    "    Returns:\n",
    "        dict mapping OthelloRule -> ModelSize (strong) -> ModelSize (weak) -> degradation\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "\n",
    "    def load_pickle(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Load pretrained accuracies\n",
    "    pretrained_accuracies = {}\n",
    "    for rule, path in pretrained_rule_to_result_file_linear_probe.items():\n",
    "        results = load_pickle(path)\n",
    "        if results:\n",
    "            pretrained_accuracies[rule] = {}\n",
    "            for res in results:\n",
    "                if res[\"othello_rule\"] == rule:\n",
    "                    pretrained_accuracies[rule][res[\"model_size\"]] = res[\n",
    "                        \"mean_accuracy\"\n",
    "                    ]\n",
    "\n",
    "    # Load finetuned accuracies and compute degradation\n",
    "    othello_rule_to_metric = {}\n",
    "\n",
    "    for rule, path in finetuned_rule_to_result_file_linear_probe.items():\n",
    "        finetuned_results = load_pickle(path)\n",
    "        if finetuned_results and rule in pretrained_accuracies:\n",
    "            othello_rule_to_metric[rule] = {}\n",
    "\n",
    "            for (\n",
    "                weak_size,\n",
    "                strong_size,\n",
    "            ), finetuned_accuracy in finetuned_results.items():\n",
    "                # Get pretrained accuracy for strong model\n",
    "                if strong_size in pretrained_accuracies[rule]:\n",
    "                    pretrained_accuracy = pretrained_accuracies[rule][strong_size]\n",
    "                    degradation = finetuned_accuracy - pretrained_accuracy\n",
    "\n",
    "                    if strong_size not in othello_rule_to_metric[rule]:\n",
    "                        othello_rule_to_metric[rule][strong_size] = {}\n",
    "                    othello_rule_to_metric[rule][strong_size][weak_size] = degradation\n",
    "\n",
    "    return othello_rule_to_metric\n",
    "\n",
    "\n",
    "# Generate the degradation metric\n",
    "othello_rule_to_degradation = load_board_accuracy_degradation_metric(\n",
    "    finetued_rule_to_result_file_linear_probe,  # First parameter should be linear probe\n",
    "    pretrained_rule_to_result_file_linear_probe,\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "save_path = os.path.join(experiment_folder, \"board_accuracy_degradation\")\n",
    "plot_wsg_vs_metric(\n",
    "    othello_rule_to_degradation,\n",
    "    finetuned_rule_to_result_file,  # Second parameter should be WSG results\n",
    "    x_axis_name=\"Change in Linear Probe accuracy [Acc(Finetuned) - Acc(Pretrained)]\",\n",
    "    title=\"WSG vs Change in Representations during Finetuning\",\n",
    "    save_path=save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deXRIAsvteuL"
   },
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_5qEvxrXcVY"
   },
   "source": [
    "# --- Random ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "BzjTH5YWF5Ss",
    "outputId": "23f355af-8f08-4637-f4b7-cd5fd71a77db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"06edd980-fd4a-42f4-afcf-fe1f71315b83\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"06edd980-fd4a-42f4-afcf-fe1f71315b83\")) {                    Plotly.newPlot(                        \"06edd980-fd4a-42f4-afcf-fe1f71315b83\",                        [{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,2,2,2,0,0],[0,0,1,2,2,0,0,0],[0,0,0,1,1,0,2,0],[0,0,0,0,1,2,1,1],[0,0,0,0,2,0,0,0],[0,0,0,2,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,1,1,1,0,0],[0,0,2,1,1,0,0,0],[0,0,0,2,2,0,1,0],[0,0,0,0,2,1,2,2],[0,0,0,0,1,0,0,0],[0,0,0,1,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,1,1,1,0,0],[0,0,1,1,1,0,0,0],[0,0,0,1,1,0,1,0],[0,0,0,0,1,1,1,1],[0,0,0,0,1,0,0,0],[0,0,0,1,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x4\",\"yaxis\":\"y4\",\"z\":[[1,2,1,1,1,2,2,2],[2,2,1,2,0,1,0,0],[1,0,1,1,0,1,2,1],[2,0,1,1,0,1,2,1],[2,1,2,0,1,2,0,2],[0,1,1,1,2,2,2,1],[0,0,1,0,2,2,1,1],[0,0,1,0,0,2,1,2]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x5\",\"yaxis\":\"y5\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,2,0,0,0],[0,0,0,2,2,1,0,0],[0,0,2,1,2,0,0,0],[0,0,0,2,2,0,1,0],[0,0,0,0,2,1,2,2],[0,0,0,0,1,0,0,0],[0,0,0,1,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x6\",\"yaxis\":\"y6\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,2,0,0,0],[0,0,0,2,2,1,0,0],[0,0,2,1,2,0,0,0],[0,0,0,2,2,0,1,0],[0,0,0,0,2,1,2,2],[0,0,0,0,1,0,0,0],[0,0,0,1,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x7\",\"yaxis\":\"y7\",\"z\":[[0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0],[0,0,0,1,1,1,0,0],[0,0,1,1,1,0,0,0],[0,0,0,1,1,0,1,0],[0,0,0,0,1,1,1,1],[0,0,0,0,1,0,0,0],[0,0,0,1,0,0,0,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"},{\"colorscale\":[[0,\"grey\"],[0.5,\"white\"],[1,\"black\"]],\"showscale\":false,\"xaxis\":\"x8\",\"yaxis\":\"y8\",\"z\":[[1,1,2,2,0,0,2,2],[1,1,0,1,1,0,0,0],[1,0,0,1,2,0,0,1],[1,2,1,2,2,0,0,0],[2,2,1,0,0,2,2,1],[0,1,1,2,1,0,0,0],[1,0,1,0,1,0,0,0],[0,1,0,2,0,0,2,0]],\"zmax\":2,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2125],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.55,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.2625,0.475],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.55,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.525,0.7375],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.55,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7875,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.55,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.2125],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.45],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.2625,0.475],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.45],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.525,0.7375],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.45],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7875,1.0],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.45],\"tickvals\":[0,1,2,3,4,5,6,7],\"ticktext\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 10: Mine\\u002fYours\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 10: White\\u002fBlack\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 10: Empty\\u002fFilled\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 10: Non-linear\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 11: Mine\\u002fYours\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 11: White\\u002fBlack\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 11: Empty\\u002fFilled\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Move 11: Non-linear\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"height\":600,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('06edd980-fd4a-42f4-afcf-fe1f71315b83');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "\n",
    "# Get example game and extract moves 10-11\n",
    "example_game = [to_square(i) for i in train_dataset[0][0].tolist()]\n",
    "game_ids = to_id(example_game)\n",
    "\n",
    "# Get board states for moves 10-11\n",
    "board_states = t.zeros((2, 8, 8), dtype=t.int32)\n",
    "board = OthelloBoardState()\n",
    "for i, token_id in enumerate(game_ids[:12]):  # Up to move 11\n",
    "    board.umpire(id_to_square(token_id))\n",
    "    if i >= 10:  # Save moves 10-11\n",
    "        board_states[i - 10] = t.from_numpy(board.state)\n",
    "\n",
    "# Create 4 different basis transformations\n",
    "basis_states = t.zeros((2, 4, 8, 8), dtype=t.int32)\n",
    "\n",
    "for move_idx in range(2):\n",
    "    state = board_states[move_idx]\n",
    "    current_player = -1 if (10 + move_idx) % 2 == 0 else 1  # Black starts\n",
    "\n",
    "    # Basis 1: empty/mine/yours\n",
    "    mine_mask = state == current_player\n",
    "    yours_mask = state == -current_player\n",
    "    basis_states[move_idx, 0] = mine_mask.long() + 2 * yours_mask.long()\n",
    "\n",
    "    # Basis 2: empty/white/black\n",
    "    white_mask = state == 1\n",
    "    black_mask = state == -1\n",
    "    basis_states[move_idx, 1] = white_mask.long() + 2 * black_mask.long()\n",
    "\n",
    "    # Basis 3: empty/filled\n",
    "    basis_states[move_idx, 2] = (state != 0).long()\n",
    "\n",
    "    # Basis 4: non-linear transformation\n",
    "    transform = FakeBoardStateTransformModulo()\n",
    "    fake_state = transform(state.unsqueeze(0).unsqueeze(0)).squeeze()\n",
    "    basis_states[move_idx, 3] = fake_state\n",
    "\n",
    "# Flatten for plotting (2*4 = 8 boards)\n",
    "all_states = basis_states.view(8, 8, 8)\n",
    "titles = []\n",
    "for move in [10, 11]:\n",
    "    titles.extend(\n",
    "        [\n",
    "            f\"Move {move}: Mine/Yours\",\n",
    "            f\"Move {move}: White/Black\",\n",
    "            f\"Move {move}: Empty/Filled\",\n",
    "            f\"Move {move}: Non-linear\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Plot directly with plotly for 0,1,2 values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplot grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=4, subplot_titles=titles, vertical_spacing=0.1, horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "# Custom colorscale for 0=white, 1=grey, 2=black\n",
    "colorscale = [[0, \"grey\"], [0.5, \"white\"], [1, \"black\"]]\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4 + 1\n",
    "    col = i % 4 + 1\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=all_states[i].numpy(),\n",
    "            colorscale=colorscale,\n",
    "            zmin=0,\n",
    "            zmax=2,\n",
    "            showscale=False,\n",
    "            xaxis=f\"x{i + 1}\",\n",
    "            yaxis=f\"y{i + 1}\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=600, width=1200)\n",
    "fig.update_xaxes(tickvals=list(range(8)), ticktext=[str(i) for i in range(8)])\n",
    "fig.update_yaxes(tickvals=list(range(8)), ticktext=list(\"ABCDEFGH\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvHlrr_wC3d-"
   },
   "outputs": [],
   "source": [
    "def calculate_leakage_by_train_games(\n",
    "    train_data: \"CharDataset\",\n",
    "    test_data: \"CharDataset\",\n",
    "    train_subset_size: int = 10000,\n",
    "    batch_size: int = 10000,\n",
    "    ordered_moves: bool = True,\n",
    ") -> int:\n",
    "    if len(train_data.data) > train_subset_size:\n",
    "        train_subset = random.sample(train_data.data, train_subset_size)\n",
    "    else:\n",
    "        train_subset = train_data.data\n",
    "    train_games_to_check = {tuple(game) for game in train_subset}\n",
    "\n",
    "    leaked_count = 0\n",
    "    num_test_batches = (len(test_data.data) + batch_size - 1) // batch_size\n",
    "    test_iterator = tqdm(range(num_test_batches), desc=\" Checking test batches\")\n",
    "\n",
    "    for i in test_iterator:\n",
    "        if not train_games_to_check:\n",
    "            break\n",
    "\n",
    "        start_idx = i * batch_size\n",
    "        test_batch = test_data.data[start_idx : start_idx + batch_size]\n",
    "        current_test_prefixes = {\n",
    "            tuple(game[:l]) if ordered_moves else tuple(sorted(game[:l]))\n",
    "            for game in test_batch\n",
    "            for l in range(1, len(game) + 1)\n",
    "        }\n",
    "\n",
    "        found_in_batch = set()\n",
    "        for train_game in train_games_to_check:\n",
    "            for l in range(1, len(train_game) + 1):\n",
    "                train_prefix = (\n",
    "                    tuple(train_game[:l])\n",
    "                    if ordered_moves\n",
    "                    else tuple(sorted(train_game[:l]))\n",
    "                )\n",
    "                if train_prefix in current_test_prefixes:\n",
    "                    found_in_batch.add(train_game)\n",
    "                    break\n",
    "\n",
    "        if found_in_batch:\n",
    "            leaked_count += len(found_in_batch)\n",
    "            train_games_to_check -= found_in_batch\n",
    "\n",
    "        test_iterator.set_postfix(\n",
    "            {\"Leaked\": leaked_count, \"Remaining\": len(train_games_to_check)}\n",
    "        )\n",
    "\n",
    "    return leaked_count\n",
    "\n",
    "\n",
    "leaked_game_count = calculate_leakage_by_train_games(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    train_subset_size=10000,\n",
    "    batch_size=10000,  # Small batch size for demonstration\n",
    ")\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"Total leaked training games found: {leaked_game_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et2ytFZ_bwzZ"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset) / (100 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYTWm-HyEAHm"
   },
   "outputs": [],
   "source": [
    "def calculate_leakage_by_train_games(\n",
    "    train_data: \"CharDataset\",\n",
    "    test_data: \"CharDataset\",\n",
    "    train_subset_size: int = 10000,\n",
    "    batch_size: int = 10000,\n",
    "    ordered_moves: bool = True,\n",
    ") -> int:\n",
    "    train_games_to_check = random.sample(train_data.data, train_subset_size)\n",
    "    leaked_count = 0\n",
    "    num_test_batches = (len(test_data.data) + batch_size - 1) // batch_size\n",
    "    test_iterator = tqdm(range(num_test_batches), desc=\" Checking test batches\")\n",
    "\n",
    "    for i in test_iterator:\n",
    "        if not train_games_to_check:\n",
    "            break\n",
    "\n",
    "        start_idx = i * batch_size\n",
    "        test_batch = test_data.data[start_idx : start_idx + batch_size]\n",
    "        current_test_prefixes = {\n",
    "            tuple(game[:l]) if ordered_moves else tuple(sorted(game[:l]))\n",
    "            for game in test_batch\n",
    "            for l in range(1, len(game) + 1)\n",
    "        }\n",
    "\n",
    "        found_in_batch = set()\n",
    "        for train_game in train_games_to_check:\n",
    "            for l in range(1, len(train_game) + 1):\n",
    "                train_prefix = (\n",
    "                    tuple(train_game[:l])\n",
    "                    if ordered_moves\n",
    "                    else tuple(sorted(train_game[:l]))\n",
    "                )\n",
    "                if train_prefix in current_test_prefixes:\n",
    "                    found_in_batch.add(train_game)\n",
    "                    break\n",
    "\n",
    "        if found_in_batch:\n",
    "            leaked_count += len(found_in_batch)\n",
    "            train_games_to_check -= found_in_batch\n",
    "            if leaked_count % 10:\n",
    "                print(leaked_count)\n",
    "\n",
    "        test_iterator.set_postfix(\n",
    "            {\"Leaked\": leaked_count, \"Remaining\": len(train_games_to_check)}\n",
    "        )\n",
    "\n",
    "    return leaked_count\n",
    "\n",
    "\n",
    "leaked_game_count = calculate_leakage_by_train_games(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    train_subset_size=1,\n",
    "    batch_size=100000,  # Small batch size for demonstration\n",
    ")\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"Total leaked training games found: {leaked_game_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coz4TQ87V4xc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KNmCQ_8oJVl"
   },
   "outputs": [],
   "source": [
    "hooked_model = convert_and_verify(trainer.model.module, mconf, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cj5v_p4oFQbD"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del hooked_model\n",
    "t.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neFWabEVFXJm"
   },
   "outputs": [],
   "source": [
    "# def load_model(checkpoint_path, model_config):\n",
    "#    model = GPT(model_config)\n",
    "#    model.load_state_dict(t.load(checkpoint_path, map_location='cpu'))\n",
    "#    model.to(DEVICE)\n",
    "#    return model\n",
    "\n",
    "# checkpoint_path = experiment_folder + 'TEST_MODEL_2025-06-24-22-48-39/ckpts/gpt_at_20250624_224839.ckpt'  # Self trained GPT\n",
    "# checkpoint_path = experiment_folder + 'TEST_MODEL_2025-06-28-15-20-17/ckpts/gpt_at_20250628_152017.ckpt'  # Biased, trained on smaller dataset\n",
    "# checkpoint_path = experiment_folder + 'TEST_MODEL_2025-06-28-15-02-06/ckpts/gpt_at_20250628_150206.ckpt'  # Hald trained standard model\n",
    "# model_2 = load_model(checkpoint_path, mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiF2VgZ3_IiN"
   },
   "outputs": [],
   "source": [
    "# hooked_model_2 = convert_and_verify(model_2, mconf, test_dataset)\n",
    "\n",
    "# results = test_hooked_transformer(hooked_model_2, test_dataset=val_dataset, batch_size=512, n_games=100, device=DEVICE)\n",
    "# print(\"\")\n",
    "# print(f\"Validation CE Loss: {results['ce_loss']:.6f}\")\n",
    "# print(f\"Illegal Move %: {results['illegal_move_percentage']:.6f}%\")\n",
    "# print(f\"Total Predictions: {results['total_predictions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_gYnul8ja89"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FZn51HV6BxlF",
    "1JSymT_uB2UA",
    "FlBlZGS11HFE",
    "iJBpHN2keuz_",
    "YF367sxmh2xt",
    "bvRRT56NfBbB",
    "xRMwW4x7ieNT",
    "8unPxOD58V0W",
    "x7ExCwGRXzJh",
    "dSmryN0PM8H_",
    "FyqteaDW9ssL",
    "cuqz9jya8wGF",
    "nQl3qrr8SV5Z",
    "FOj-51o88zVd",
    "ZjTXE9OjZIrm",
    "agBm7yQHYXAp",
    "ThMvq0yOYnXU",
    "tc8OKY5ZhHqn",
    "y7iUk7uY8wcE",
    "vFKAJF7S7aGF",
    "Oyzic3pGk6qh",
    "DNdXLKRdbPXZ",
    "Q7taVfY8YIIm",
    "s6KeGvQd-xri",
    "b8PxZcUe0zJL",
    "HdOSlYFi6-HI",
    "V820C1vGXVY1",
    "Uy2e79Ay0ops",
    "qU8sbUsfMa0H",
    "qD6EzWo5OmJf",
    "lIgr9l_8BS-p",
    "kqeD1NyB0KSs",
    "A9hvwWKsGku4",
    "rZEfASMX0Gjy",
    "L4L5Qx66M_1A",
    "B0nMvQJLJzf8"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
